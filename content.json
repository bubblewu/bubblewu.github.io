{"meta":{"title":"大泡泡的笔记","subtitle":"记录平时工作过程中的学习点滴","description":"Java、Python、机器学习、深度学习、推荐系统、自然语言处理","author":"Bubble","url":"https://bubblewu.github.io","root":"/"},"pages":[{"title":"404 Not Found","date":"2020-06-08T06:59:37.716Z","updated":"2020-06-08T03:32:03.119Z","comments":true,"path":"404.html","permalink":"https://bubblewu.github.io/404.html","excerpt":"","text":"404 很抱歉，您访问的页面不存在 可能是输入地址有误或该地址已被删除 向博主反馈问题"},{"title":"Android SDK","date":"2020-06-08T09:11:17.985Z","updated":"2020-06-08T03:32:03.128Z","comments":true,"path":"adb/index.html","permalink":"https://bubblewu.github.io/adb/index.html","excerpt":"","text":"Android SDK SDK:(software development kit) &nbsp;&nbsp;&nbsp;&nbsp;被软件开发工程师用于为特定的软件包、软件框架、硬件平台、操作系统等建立应用软件的开发工具的集合。因此，Android SDK 指的是Android专属的软件开发工具包。 Start Learning"},{"title":"所有分类","date":"2020-06-09T02:28:09.039Z","updated":"2020-06-08T03:32:03.130Z","comments":true,"path":"categories/index.html","permalink":"https://bubblewu.github.io/categories/index.html","excerpt":"","text":""},{"title":"个人简介","date":"2020-06-08T09:17:17.877Z","updated":"2020-06-08T09:17:17.868Z","comments":true,"path":"about/index.html","permalink":"https://bubblewu.github.io/about/index.html","excerpt":"记录工作过程中的点滴！","text":"记录工作过程中的点滴！ 本Blog主要用来记录工作过程中的点滴！ 联系博主"},{"title":"","date":"2020-06-08T06:59:37.715Z","updated":"2020-06-08T03:32:03.130Z","comments":true,"path":"list/index.html","permalink":"https://bubblewu.github.io/list/index.html","excerpt":"","text":""},{"title":"Contributors「鸣谢」","date":"2020-06-09T02:16:51.775Z","updated":"2020-06-08T03:32:03.130Z","comments":true,"path":"contributors/index.html","permalink":"https://bubblewu.github.io/contributors/index.html","excerpt":"","text":"特别鸣谢 hexo 开发者和 volantis 开发者！ Hexo volantis"},{"title":"我的朋友们","date":"2020-06-08T06:59:37.720Z","updated":"2020-06-08T03:32:03.130Z","comments":false,"path":"friends/index.html","permalink":"https://bubblewu.github.io/friends/index.html","excerpt":"这里写友链上方的内容。","text":"这里写友链上方的内容。 这里可以写友链页面下方的文字备注，例如自己的友链规范、示例等。"},{"title":"留言板","date":"2020-05-20T15:25:38.000Z","updated":"2020-06-08T03:32:03.131Z","comments":true,"path":"msgboard/index.html","permalink":"https://bubblewu.github.io/msgboard/index.html","excerpt":"","text":""},{"title":"所有标签","date":"2020-06-08T06:59:37.709Z","updated":"2020-06-08T03:32:03.131Z","comments":true,"path":"tags/index.html","permalink":"https://bubblewu.github.io/tags/index.html","excerpt":"","text":""},{"title":"2. 连接调试","date":"2020-05-17T08:02:45.000Z","updated":"2020-06-08T03:32:03.128Z","comments":true,"path":"adb/debug/index.html","permalink":"https://bubblewu.github.io/adb/debug/index.html","excerpt":"","text":"win12345678910# 什么进程占用了 5037netstat -ano | findstr \"5037\"# 结果显示进程PID 21152（示例）# 查看进程是哪个程序启动的这个进程（21152为进程PID）tasklist | findstr \"21152\"#结果显示 某个服务# 杀进程taskkill /f /pid 21152 mac1234567891011# 什么进程占用了 5037netstat -an|grep 5037# 查看进程是哪个程序启动的这个进程（21152为进程PID）lsof -i :5037# 杀进程(PID为53067的进程)kill -9 53067# psps -ef | grep 5037"},{"title":"3. apk安装&卸载","date":"2020-05-17T12:35:53.000Z","updated":"2020-06-08T03:32:03.129Z","comments":true,"path":"adb/installapk/index.html","permalink":"https://bubblewu.github.io/adb/installapk/index.html","excerpt":"","text":"安装(adb install)1234567891011121314# 普通安装adb install &lt;apk_path&gt;# 覆盖安装adb install -r &lt;apk_path&gt;# 安装debug包adb install -t &lt;apk_path&gt;# 降级安装adb install -d &lt;apk_path&gt; # 只针对debug包，对release包无效# 针对特定设备安装(多设备同时连接电脑时)adb -s &lt;devices_id&gt; install &lt;apk_path&gt; 卸载(adb uninstall)12345# 普通卸载adb uninstall &lt;package_name&gt; # 例如: com.jd.xxx# 针对特定设备卸载(多设备同时连接电脑时)adb -s &lt;devices_id&gt; uninstall &lt;package_name&gt; # 例如: com.jd.xxx 自动化下的安装卸载(pm命令)12345# 安装apkpm install &lt;device_apk_path&gt; # device_apk_path为手机路径 /sdcard# 卸载apkpm install &lt;package_name&gt; # 例如: com.jd.xxx pm 更多用法"},{"title":"4. 玩转pm命令","date":"2020-05-17T13:05:23.000Z","updated":"2020-06-08T03:32:03.129Z","comments":true,"path":"adb/pm/index.html","permalink":"https://bubblewu.github.io/adb/pm/index.html","excerpt":"","text":"获取设备app包名称列表1adb shell pm list package # 列出安装在设备上应用的包名 获取设备app包名称列表, 只显示系统应用1adb shell pm list package -s # 列出安装在设备上应用的包名 获取设备app包名称列表, 只显示三方应用1adb shell pm list package -3 # 列出安装在设备上应用的包名 列出应用包名及对应的apk名及存放位置1adb shell pm list package -f # 列出安装在设备上应用的包名 列出应用包名及其安装来源1adb shell pm list package -i 查看APP详细信息1adb shell pm dump &lt;package_name&gt; # 例如：com.jd.xxxx 安装apk1adb shell pm install &lt;apk_path&gt; # 目标 apk 存放于 Android 设备上(，请用 pm install 安装) 卸载apk1adb shell pm uninstall &lt;package_name&gt; 清除APP数据和缓存1adb shell pm clear &lt;package_name&gt; 重置所有APP权限1adb shell pm reset 查看帮助文档1adb shell pm"},{"title":"1. SDK下载安装","date":"2020-05-17T06:59:42.000Z","updated":"2020-06-08T03:32:03.129Z","comments":true,"path":"adb/sdk/index.html","permalink":"https://bubblewu.github.io/adb/sdk/index.html","excerpt":"","text":"下载Android SDK下载地址：https://www.androiddevtools.cn官方地址：http://developer.android.com/sdk点击Android SDK工具，选择SDK，按不同系统下载对应版本 安装Android SDK打开Android SDK文件夹，点击SDK Manager，只勾选platform-tools、build-tools、tools三个工具安装即可 环境变量配置1234567# win 编辑环境变量ANDROID_HOME=&lt;android-sdk的path目录路径&gt; # 新增ANDROID_HOMEPATH=$ANDROID_HOME/bin;$ANDROID_HOME/platform-tools;$ANDROID_HOME/build-tools;$ANDROID_HOME/tools# mac 修改.bashrc或.zshrc(zsh使用者)export ANDROID_HOME=&lt;android-sdk的path目录路径&gt;export CLASSPATH=.:$ANDROID_HOME/bin;$ANDROID_HOME/platform-tools;$ANDROID_HOME/build-tools;$ANDROID_HOME/tools"}],"posts":[{"title":"并发模式-6：Read-Write Lock模式：读写锁","slug":"Java/并发/并发模式-6：Read-Write Lock模式：读写锁","date":"2021-10-09T08:42:35.000Z","updated":"2021-10-09T08:48:37.511Z","comments":true,"path":"ckujjz03a00007syd5ex780wz/","link":"","permalink":"https://bubblewu.github.io/ckujjz03a00007syd5ex780wz/","excerpt":"Read-Write Lock模式：读写锁案例","text":"Read-Write Lock模式：读写锁案例 Read-Write Lock模式生活小case课堂上老师讲解Java的并发知识，黑板上记录了许多干货。干货太多黑板没有空间了，老师要擦掉板书再继续写新的内容，然而学生都还没看完，不让老师擦掉。这时，老师等待大家看完，再擦掉重新写。这个思想就是Read-Write Lock模式。 概念Read-Write Lock模式，即：读取和写入操作分开考虑，在执行读取操作之前线程必须获取用于读取的锁，同理写入之前也需获取用于写入的锁。 线程读取操作时实例状态不变，故可多个线程同时读取，但不可写入； 线程写入操作时会改变实例状态，故在此期间，其他线程不可读取或写入； 这样将针对写入和读取的互斥处理操作分开考虑，能够提高程序的性能。 适用场景 适合读取操作繁重时； 适合读取频率比写入频率高时； 案例场景假设有一个Data类可以进行数据的读写，在多线程环境下对其进行读写操作。 实现主要模块 类名 说明 Main 测试主类 Data 可以读写的类 WriterThread 表示写入线程的类 ReaderThread 表示读取线程的类 ReadWriteLock 提供读写锁的类 代码 Main函数 123456789101112131415public static void main(String[] args) &#123; // 启动6个读取线程和2个写入线程 // 结果打印ReadThread读取的内容，当WriteThread写入时，输出会暂停一下。 // reads日志中右边的10个字符是相同的，因为即使有线程冲突，程序的安全性是可以保证，否则会多个字符交叉在一起显示 Data data = new Data(10); new ReadThread(data).start(); new ReadThread(data).start(); new ReadThread(data).start(); new ReadThread(data).start(); new ReadThread(data).start(); new ReadThread(data).start(); new WriteThread(data, \"1234567890\").start(); new WriteThread(data, \"abcdefghijk\").start(); &#125; Data数据操作 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576package com.bubble.demo.read_write_lock;import java.util.Arrays;/** * 用于数据读写 * * @author wu gang * date: 2021-10-08 18:50 **/public class Data &#123; /** * 实际读写对象的数组 */ private final char[] buffer; /** * 读写锁 */ private final ReadWriteLock lock = new ReadWriteLock(); /** * 基于size初始化buffer数组，默认用字符*作为初始值来填充 * * @param size 数组长度 */ public Data(int size) &#123; this.buffer = new char[size]; Arrays.fill(buffer, '*'); &#125; public char[] read() throws InterruptedException &#123; lock.readLock(); try &#123; return doRead(); &#125; finally &#123; lock.readUnLock(); &#125; &#125; private char[] doRead() &#123; char[] newBuf = new char[buffer.length]; System.arraycopy(buffer, 0, newBuf, 0, buffer.length); slowly(); return newBuf; &#125; public void write(char c) throws InterruptedException &#123; lock.writeLock(); try &#123; doWrite(c); &#125; finally &#123; lock.writeUnLock(); &#125; &#125; private void doWrite(char c) &#123; for (int i = 0; i &lt; buffer.length; i++) &#123; buffer[i] = c; // 假定写入操作比读取操作耗时久，每写入一个字符就sleep下 slowly(); &#125; &#125; /** * 模拟耗时操作 */ private void slowly() &#123; try &#123; Thread.sleep(50); &#125; catch (InterruptedException ignored) &#123; &#125; &#125;&#125; 读取线程 12345678910111213141516171819202122232425262728package com.bubble.demo.read_write_lock;/** * 对Data实例执行读取操作的线程 * * @author wu gang * date: 2021-10-08 19:23 **/public class ReadThread extends Thread &#123; private final Data data; public ReadThread(Data data) &#123; this.data = data; &#125; @Override public void run() &#123; try &#123; while (true) &#123; char[] readBuf = data.read(); System.out.printf(\"%s reads: %s%n\", Thread.currentThread().getName(), String.valueOf(readBuf)); &#125; &#125; catch (InterruptedException ignored) &#123; &#125; &#125;&#125; 写入线程 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647package com.bubble.demo.read_write_lock;import java.util.Random;/** * 对Data实例执行写入操作的线程（无互斥处理相关代码） * * @author wu gang * date: 2021-10-08 19:23 **/public class WriteThread extends Thread &#123; private static final Random RANDOM = new Random(); private final Data data; /** * 程序逐个取出该字符串中的字符，并写入到Data实例中 */ private final String filter; private int index = 0; public WriteThread(Data data, String filter) &#123; this.data = data; this.filter = filter; &#125; @Override public void run() &#123; try &#123; while (true) &#123; char c = nextChar(); data.write(c); Thread.sleep(3000); &#125; &#125; catch (InterruptedException ignored) &#123; &#125; &#125; private char nextChar() &#123; char c = filter.charAt(index); index++; if (index &gt;= filter.length()) &#123; index = 0; &#125; return c; &#125;&#125; 自定义读写锁 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687package com.bubble.demo.read_write_lock;/** * 读写锁： * 防止下面的两种冲突： * - 读取和写入的冲突（read-write conflict） * - 写入和写入的冲突（write-write conflict） * 由于读取不涉及实例状态的变化，读取和读取之间无冲突。 * * 实现时主要考虑下面两种情况： * 1、当线程想要获取读锁时： * - 如果有线程正在执行写入，则等待，避免read-write conflict； * - 如果有线程正在执行读取，则无需等待； * 2、当线程想要获取写锁时： * - 如果有线程正在执行写入，则等待，避免write-write conflict； * - 如果有线程正在执行读取，则等待，避免read-write conflict； * * @author wu gang * date: 2021-10-08 18:52 **/public class ReadWriteLock &#123; /** * 实际正在读取中的线程个数。 * 即执行了readLock但未执行readUnLock的线程个数，值一定大于0 */ private int readingReaders = 0; /** * 正在等待写入的线程个数。 * 即执行到writeLock之后，使用wait执行等待的线程的个数 */ private int waitingWriters = 0; /** * 实际正在写入中的线程个数。 * 即执行了writeLock但未执行writeUnLock的线程个数，值只能是0或1。 */ private int writeWriters = 0; /** * 若写入优先则为true，否则读取优先。 * 不降低线程的生存性，去掉不影响结果的输出。 * 让ReadThread和WriteThread轮流优先执行， * 就像实际生活中车前进方向的信号灯和人行方向的信号灯轮流变为红灯一样。 */ private boolean preferWriter = true; public synchronized void readLock() throws InterruptedException &#123; // 读时，如果有线程正在写入，避免冲突，wait while (writeWriters &gt; 0 || (preferWriter &amp;&amp; waitingWriters &gt; 0)) &#123; wait(); &#125; // 实际正在读取的线程个数加1 readingReaders++; &#125; public synchronized void readUnLock() &#123; // 实际正在读取的线程个数减1 readingReaders--; preferWriter = true; notifyAll(); &#125; public synchronized void writeLock() throws InterruptedException &#123; // 正在等待的线程数量加1 waitingWriters++; try &#123; // 写时，如果有线程正在读或写入，避免冲突，wait while (readingReaders &gt; 0 || writeWriters &gt; 0) &#123; wait(); &#125; &#125; finally &#123; // 正在等待的线程数量减1 waitingWriters--; &#125; // 实际正在写入的线程数量加1 writeWriters++; &#125; public synchronized void writeUnLock() &#123; // 实际正在写入的线程数量减1 writeWriters--; preferWriter = false; notifyAll(); &#125;&#125; 结果输出 当reader角色正在读取，writer角色正在等待的情形 当一个writer角色正在写入，reader和其他writer角色正在等待的情形 正常加读写锁输出结果打印ReadThread读取的内容，当WriteThread写入时，输出会暂停一下。reads日志中右边的10个字符是相同的，因为即使有线程冲突，程序的安全性是可以保证，否则会多个字符交叉在一起显示。 1234567891011121314151617181920212223242526272829Thread-1 reads: **********Thread-0 reads: **********Thread-3 reads: **********Thread-2 reads: **********Thread-5 reads: **********Thread-4 reads: **********Thread-2 reads: aaaaaaaaaaThread-4 reads: aaaaaaaaaaThread-1 reads: aaaaaaaaaaThread-5 reads: aaaaaaaaaaThread-0 reads: aaaaaaaaaaThread-3 reads: aaaaaaaaaaThread-0 reads: 1111111111Thread-4 reads: 1111111111Thread-4 reads: 1111111111Thread-3 reads: 1111111111Thread-5 reads: 1111111111Thread-1 reads: 1111111111Thread-4 reads: 1111111111Thread-0 reads: 1111111111Thread-2 reads: 1111111111Thread-3 reads: 1111111111Thread-1 reads: 1111111111Thread-5 reads: 1111111111Thread-4 reads: 1111111111Thread-5 reads: 1111111111Thread-1 reads: 1111111111Thread-3 reads: 1111111111... 将读写锁换为synchronized关键字耗时会更久。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263Thread-0 reads: **********Thread-5 reads: 1111111111Thread-4 reads: 1111111111Thread-3 reads: 1111111111Thread-2 reads: 1111111111Thread-1 reads: 1111111111Thread-1 reads: 1111111111Thread-1 reads: 1111111111Thread-1 reads: 1111111111Thread-1 reads: 1111111111Thread-1 reads: 1111111111Thread-2 reads: 1111111111Thread-3 reads: 1111111111Thread-4 reads: 1111111111Thread-4 reads: 1111111111Thread-5 reads: 1111111111Thread-0 reads: 1111111111Thread-5 reads: 1111111111Thread-4 reads: 1111111111Thread-3 reads: 1111111111Thread-2 reads: 1111111111Thread-2 reads: 1111111111Thread-1 reads: 1111111111Thread-2 reads: 1111111111Thread-3 reads: 1111111111Thread-4 reads: 1111111111Thread-5 reads: 1111111111Thread-0 reads: 1111111111Thread-5 reads: 1111111111Thread-4 reads: 1111111111Thread-3 reads: 1111111111Thread-3 reads: 1111111111Thread-2 reads: 1111111111Thread-1 reads: 1111111111Thread-2 reads: 1111111111Thread-3 reads: 1111111111Thread-4 reads: 1111111111Thread-5 reads: 1111111111Thread-5 reads: 1111111111Thread-0 reads: 1111111111Thread-5 reads: 1111111111Thread-4 reads: 1111111111Thread-3 reads: 1111111111Thread-2 reads: 1111111111Thread-1 reads: 1111111111Thread-2 reads: 1111111111Thread-3 reads: 1111111111Thread-4 reads: 1111111111Thread-5 reads: 1111111111Thread-0 reads: 1111111111Thread-5 reads: 1111111111Thread-4 reads: bbbbbbbbbbThread-3 reads: bbbbbbbbbbThread-2 reads: bbbbbbbbbbThread-1 reads: bbbbbbbbbbThread-2 reads: bbbbbbbbbbThread-3 reads: bbbbbbbbbbThread-4 reads: bbbbbbbbbbThread-5 reads: 2222222222Thread-0 reads: 2222222222Thread-5 reads: 2222222222Thread-4 reads: 2222222222... 不加锁（去掉Data类中read和write方法中的锁），非线程安全的输出：12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152Thread-1 reads: **********Thread-5 reads: **********Thread-2 reads: **********Thread-4 reads: **********Thread-3 reads: **********Thread-0 reads: **********Thread-5 reads: aa********Thread-2 reads: aa********Thread-4 reads: aa********Thread-1 reads: aa********Thread-3 reads: aa********Thread-0 reads: aa********Thread-2 reads: aaa*******Thread-1 reads: aaa*******Thread-4 reads: aaa*******Thread-5 reads: aaa*******Thread-3 reads: aaa*******Thread-0 reads: aaa*******Thread-2 reads: aaa1******Thread-4 reads: aaa1******Thread-1 reads: aaa1******Thread-5 reads: aaa1******Thread-3 reads: aaa1******Thread-0 reads: aaa1******Thread-2 reads: aaa1a*****Thread-1 reads: aaa1a*****Thread-4 reads: aaa1a*****Thread-5 reads: aaa1a*****Thread-3 reads: aaa1a*****Thread-4 reads: aaa1aaa***Thread-5 reads: aaa1aaa***Thread-3 reads: aaa1aaa***Thread-0 reads: aaa1aaa***Thread-1 reads: aaa1aaa***Thread-2 reads: aaa1aaaa**Thread-4 reads: aaa1aaaa**Thread-5 reads: aaa1aaaa**Thread-3 reads: aaa1aaaa**Thread-0 reads: aaa1aaaa**Thread-1 reads: aaa1aaaa**Thread-2 reads: aaa1aaaa1*Thread-4 reads: aaa1aaaa1*Thread-5 reads: aaa1aaaa1*Thread-3 reads: aaa1aaaa1*Thread-0 reads: aaa1aaaa1*Thread-1 reads: aaa1aaaa1aThread-2 reads: aaa1aaaa1aThread-4 reads: aaa1aaaa1aThread-3 reads: aaa1aaaa1aThread-0 reads: aaa1aaaa1aThread-1 reads: aaa1aaaa1a... 扩展juc包下的读写锁：ReentrantReadWriteLockjava.util.concurrent.locks包下提供了ReadWriteLock接口和ReentrantReadWriteLock实现类，来提供Read-Write Lock模式的读写锁功能。 特征ReentrantReadWriteLock类的主要特征有： 1、公平性在创建ReentrantReadWriteLock类的实例时，可以选择锁的获取顺序是否为公平（fair）的。如果创建的实例是公平的，那么等待时间久的线程可以优先获取锁。 2、可重入性ReentrantReadWriteLock类的锁是可重入的（Reentrant）。可重入锁：是指以线程为单位，当一个线程获取对象锁之后，这个线程可以再次获取本对象上的锁，而其他的线程是不可以的。 可参考：JAVA可重入锁与不可重入锁 synchronized和ReentrantReadWriteLock都是可重入锁； 意义：防止死锁。 如：子类覆写了父类的synchonized方法，然后调用父类中的方法，此时如果没有可重入的锁，那么这段代码将产生死锁。 实现原理： 为每一个锁关联一个请求计数器和一个占有它的线程。当计数为0时，即锁未被占有，线程请求时JVM将其记录为锁的占有者并将请求数记为1。如果同一个线程再次请求这个锁，计数器递增。每次占用线程退出同步块时，计数器的值将递减，直到计数器为0，锁就会被释放。 一个线程执行synchronized同步代码时，再次重入该锁过程中，如果抛出异常，会释放锁。 可参考：线程执行SYNCHRONIZED同步代码块时再次重入该锁过程中抛异常,是否会释放锁 3、锁降级ReentrantReadWriteLock类可以按照下面的顺序将用于写入的锁降级为用于读取的锁。 获取用于写入的锁 -&gt; 获取用于读取的锁 -&gt; 释放用于写入的锁。 注意：用于读取的锁不可以降级为用于写入的锁。 4、便捷方法提供了一些便捷方法： 获取等待中的线程个数的方法：getQueueLength； 检查是否获取了用于写入的锁的方法：isWriteLocked； 案例使用juc包下的读写锁RenentrantReadWriteLock来实现Data类。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879package com.bubble.demo.read_write_lock;import java.util.Arrays;import java.util.concurrent.locks.Lock;import java.util.concurrent.locks.ReentrantReadWriteLock;&#x2F;** * 基于juc下的ReentrantReadWriteLock读写锁来实现 * * @author wu gang * date: 2021-10-09 16:09 **&#x2F;public class DataByJUC &#123; &#x2F;** * 实际读写对象的数组 *&#x2F; private final char[] buffer; &#x2F;** * 读写锁 *&#x2F; private final ReentrantReadWriteLock lock &#x3D; new ReentrantReadWriteLock(true); private final Lock readLock &#x3D; lock.readLock(); private final Lock writeLock &#x3D; lock.writeLock(); &#x2F;** * 基于size初始化buffer数组，默认用字符*作为初始值来填充 * * @param size 数组长度 *&#x2F; public DataByJUC(int size) &#123; this.buffer &#x3D; new char[size]; Arrays.fill(buffer, &#39;*&#39;); &#125; public char[] read() throws InterruptedException &#123; readLock.lock(); try &#123; return doRead(); &#125; finally &#123; readLock.unlock(); &#125; &#125; private char[] doRead() &#123; char[] newBuf &#x3D; new char[buffer.length]; System.arraycopy(buffer, 0, newBuf, 0, buffer.length); slowly(); return newBuf; &#125; public void write(char c) throws InterruptedException &#123; writeLock.lock(); try &#123; doWrite(c); &#125; finally &#123; writeLock.unlock(); &#125; &#125; private void doWrite(char c) &#123; for (int i &#x3D; 0; i &lt; buffer.length; i++) &#123; buffer[i] &#x3D; c; &#x2F;&#x2F; 假定写入操作比读取操作耗时久，每写入一个字符就sleep下 slowly(); &#125; &#125; &#x2F;** * 模拟耗时操作 *&#x2F; private void slowly() &#123; try &#123; Thread.sleep(50); &#125; catch (InterruptedException ignored) &#123; &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://bubblewu.github.io/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://bubblewu.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"并发模式-5：Producer-Consumer模式：生产者消费者","slug":"Java/并发/并发模式-5：Producer-Consumer模式：生产者消费者","date":"2020-08-18T06:40:19.000Z","updated":"2020-08-18T08:48:43.764Z","comments":true,"path":"ckdzpgvtp0000e7ydh7rl9onx/","link":"","permalink":"https://bubblewu.github.io/ckdzpgvtp0000e7ydh7rl9onx/","excerpt":"生产者消费者模式，即N个线程进行生产，同时N个线程进行消费，两种角色通过内存缓冲区进行通信。","text":"生产者消费者模式，即N个线程进行生产，同时N个线程进行消费，两种角色通过内存缓冲区进行通信。 Producer-Consumer模式生产者消费者模式，即N个线程进行生产，同时N个线程进行消费，两种角色通过内存缓冲区进行通信。 三个角色在Producer-Consumer模式，承担安全守护责任的是Channel角色。Channel角色执行线程间的互斥处理，确保Producer角色正确地将Data角色传递给Consumer角色。 Channel角色Producer-Consumer模式为了Producer向Consumer传递Data，在中间设置了Channel角色。 Producer直接调用Consumer的方法：如Producer直接调用Consumer的方法，那么执行处理的就不是Consumer的线程，而是Producer的线程了。这样执行处理花费的时间就必须由Producer的线程来承担，准备下一个数据的处理也会发生相应的延迟，会使程序的响应性变得差。 就好像：糕点师傅做好蛋糕，直接交给客人，在客人吃完后再做下一个蛋糕一样。 借助Channel角色：Producer将Data传递给Channel角色后，无需等待Consumer角色对Data进行处理，就可以立即开始准备下一个Data。也就是，Producer可以持续不断地创建Data，而不会受到Consumer角色的处理进度影响。 如何传递Data 队列：先接收的先传递使用FIFO先进先出的队列来实现。 栈：后接收的先传递使用LIFO后进先出的栈来实现。 优先队列：优先级高的先传递使用优先队列来实现，Channel角色给收到的Data设置优先级，优先级高的先传递给Consumer来处理。 存在意义因为Channel的存在，Producer和Consumer这些线程才能保持协调运行。Channel这个中间角色可以实现线程的协调运行。 线程的协调运行要考虑：放在中间的东西。 线程的互斥处理要考虑：应该保护的东西。 协调运行和互斥处理是内外统一的。为了让线程协调运行，必须执行互斥处理，以防止共享的内容被破坏；线程的互斥处理是为了线程的协调运行才执行的。 案例场景生产者消费者模式Demo：旋转小餐厅里，有3位师傅制作蛋糕放到桌子上，然后有3位客人来吃这些蛋糕。主要业务点： 师傅（MakerThread）制作蛋糕（String），并将其放置在桌子（Table）上； 桌子上最多可以放置3个蛋糕； 如果桌子上已经放满3个，就需等有空余位置时才能继续放置； 客人（EaterThread）按蛋糕放置等顺序来取桌子（Table）上等蛋糕来吃； 当桌子没有蛋糕时，客人就需等待直到有蛋糕放入； 实现 Main函数： 123456789public static void main(String[] args) &#123; Table table = new Table(3); for (int i = 0; i &lt; 3; i++) &#123; MakerThread makerThread = new MakerThread(\"-&gt; Maker.\" + i, table, 2020 + i); makerThread.start(); EaterThread eaterThread = new EaterThread(\"Eater.\" + i, table, 2020 + i); eaterThread.start(); &#125; &#125; 输出： 1234567891011121314-&gt; Maker.1 put: Cake No.0 by -&gt; Maker.1Eater.2 take: Cake No.0 by -&gt; Maker.1-&gt; Maker.2 put: Cake No.1 by -&gt; Maker.2Eater.0 take: Cake No.1 by -&gt; Maker.2-&gt; Maker.0 put: Cake No.2 by -&gt; Maker.0Eater.2 take: Cake No.2 by -&gt; Maker.0-&gt; Maker.1 put: Cake No.3 by -&gt; Maker.1Eater.1 take: Cake No.3 by -&gt; Maker.1-&gt; Maker.0 put: Cake No.4 by -&gt; Maker.0Eater.1 take: Cake No.4 by -&gt; Maker.0-&gt; Maker.2 put: Cake No.5 by -&gt; Maker.2Eater.0 take: Cake No.5 by -&gt; Maker.2-&gt; Maker.1 put: Cake No.6 by -&gt; Maker.1Eater.0 take: Cake No.6 by -&gt; Maker.1 Channel角色 Table类： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869/** * Channel角色：表示桌子 * * @author wugang * date: 2020-07-16 19:59 **/public class Table &#123; /** * 盘子：放置蛋糕的数组 */ private final String[] dishArray; /** * 下一次放置蛋糕的位置 */ private int tail; /** * 下一次取蛋糕的位置 */ private int head; /** * 当前桌子上放置的蛋糕个数 */ private int count; public Table(int totalCount) &#123; this.dishArray = new String[totalCount]; this.head = 0; this.tail = 0; this.count = 0; &#125; /** * 放置蛋糕 * * @param cake 蛋糕 */ public synchronized void put(String cake) throws InterruptedException &#123; System.out.println(Thread.currentThread().getName() + \" put: \" + cake); // 最多只能放置3个 while (count &gt;= dishArray.length) &#123; wait(); &#125; dishArray[tail] = cake; // 取下一次要放置的位置 tail = (tail + 1) % dishArray.length; count++; notifyAll(); &#125; /** * 取蛋糕 * * @return 蛋糕 */ public synchronized String take() throws InterruptedException &#123; // 桌子上没有蛋糕，等待 while (count &lt;= 0) &#123; wait(); &#125; String cake = dishArray[head]; // 取下一次要取的位置 head = (head + 1) % dishArray.length; count--; notifyAll(); System.out.println(Thread.currentThread().getName() + \" take: \" + cake); return cake; &#125;&#125; 基于juc的队列来实现Table： 12345678910111213141516171819202122232425/** * 基于juc的队列来实现Table * * @author wugang * date: 2020-07-17 17:57 **/public class TableQueue extends ArrayBlockingQueue&lt;String&gt; &#123; public TableQueue(int capacity) &#123; super(capacity); &#125; @Override public void put(String cake) throws InterruptedException &#123; System.out.println(Thread.currentThread().getName() + \" put: \" + cake); super.put(cake); &#125; @Override public String take() throws InterruptedException &#123; String cake = super.take(); System.out.println(Thread.currentThread().getName() + \" take: \" + cake); return cake; &#125;&#125; MakerThread生产者： 123456789101112131415161718192021222324252627282930313233343536373839/** * 表示糕点师 * * @author wugang * date: 2020-07-16 20:00 **/public class MakerThread extends Thread &#123; private final Random random; private final Table table; /** * 蛋糕的流水号，所有糕点师共用 */ private static int id = 0; public MakerThread(String name, Table table, long seed) &#123; super(name); this.table = table; this.random = new Random(seed); &#125; @Override public void run() &#123; while (true) &#123; try &#123; TimeUnit.MILLISECONDS.sleep(random.nextInt(1000)); String cake = \"Cake No.\" + nextId() + \" by \" + getName(); table.put(cake); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private static synchronized int nextId() &#123; return id++; &#125;&#125; EaterThread消费者： 1234567891011121314151617181920212223242526272829/** * 表示来吃蛋糕的客人 * * @author wugang * date: 2020-07-16 20:00 **/public class EaterThread extends Thread &#123; private final Random random; private final Table table; public EaterThread(String name, Table table, long seed) &#123; super(name); this.table = table; this.random = new Random(seed); &#125; @Override public void run() &#123; while (true) &#123; try &#123; String cake = table.take(); TimeUnit.MILLISECONDS.sleep(random.nextInt(1000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; 扩展常用队列 ArrayBlockingQueue类：基于数组的BlockingQueue表示元素个数有最大限制的BlockingQueue。当队列满了仍put数据时，或队列为空仍要take数据时，线程会阻塞， LinkedBlockingQueue类：基于链表的BlockingQueue表示元素个数没有最大限制的BlockingQueue。该类基于链表，如果没有特别指定，元素个数没有最大限制，只要还有内存，就可以put数据。 PriorityBlockingQueue类：带有优先级的BlockingQueue表示有优先级的BlockingQueue。数据的优先级时根据Comparable接口的自然排序，或构造函数的Comparator接口决定的顺序指定。 DelayQueue类：一定时间之后才可以take的BlockingQueue表示用于存储java.util.concurrent.Delayed对象的队列。当从该队列take时，只有在各元素指定的时间到期后才可以take。 SynchronousQueue类：直接传递的BlockingQueueSynchronousQueue类表示的是BlockingQueue，该BlockingQueue用于执行由Producer角色到Consumer角色的直接传递。如果Producer先put，在Consumer进行take之前，Producer的线程会一直阻塞。相反，如Consumer先take，在Producer执行put之前，Consumer的线程将会一直阻塞。 ConcurrentLinkedQueue类：元素个数没有最大限制的线程安全队列ConcurrentLinkedQueue类并不是BlockingQueue的实现类，它表示元素个数没有最大限制的线程安全队列。在ConcurrentLinkedQueue中，内部的数据结构是分开的，线程之间互不影响，所以就无需进行互斥处理。 java.util.concurrent.Exchanger类交换缓冲区java.util.concurrent.Exchanger类用于让两个线程安全地交换对象。 如上案例，可以将buffer1缓冲区传递给ProducerThread，然后将buffer2缓冲区传递给ConsumerThread，同时还会将通用的Exchanger的实例分别传递给ProducerThread和ConsumerThread。 Main类：1234567Exchanger&lt;Object[]&gt; exchanger = new Exchanger&lt;&gt;(); Object[] buffer1 = new Object[3]; Object[] buffer2 = new Object[3]; MakerExchangerThread makerThread = new MakerExchangerThread(\"-&gt; Maker.\", exchanger, buffer1, 2020); makerThread.start(); EaterExchangerThread eaterThread = new EaterExchangerThread(\"Eater.\", exchanger, buffer2, 2030); eaterThread.start(); 输出 12345678910111213141516171819202122232425262728293031Eater.: Before exchange-&gt; Maker. put: 0-&gt; Maker. put: 1-&gt; Maker. put: 2-&gt; Maker.: Before exchange-&gt; Maker.: After exchangeEater.: After exchangeEater. take: 0Eater. take: 1-&gt; Maker. put: 3Eater. take: 2-&gt; Maker. put: 4-&gt; Maker. put: 5-&gt; Maker.: Before exchangeEater.: Before exchangeEater.: After exchange-&gt; Maker.: After exchangeEater. take: 3Eater. take: 4-&gt; Maker. put: 6Eater. take: 5Eater.: Before exchange-&gt; Maker. put: 7-&gt; Maker. put: 8-&gt; Maker.: Before exchange-&gt; Maker.: After exchangeEater.: After exchangeEater. take: 6-&gt; Maker. put: 9Eater. take: 7-&gt; Maker. put: 10 MakerExchangerThread生成者： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253/** * 表示糕点师 * 基于juc包下的Exchanger类： 用于让两个线程安全地交换对象。 * 主要步骤： * - 生产端填充字符，直到缓冲区被填满； * - 使用exchange方法将填满的缓冲区传递给消费端； * - 传递完成后，作为交换，接收消费端已经消费完的空的缓冲区； * * @author wugang * date: 2020-07-16 20:00 **/public class MakerExchangerThread extends Thread &#123; private final Exchanger&lt;Object[]&gt; exchanger; private Object[] dishArray; private final Random random; /** * 蛋糕的流水号，所有糕点师共用 */ private static int id = 0; public MakerExchangerThread(String name, Exchanger&lt;Object[]&gt; exchanger, Object[] dishArray, long seed) &#123; super(name); this.exchanger = exchanger; this.dishArray = dishArray; this.random = new Random(seed); &#125; @Override public void run() &#123; while (true) &#123; try &#123; // 向缓冲区填充字符 for (int i = 0; i &lt; dishArray.length; i++) &#123; dishArray[i] = nextId(); TimeUnit.MILLISECONDS.sleep(random.nextInt(1000)); System.out.println(getName() + \" put: \" + dishArray[i]); &#125; // 交换缓冲区 System.out.println(getName() + \": Before exchange\"); dishArray = exchanger.exchange(dishArray); System.out.println(getName() + \": After exchange\"); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125; private static synchronized int nextId() &#123; return id++; &#125;&#125; EaterExchangerThread消费者： 12345678910111213141516171819202122232425262728293031323334353637383940414243/** * 表示来吃蛋糕的客人 * 基于juc包下的Exchanger类： 用于让两个线程安全地交换对象。 * 主要步骤： * - 使用exchange方法将空的缓冲区传递给生产端； * - 传递完成后，作为交换，接收生产端已经填满的缓冲区； * - 使用满的缓冲区的数据； * * @author wugang * date: 2020-07-16 20:00 **/public class EaterExchangerThread extends Thread &#123; private final Exchanger&lt;Object[]&gt; exchanger; private Object[] dishArray; private final Random random; public EaterExchangerThread(String name, Exchanger&lt;Object[]&gt; exchanger, Object[] dishArray, long seed) &#123; super(name); this.exchanger = exchanger; this.dishArray = dishArray; this.random = new Random(seed); &#125; @Override public void run() &#123; while (true) &#123; try &#123; // 交换缓冲区 System.out.println(getName() + \": Before exchange\"); dishArray = exchanger.exchange(dishArray); System.out.println(getName() + \": After exchange\"); // 从缓冲区中取出蛋糕 for (int i = 0; i &lt; dishArray.length; i++) &#123; System.out.println(getName() + \" take: \" + dishArray[i]); TimeUnit.MILLISECONDS.sleep(random.nextInt(1000)); &#125; &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://bubblewu.github.io/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://bubblewu.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"并发模式-4：Balking模式：停止并返回","slug":"Java/并发/并发模式-4：Balking模式：停止并返回","date":"2020-08-18T06:40:19.000Z","updated":"2020-08-18T07:25:14.500Z","comments":true,"path":"ckdzpgvu20005e7yd6yeper0b/","link":"","permalink":"https://bubblewu.github.io/ckdzpgvu20005e7yd6yeper0b/","excerpt":"Balking模式：如果现在不适合或没必要执行这个操作，就停止处理，直接返回。","text":"Balking模式：如果现在不适合或没必要执行这个操作，就停止处理，直接返回。 Balking模式 思想：Balking就是停止返回的意思。Balking模式：如果现在不适合或没必要执行这个操作，就停止处理，直接返回。 与Guarded Suspension保护暂停模式区别Balking模式Guarded Suspension保护暂停模式一样都需要守护条件。在Balking模式中，如果守护条件不成立，则立即中断处理。而后者是一直等待到可执行。 案例场景例如：文本的自动保存功能，防止电脑突然宕机，定期的将数据保存到文件中。 定期将某些数据写入文件中。每次写入都会覆盖上次写入到内容，也就是说只有最新的内容才会被保存。但需注意：当本次写入数据与上次数据内容完全相同时，就不再执行写入操作，直接返回。 也就是说，该场景下数据内容存在不同是守护条件。如果守护条件不成立，也就是数据相同，则不再执行写入操作，直接返回（Balk）。 实现Data类对应文本工具的文本内容，SaverThread类对应执行自动保存的线程，而ChangerThread类是模仿用户操作，即对文本修改并随时保存的用户。 Main： 12345public static void main(String[] args) &#123; Data data = new Data(\"data.txt\", \"(empty)\"); new ChangerThread(\"ChangerThread\", data).start(); new SaverThread(\"SaverThread\", data).start(); &#125; 输出：依次输出，没有重复的编号。 123456789101112SaverThread save content: No.0SaverThread save content: No.1ChangerThread save content: No.2ChangerThread save content: No.3SaverThread save content: No.4SaverThread save content: No.5ChangerThread save content: No.6ChangerThread save content: No.7SaverThread save content: No.8SaverThread save content: No.9ChangerThread save content: No.10ChangerThread save content: No.11 Data类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162/** * 表示可以修改并保存的数据类 * * @author wugang * date: 2020-08-18 11:16 **/public class Data &#123; /** * 保存的文件名称 */ private final String fileName; /** * 数据内容 */ private String content; /** * 守护条件：修改后的内容如果还未保存，就未true */ private boolean changed; public Data(String fileName, String content) &#123; this.fileName = fileName; this.content = content; this.changed = true; &#125; /** * 修改数据内容 * * @param newContent 新内容 */ public synchronized void change(String newContent) &#123; content = newContent; changed = true; &#125; /** * 若数据内容已经修改，则保存到文件中 */ public synchronized void save() &#123; if (!changed) &#123; return; &#125; doSave(); changed = false; &#125; /** * 将数据内容保存到文件 */ private void doSave() &#123; System.out.println(Thread.currentThread().getName() + \" save content: \" + content); try &#123; Writer writer = new FileWriter(fileName); writer.write(content); writer.close(); &#125; catch (IOException e) &#123; System.err.println(String.format(\"save error, fileName = %s, content = %s\", fileName, content) + e); &#125; &#125;&#125; ChangerThread类 1234567891011121314151617181920212223242526272829/** * 修改并保存数据内容的类 * * @author wugang * date: 2020-08-18 11:18 **/public class ChangerThread extends Thread &#123; private final Data data; private final Random random; public ChangerThread(String name, Data data) &#123; super(name); this.data = data; this.random = new Random(); &#125; @Override public void run() &#123; for (int i = 0; true ; i++) &#123; try &#123; data.change(\"No.\" + i); Thread.sleep(random.nextInt(1000)); data.save(); &#125; catch (InterruptedException ignored) &#123; &#125; &#125; &#125;&#125; SaverThread类 12345678910111213141516171819202122232425262728/** * 定期保存数据内容的类 * * @author wugang * date: 2020-08-18 11:17 **/public class SaverThread extends Thread &#123; private final Data data; public SaverThread(String name, Data data) &#123; super(name); this.data = data; &#125; @Override public void run() &#123; while (true) &#123; // 保存数据 data.save(); try &#123; // 每隔1s就保存一次 TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException ignored) &#123; &#125; &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://bubblewu.github.io/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://bubblewu.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"并发模式-3：Guarded Suspension模式：保护暂停","slug":"Java/并发/并发模式-3：Guarded Suspension模式：保护暂停","date":"2020-08-18T04:54:19.000Z","updated":"2020-08-18T07:25:11.891Z","comments":true,"path":"ckdzm6t9500009eyd7mgih05q/","link":"","permalink":"https://bubblewu.github.io/ckdzm6t9500009eyd7mgih05q/","excerpt":"Guarded Suspension模式思想就是：如果执行现在的处理会造成问题，那就让执行处理的线程进行等待。Guarded Suspension模式通过让线程等待来保护实例的安全性。就像你没穿衣服，让快递员在门口等你一会儿来保护你的隐私一样。也就是说，该模式存在一个持有状态的对象，该对象只有在自身状态合适时，才会允许线程进行目标处理。 在Single Threaded Execution模式中，只要有一个线程进入临界区，其他线程就无法进入，只能等待。而在Guarded Suspension模式中，线程是否等待取决于守护条件。后者是在前者基础上添加了附加条件而形成的。","text":"Guarded Suspension模式思想就是：如果执行现在的处理会造成问题，那就让执行处理的线程进行等待。Guarded Suspension模式通过让线程等待来保护实例的安全性。就像你没穿衣服，让快递员在门口等你一会儿来保护你的隐私一样。也就是说，该模式存在一个持有状态的对象，该对象只有在自身状态合适时，才会允许线程进行目标处理。 在Single Threaded Execution模式中，只要有一个线程进入临界区，其他线程就无法进入，只能等待。而在Guarded Suspension模式中，线程是否等待取决于守护条件。后者是在前者基础上添加了附加条件而形成的。 Guarded Suspension模式GuardedObject（被守护的对象）GuardedObject角色是一个持有被守护方法的类。当线程执行该守护方法guardedMethod时，如守护条件成立，则可以立即执行；否则就需进行等待。守护条件的成立与否会跟随GuardedObject角色的状态不同而发生变化。除了guardedMethod之外，GuardedObject角色还有可能持有其他改变实例状态的方法stateChangingMethod，特别是改变守护条件。 在Java中，可以使用while语句和wait方法来实现守护方法guardedMethod，而改变实例状态的方法stateChangingMethod可以通过notify/notifyAll来实现。 案例案例中的RequestQueue类扮演GuardedObject守护角色，getRequest方法就是guardedMethod守护方法，putRequest方法就是stateChangingMethod改变实例状态的方法。 Main：一个线程ClientThread将请求Request的实例传递给另一个线程ServerThread。12345public static void main(String[] args) &#123; RequestQueue requestQueue = new RequestQueue(); new ClientThread(requestQueue, \"大泡泡\", 2020).start(); new ServerThread(requestQueue, \"Bubble\", 2020).start(); &#125; 输出： 12345678910大泡泡请求：[Request: No.0]Bubble处理：[Request: No.0]大泡泡请求：[Request: No.1]Bubble处理：[Request: No.1]大泡泡请求：[Request: No.2]Bubble处理：[Request: No.2]大泡泡请求：[Request: No.3]Bubble处理：[Request: No.3]大泡泡请求：[Request: No.4]Bubble处理：[Request: No.4] Request: 1234567891011121314151617181920212223/** * 表示一个请求的类 * * @author wugang * date: 2020-08-17 18:25 **/public class Request &#123; private final String name; public Request(String name) &#123; this.name = name; &#125; public String getName() &#123; return name; &#125; @Override public String toString() &#123; return \"[Request: \" + name + \"]\"; &#125;&#125; RequestQueue: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950/** * 请求存放队列 * * @author wugang * date: 2020-08-17 18:25 **/public class RequestQueue &#123; /** * FIFO队列，存放请求。 * 下面的get和put方法都是用了Synchronized来保护queue字段（LinkedList的实例）， * 保证它是SingleThreadedExecution模式的即getRequest()中的两个处理（前置条件和目标处理）必须同时由一个线程来执行。 * - 判断queue中是痘存在可取的元素； * - 从queue中取出一个元素 */ private final Queue&lt;Request&gt; queue = new LinkedList&lt;&gt;(); /** * 取出并返回最先存放的那个请求。 * 如队列为空，就一直等待，直到唤醒。 * * @return 最先存放的那个请求 */ public synchronized Request getRequest() &#123; // 如队列存在元素，就会返回头元素（不删除）；如为空，则返回null // 也就是Guarded Suspension模式中的守护条件，即目前进行处理的前置条件 while (queue.peek() == null) &#123; try &#123; // 线程要执行某个实例的wait方法时，线程必须获取该实例的锁。 // wait方法被调用时，获取的时this的锁。 // 执行this的wait方法后，线程进入this的等待队列，并释放持有的this锁。 // notify、notifyAll或interrupt会让线程退出等待队列，但在实际地继续执行处理之前，还必须再获取this的锁。 wait(); &#125; catch (InterruptedException ignored) &#123; &#125; &#125; // 移除队列中的第一个元素并返回，如队列为空则抛出NoSuchElementException return queue.remove(); &#125; /** * 添加一个请求到队列 * * @param request 请求 */ public synchronized void putRequest(Request request) &#123; queue.offer(request); notifyAll(); &#125;&#125; ClientThread: 123456789101112131415161718192021222324252627282930/** * 发送请求的类：将请求加入到队列中 * * @author wugang * date: 2020-08-17 18:25 **/public class ClientThread extends Thread &#123; private final Random random; private final RequestQueue queue; public ClientThread(RequestQueue queue, String name, long seed) &#123; super(name); this.queue = queue; this.random = new Random(seed); &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; Request request = new Request(\"No.\" + i); System.out.println(Thread.currentThread().getName() + \"请求：\" + request); queue.putRequest(request); try &#123; TimeUnit.MILLISECONDS.sleep(random.nextInt(1000)); &#125; catch (InterruptedException ignore) &#123; &#125; &#125; &#125;&#125; ServerThread: 1234567891011121314151617181920212223242526272829/** * 接收请求的类 * * @author wugang * date: 2020-08-17 18:26 **/public class ServerThread extends Thread &#123; private final Random random; private final RequestQueue queue; public ServerThread(RequestQueue queue, String name, long seed) &#123; super(name); this.queue = queue; this.random = new Random(seed); &#125; @Override public void run() &#123; for (int i = 0; i &lt; 10000; i++) &#123; Request request = queue.getRequest(); System.out.println(Thread.currentThread().getName() + \"处理：\" + request); try &#123; TimeUnit.MILLISECONDS.sleep(random.nextInt(1000)); &#125; catch (InterruptedException ignore) &#123; &#125; &#125; &#125;&#125; 扩展guarded wait和busy waitguarded waitguarded wait是被守护而等待的意思。 实现方法为：线程使用wait进行等待，被notify或notifyAll后，再次检查条件是否成立。 由于线程在使用wait进行等待期间，是待在等待队列中停止执行的，所以不会浪费Java虚拟机的处理时间。 12345678// 等待端while(!ready) &#123; wait();&#125;// 唤醒端ready = true;notifyAll(); busy waitbusy wait是忙于等待的意思。 实现方法：线程不使用wait进行等待，而是执行yield方法（尽可能将优先级让给其他线程）的同时检查守护条件。 由于等待端的线程也是持续运行的，所以浪费Java虚拟机的时间。 wait是Object类的final方法，而yield是Thread类的静态本地方法。","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://bubblewu.github.io/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://bubblewu.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"DB之Redis","slug":"Redis/DB之Redis","date":"2020-08-11T11:52:19.000Z","updated":"2020-08-11T11:39:35.113Z","comments":true,"path":"ckdpvhqe000000cyd631hfn7f/","link":"","permalink":"https://bubblewu.github.io/ckdpvhqe000000cyd631hfn7f/","excerpt":"本文详细讲解了关于Redis的知识点。","text":"本文详细讲解了关于Redis的知识点。 概述什么是RedisRedis是基于C语言编写的、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。 主要特性整理了Redis的7种特性，有： 速度快：处理速度非常快，每秒能执行约11万集合，每秒约81000+记录。 速度快的原因是： 基于C语言实现，效率高； 数据存储在内存中，读取速度快；（主要） 单线程模型，避免线程上下文切换和竞态消耗； 使用了多路I/O复用模型； 这里“多路”指的是多个网络连接，“复用”指的是复用同一个线程。采用多路 I/O 复用技术可以让单个线程高效的处理多个连接请求（尽量减少网络IO的时间消耗），且Redis在内存中操作数据的速度非常快（内存内的操作不会成为这里的性能瓶颈），主要以上两点造就了Redis具有很高的吞吐量。多路 I/O 复用模型是利用select、poll、epoll可以同时监察多个流的 I/O 事件的能力，在空闲的时候，会把当前线程阻塞掉，当有一个或多个流有I/O事件时，就从阻塞态中唤醒，于是程序就会轮询一遍所有的流（epoll是只轮询那些真正发出了事件的流），并且只依次顺序的处理就绪的流，这种做法就避免了大量的无用操作。 注意： 单线程：Redis内部使用文件事件处理器FileEventHandler，这个处理器是单线程的，所以Redis也被叫做单线程的模型。它采用IO多路复用机制同时监听多个socket，根据socket上的事件来选择对应的事件处理器来进行处理。 非单线程：Redis内部也有许多多线程操作，如fysnc file descriptor和close file descritor操作时会有独立的线程来操作。持久化使用RDB时，手动使用bgsave命令触发时，会调用系统的fork函数创建子进程后台处理。即 Redis 使用操作系统的fork多进程 COW(Copy On Write) 机制来实现快照持久化。持久化AOF时的瘦身操作，fork子线程进行命令合并； 可持久化：支持持久化，即使机器宕机或断电也不会丢失数据。因为数据保存在内存中，对数据的更新将会异步的保存到磁盘上。 主要有三种持久化方式： 快照：一种半持久模式，不时的将数据集以异步的方式从内存以RDB格式写入硬盘； AOF可追加文件：将数据集的修改操作追加记录； 快照和AOF混合使用： 多种数据结构：5种常见的数据结构：字符串（String）、散列哈希（Hash）、列表（List）、集合（Set）和有序集合（Sort Set）。其他的还有位图（BitMaps）、HyperLogLog（超小内存的唯一值计数）、GEO（地理信息定位）。 功能丰富：支持发布订阅、Lua脚本（原子性的操作）、事务、pipeline管道操作； 主从复制：支持主从同步，确保Master和Slave之间的数据同步。可以将数据复制到任意数量的从服务器，而从服务器也是可以关联其他从服务器的主服务器。 由于完全实现了发布订阅机制，使得从Slave在任何地方同步数据时，就可以订阅一个频道并接收Master完整的发布记录。 高可用、分布式、集群模式：支持集群模式，Sentinel哨兵机制支持高可用。 支持多种编程语言，使用简单：如Java、Python等热门语言，都提供了API可以使用。 应用场景缓存系统如JetCache中Local使用Caffeine，Remote使用Redis。 为什么用Redis做缓存？主要是基于高性能和高并发两个方面考虑，才使用缓存。缓存分为本地缓存和远程缓存。本地缓存的特点是轻量且快速，生命周期随着JVM的销毁而结束，如果多实例或多机器的情况下，每个实例或机器都需要保存一份本地缓存，浪费空间而且不具备一致性。远程缓存也可称为分布式缓存，如Redis或MemCached等，使用远程缓存多个实例或机器可共用一份缓存，能够保证一致性，但需要Redis自身保持高可用。 而Redis是单线程的，基于内存的数据库，支持持久化和高可用，数据结构丰富，多用于缓存系统。 Redis与MemCached的区别 Redis支持丰富的数据结构，而MemCached支持简单的String类型（新增了二进制类型）； Redis支持数据持久化，而MemCached是数据全部存在内存中； Redis支持集群模式，而MemCached没有原生集群模式，需要依靠客户端来实现往集群中分片写入数据； Redis使用单线程的IO多路复用模型。MemCached是多线程的，非阻塞IO复用的网络模型。 消息队列系统Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。Redis 客户端可以订阅任意数量的频道。 还可以基于List结构的消息队列：lpush + brpop = message queue 阻塞式先进先出 计数器increment方法实现。 1、计数器：记录用户个人主页的访问量可以使用 123456incr userId:pageView&#96;&#96;&#96;&#96; 单线程无竞争的，来记录每个用户每个页面的访问量- 2、计数器：记录网站每个用户某页的访问量&#96;&#96;&#96;redishincrby user pageView count 排行榜功能有序集合Zset里面的元素是唯一的，有序的，按分数从小到大排序。如： 1zadd key score1 element1 score2 element2 ... score可以为：时间戳、销量、关注人数等 社交网络如社交网络应用中的点赞数、粉丝数、关注数等。可以将点赞用户存在set集合中，scard获取其大小。 实时系统过滤器实现过滤功能，如布隆过滤器。 安装部署四种安装方式具体安装部署方式可参考官网或其他文章，比较简单。 单机模式： 主从模式： Sentinel哨兵模式； Cluster集群模式： 可执行文件基于Redis 5.0.5版本： redis-server 服务器 redis-cli 命令行客户端，连接服务端 redis-benchmark 基准和性能测试 redis-check-aof AOF文件修复工具 redis-check-rdb RDB文件修复工具 redis-sentinel 启动哨兵节点 启动三种启动方式 简单启动：直接执行redis-server (默认ip为127.0.0.1/localhost，port为6379) 动态参数启动： 1redis-server --port 6380 配置文件启动（推荐）： 1redis-server redis.conf 验证123ps -ef | grep redis 查看pid进程；netstat -antp | grep redis 查看端口是否Listening；redis-cli -h ip -p port ping 客户端连接ping测试是否返回PONG 开机启动1systemctl enable redis.service 配置参数线上修改配置如果已经启动服务，修改配置需重启，影响线上服务；可以使用客户端命令修改（不会修改配置文件，临时生效，重启后恢复原样）。如下案例： 123456127.0.0.1:6379&gt; CONFIG GET appendonly1) &quot;appendonly&quot;2) &quot;no&quot;127.0.0.1:6379&gt;127.0.0.1:6379&gt;127.0.0.1:6379&gt; CONFIG SET appendonly yes 配置文件详解基于Redis 5.0.5版本： 网络 Network12345678910111213141516171819202122232425262728################################## NETWORK ###################################### ip绑定，默认127.0.0.1。多个逗号分割# 注意：0.0.0.0 仅在测试环境下，生成环境需绑定具体的ipbind 127.0.0.1# 是否开启保护模式，默认yes。# 要是配置里没有指定bind和密码。开启该参数后，redis只会本地进行访问，拒绝外部访问protected-mode yes# redis对外端口，默认6379，当单机多实例时需指定不同端口port 6379# 确定了TCP连接中已完成队列(完成三次握手之后)的长度。# 当然此值必须不大于Linux系统定义的/proc/sys/net/core/somaxconn值，默认是511，而Linux的默认参数值是128。# 当系统并发量大并且客户端速度缓慢的时候，可以将这二个参数一起参考设定。# 该内核参数默认值一般是128，对于负载很大的服务程序来说大大的不够。一般会将它修改为2048或者更大。# 在/etc/sysctl.conf中添加:net.core.somaxconn = 2048，然后在终端中执行sysctl -p。tcp-backlog 511# 设置客户端空闲超过timeout，服务端会断开连接，为0则服务端不会主动断开连接，不能小于0。timeout 0# 如果设置不为0，就使用配置tcp的SO_KEEPALIVE值。# 使用keepalive有两个好处:# - 检测挂掉的对端。# - 降低中间设备出问题而导致网络看似连接却已经与对端端口的问题。# 在Linux内核中，设置了keepalive，redis会定时给对端发送ack。检测到对端关闭需要两倍的设置值。tcp-keepalive 300 通用配置 Gennral123456789101112131415161718192021222324252627282930313233343536################################# GENERAL ###################################### 是否以守护进程（no/yes）的方式启动，# 默认为no，不是作为守护进程运行的，# 如果你想让它在后台运行，你就把它改成 yes。# 当redis作为守护进程运行的时候，它会写一个 pid 到 /var/run/redis.pid 文件里面daemonize no# 可以通过upstart和systemd管理Redis守护进程：# - supervised no - 没有监督互动；# - supervised upstart - 通过将Redis置于SIGSTOP模式来启动信号；# - supervised systemd - signal systemd将READY = 1写入$ NOTIFY_SOCKET；# - supervised auto - 检测upstart或systemd方法基于 UPSTART_JOB或NOTIFY_SOCKET环境变量；supervised no# 配置PID文件路径，当redis作为守护进程运行的时候，它会把 pid 默认写到 /var/redis/run/redis_6379.pid 文件里面pidfile /var/run/redis_6379.pid# 定义日志级别：# - debug（记录大量日志信息，适用于开发、测试阶段）# - verbose（较多日志信息）# - notice（适量日志信息，使用于生产环境）# - warning（仅有部分重要、关键信息才会被记录）loglevel notice# Redis系统日志，文件名。# 日志文件的位置，当指定为空字符串时，为标准输出；# 如果redis已守护进程模式运行，那么日志将会输出到/dev/nulllogfile \"\"# 设置数据库的数目。默认的数据库是DB 0 。# 可以在每个连接上使用select &lt;dbid&gt; 命令选择一个不同的数据库。databases 16# 是否总是显示logoalways-show-logo yes 快照 SnapShotting123456789101112131415161718192021222324252627282930313233343536################################ SNAPSHOTTING ################################# 存 DB 到磁盘：格式：save &lt;间隔时间（秒）&gt; &lt;写入次数&gt;# 根据给定的时间间隔和写入次数将数据保存到磁盘。# 下面的例子的意思是：# - 900 秒内如果至少有 1 个 key 的值变化，则保存# - 300 秒内如果至少有 10 个 key 的值变化，则保存# - 60 秒内如果至少有 10000 个 key 的值变化，则保存# 注意：你可以注释掉所有的 save 行来停用保存功能。# 也可以直接一个空字符串来实现停用：save \"\"save 900 1save 300 10save 60 10000# 如果用户开启了RDB快照功能，那么在redis持久化数据到磁盘时如果出现失败，默认情况下，redis会停止接受所有的写请求。# 可以让用户很明确的知道内存中的数据和磁盘上的数据已经存在不一致了。# 如果redis不顾这种不一致，一意孤行的继续接收写请求，就可能会引起一些灾难性的后果。# 如果下一次RDB持久化成功，redis会自动恢复接受写请求。# 如果不在乎这种数据不一致或者有其他的手段发现和控制这种不一致的话，可以关闭这个功能，# 以便在快照写入失败时，也能确保redis继续接受新的写请求。stop-writes-on-bgsave-error yes# 对于存储到磁盘中的快照，可以设置是否进行压缩存储。# 如果是的话，redis会采用LZF算法进行压缩。# 如果你不想消耗CPU来进行压缩的话， 可以设置为关闭此功能，但是存储在磁盘上的快照会比较大rdbcompression yes# 在存储快照后，我们还可以让redis使用CRC64算法来进行数据校验，但是这样做会增加大约10%的性能消耗，# 如果希望获取到最大的性能提升，可以关闭此功能。rdbchecksum yes# 设置快照的文件名dbfilename dump.rdb# Redis工作目录， 设置快照文件的存放路径，这个配置项一定是个目录，而不能是文件名dir ./ 主从复制 Replication123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566################################# REPLICATION ################################## 当设置本机为从服务器时，设置master服务的IP地址及端口，在Redis启动时，它会自动从master进行数据同步# replicaof &lt;masterip&gt; &lt;masterport&gt;# 当master服务设置了密码保护时，从服务器连接master的密码# masterauth &lt;master-password&gt;# 当主从连接中断，或者主从复制建立期间，是否允许从服务器对外提供服务。# 默认为yes,即允许对外提供服务，但有可能读到脏数据。# slave 可能会有两种表现：# 1) 如果为 yes ，slave 仍然会应答客户端请求，但返回的数据可能是过时， 或者数据可能是空的在第一次同步的时候# 2) 如果为 no ，在你执行除了 info he salveof 之外的其他命令时，slave 都将返回一个 \"SYNC with master in progress\" 的错误replica-serve-stale-data yes# 配置一个 slave 实体是否接受写入操作。# 通过写入操作来存储一些短暂的数据对于一个 slave 实例来说可能是有用的，# 因为相对从 master 重新同步数而言，把数据写入到 slave 会更容易被删除。# 但是如果客户端因为一个错误的配置写入，也可能会导致一些问题。# 从 redis 2.6 版起，默认 slaves 都是只读的。replica-read-only yes# 主从数据复制是否使用无硬盘复制功能。即是否使用socket方式复制数据。# 目前redis复制提供两种方式，disk和socket。# 如果新的slave连上来或者重连的slave无法部分同步，就会执行全量同步，master会生成rdb文件。# 有2种方式：# - disk方式是master创建一个新的进程把rdb文件保存到磁盘，再把磁盘上的rdb文件传递给slave。# - socket是master创建一个新的进程，直接把rdb文件以socket的方式发给slave。# disk方式的时候，当一个rdb保存的过程中，多个slave都能共享这个rdb文件。# socket的方式就的一个个slave顺序复制。# 在磁盘速度缓慢，网速快的情况下推荐用socket方式。repl-diskless-sync no# 当使用socket复制数据启用的时候，socket复制的延迟时间，如果设置成0表示禁用，默认值是5s。repl-diskless-sync-delay 5# 从节点根据指定的时间间隔向主节点发起ping请求# repl-ping-replica-period 10# 复制连接超时时间。# 需要注意的是repl-timeout需要设置一个比repl-ping-slave-period更大的值，不然会经常检测到超时# repl-timeout 60# 是否禁止复制tcp链接的tcp nodelay参数，可传递yes或者no。默认是no，即使用tcp nodelay。# 如果master设置了yes来禁止tcp nodelay设置，在把数据复制给slave的时候，会减少包的数量和更小的网络带宽。但是这也可能带来数据的延迟。# 默认我们推荐更小的延迟，但是在数据量传输很大的场景下，建议选择yes。repl-disable-tcp-nodelay no# 复制缓冲区大小， 默认是1mb# 当从节点在一段时间内断开连接时，主节点会收集数据到backlog这个缓冲区，# 因此当一个从节点想要重新连接时，通常不需要完全的重新同步，但是部分的重新同步就足够了，只是通过在断开连接的时候传递数据的一部分。# repl-backlog-size 1mb# 单位s。当主节点不再联系从节点，则释放backlog(内存)# repl-backlog-ttl 3600# 从节点优先级。# 当master不可用，Sentinel会根据slave的优先级选举一个master。# 最低的优先级的slave，当选master。# 而配置成0，永远不会被选举replica-priority 100# 当健康的slave的个数小于N，mater就禁止写入# min-replicas-to-write 3# 延迟小于min-slaves-max-lag秒的slave才认为是健康的slave# min-replicas-max-lag 10 安全 Security12345678910111213################################## SECURITY #################################### requirepass配置可以让用户使用AUTH命令来认证密码，才能使用其他命令。# 这让redis可以使用在不受信任的网络中。为了保持向后的兼容性，可以注释该命令，因为大部分用户也不需要认证。# 使用requirepass的时候需要注意，因为redis太快了，每秒可以认证15w次密码，简单的密码很容易被攻破，所以最好使用一个更复杂的密码。注意只有密码没有用户名。# requirepass foobared# 把危险的命令给修改成其他名称。# 比如CONFIG命令可以重命名为一个很难被猜到的命令，这样用户不能使用，而内部工具还能接着使用。# rename-command CONFIG b840fc02d524045429941cc15f59e41cb7be6c52# 设置成一个空的值，可以禁止一个命令# rename-command CONFIG \"\" 客户端 Clients1234567################################### CLIENTS ##################################### 设置能连上redis的最大客户端连接数量。# 默认是10000个客户端连接。# 由于redis不区分连接是客户端连接还是内部打开文件或者和slave连接等，所以maxclients最小建议设置到32。# 如果超过了maxclients，redis会给新的连接发送max number of clients reached，并关闭连接。# maxclients 10000 内存管理 Memory Management1234567891011121314151617181920212223242526272829############################## MEMORY MANAGEMENT ################################# redis配置的最大内存容量。# 当内存满了，需要配合maxmemory-policy策略进行处理。# 注意slave的输出缓冲区是不计算在maxmemory内的。# 所以为了防止主机内存使用完，建议设置的maxmemory需要更小一些。# maxmemory &lt;bytes&gt;# 驱逐策略：内存容量超过maxmemory后的处理策略。# LRU算法只是预测最近被访问的数据将来最有可能被访问到。我们可以转变思路，采用一种LFU(Least Frequently Used)算法，也就是最频繁被访问的数据将来最有可能被访问到。# - volatile-lru：利用LRU算法移除设置过过期时间的key。## LRU是Least Recently Used的缩写，即最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。# - volatile-random：随机移除设置过过期时间的key。# - volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL）# - allkeys-lru：利用LRU算法移除任何key。# - allkeys-random：随机移除任何key。# - noeviction：不移除任何key，只是返回一个写错误。# - volatile-lfu：从已经设置过期时间的数据中，挑选最不经常使用的数据淘汰。# - allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。# maxmemory-policy noeviction# lru检测的样本数。# 使用lru或者ttl淘汰算法，从需要淘汰的列表中随机选择sample个key，选出闲置时间最长的key移除。# maxmemory-samples 5# 从 Redis 5 开始，默认情况下，replica 节点会忽略 maxmemory 设置（除非在发生 failover 后，此节点被提升为 master 节点）。# 这意味着只有 master 才会执行过期删除策略，并且 master 在删除键之后会对 replica 发送 DEL 命令。# replica-ignore-maxmemory yes 惰性/异步删除 LazyFree123456789101112131415############################# LAZY FREEING ##################################### Redis 有两种方式删除键。# - 一种是使用如 DEL 这样的命令进行的同步删除。# 同步删除意味着删除过程中服务端会停止处理新进来的命令。# 若要删除的 key 关联了一个小的 object 删除耗时会很短。# 若要删除的 key 管理了一个很大的 object，比如此对象有上百万个元素，服务端会阻塞相同长一段时间（甚至超过一秒）。# - Redis 5.0.5 同时提供了一种非阻塞的方式用于删除。# 比如 UNLINK（非阻塞的 DEL）以及用于 FLUSHALL 和 FLUSHDB 的 ASYNC 选项，这些命令能在后台回收内存。# 这些命令能在常数时间内执行完毕。其他线程会在后台尽快回收内存。lazyfree-lazy-eviction nolazyfree-lazy-expire nolazyfree-lazy-server-del noreplica-lazy-flush no AOF持久化 Append Only Mode123456789101112131415161718192021222324252627282930313233343536373839404142############################## APPEND ONLY MODE ################################ 默认redis使用的是rdb方式持久化，这种方式在许多应用中已经足够用了。# 但是redis如果中途宕机，会导致可能有几分钟的数据丢失。# Append Only File是另一种持久化方式，可以提供更好的持久化特性。# Redis会把每次写入的数据在接收后都写入 appendonly.aof 文件，每次启动时Redis都会先把这个文件的数据读入内存里，先忽略RDB文件。# 禁用了appendonly功能，这样的风险是一旦redis实例crash，重启后只能恢复到最近1次快照(即bgsave产生的rdb文件)，可能会丢失很长时间的数据。# appendonly可以实现准实时刷盘，默认每1s将数据追加到磁盘文件，也可以配置成每次修改都刷盘，当redis crash时最大限度的保证数据完整性。appendonly no# The name of the append only file (default: \"appendonly.aof\")appendfilename \"appendonly.aof\"# aof持久化策略的配置：# - no表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。# - always表示每次写入都执行fsync，以保证数据同步到磁盘。# - everysec表示每秒执行一次fsync，可能会导致丢失这1s数据# appendfsync alwaysappendfsync everysec# appendfsync no# 在aof重写或者写入rdb文件的时候，会执行大量IO，此时对于everysec和always的aof模式来说，执行fsync会造成阻塞过长时间。# 设置为yes表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，# 默认为no，建议yes。Linux的默认fsync策略是30秒。可能丢失30秒数据。# 如果对延迟要求很高的应用，这个字段可以设置为yes，否则还是设置为no，这样对持久化特性来说这是更安全的选择。no-appendfsync-on-rewrite no# aof自动重写配置。# 当目前aof文件大小超过上一次重写的aof文件大小的百分之多少进行重写。# 即当aof文件增长到一定大小的时候Redis能够调用bgrewriteaof对日志文件进行重写。# 当前AOF文件大小是上次日志重写得到AOF文件大小的二倍（设置为100）时，自动启动新的日志重写过程。auto-aof-rewrite-percentage 100# 设置允许重写的最小aof文件大小，避免了达到约定百分比但尺寸仍然很小的情况还要重写auto-aof-rewrite-min-size 64mb# 是否redis在启动时可以加载被截断的AOF文件aof-load-truncated yes# 混合持久化：RDB快照和AOF。# 具体参考内部原理中的持久化之混合持久化aof-use-rdb-preamble yes Lua脚本 LUA SCRIPTING12345################################ LUA SCRIPTING ################################ 设置lua脚本的最大运行时间,单位为毫秒# 如果此值设置为0或负数，则既不会有报错也不会有时间限制。lua-time-limit 5000 集群 Redis Cluster1234567891011121314151617181920212223242526272829303132################################ REDIS CLUSTER ################################ 集群开关，默认是注释掉掉，不开启集群模式# cluster-enabled yes# 集群配置文件的名称，每个节点都有一个集群相关的配置文件，持久化保存集群的信息。# 这个文件并不需要手动配置，这个配置文件有Redis生成并更新，每个Redis集群节点需要一个单独的配置文件，请确保与实例运行的系统中配置文件名称不冲突# cluster-config-file nodes-6379.conf# 节点互连超时的阀值，集群节点超时毫秒数# cluster-node-timeout 15000# 在进行故障转移的时候，全部slave都会请求申请为master，但是有些slave可能与master断开连接一段时间了，导致数据过于陈旧，这样的slave不应该被提升为master。# 该参数就是用来判断slave节点与master断线的时间是否过长。# 判断方法是：# 比较slave断开连接的时间和(node-timeout * slave-validity-factor) + repl-ping-slave-period# 如果节点超时时间为三十秒, 并且slave-validity-factor为10,# 假设默认的repl-ping-slave-period是10秒，即如果超过310秒slave将不会尝试进行故障转移# cluster-replica-validity-factor 10# master的slave数量大于该值，slave才能迁移到其他孤立master上。# 如这个参数若被设为2，那么只有当一个主节点拥有2 个可工作的从节点时，它的一个从节点会尝试迁移。# cluster-migration-barrier 1# 默认情况下，集群全部的slot由节点负责，集群状态才为ok，才能提供服务。 # 设置为no，可以在slot没有全部分配的时候提供服务。 # 不建议打开该配置，这样会造成分区的时候，小分区的master一直在接受写请求，而造成很长时间数据不一致# cluster-require-full-coverage yes# 控制 master 发生故障时是否自动进行 failover。# 当设置为 yes 后 master 发生故障时不会自动进行 failover，这时你可以进行手动的 failover 操作。# cluster-replica-no-failover no 慢查询 SlowLog123456789101112################################## SLOW LOG #################################### （慢查询就是在日志中记录运行比较慢的SQL语句）# slog log是用来记录redis运行中执行比较慢的命令耗时。# 当命令的执行超过了指定时间，就记录在slow log中，slog log保存在内存中，所以没有IO操作。# 执行时间比slowlog-log-slower-than大的请求记录到slowlog里面，单位是微秒，所以1000000就是1秒。# 注意，负数时间会禁用慢查询日志，而0则会强制记录所有命令。slowlog-log-slower-than 10000# 慢查询日志长度。当一个新的命令被写进日志的时候，最老的那个记录会被删掉，这个长度没有限制。 # 只要有足够的内存就行，你可以通过 SLOWLOG RESET 来释放内存slowlog-max-len 128 延迟监控 Latency Monitor123456################################ LATENCY MONITOR ############################### 用来监控redis中执行比较缓慢的一些操作，用LATENCY打印redis实例在跑命令时的耗时图表。只记录大于等于下边设置的值的操作。# 0的话，就是关闭监视。# 默认延迟监控功能是关闭的，如果你需要打开，也可以通过CONFIG SET命令动态设置。latency-monitor-threshold 0 订阅通知 Event Notification1234567891011121314151617181920212223242526272829303132############################# EVENT NOTIFICATION ############################### Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。# Redis 客户端可以订阅任意数量的频道。# 因为开启键空间通知功能需要消耗一些 CPU，所以在默认配置下，该功能处于关闭状态。# &gt; 注意：因为 Redis 目前的订阅与发布功能采取的是发送即忘（fire and forget）策略，所以如果你的程序需要可靠事件通知（reliable notification of events），# &gt; 么目前的键空间通知可能并不适合你：当订阅事件的客户端断线时，它会丢失所有在断线期间分发给它的事件。# 对于每个修改数据库的操作，键空间通知都会发送两种不同类型的事件：键空间通知（key-space）和键事件通知（key-event）。# &gt; 当 del mykey 命令执行时：# &gt; - 键空间频道的订阅者将接收到被执行的事件的名字，在这个例子中，就是 del# &gt; - 键事件频道的订阅者将接收到被执行事件的键的名字，在这个例子中，就是 mykey# 参数可以是以下字符的任意组合， 它指定了服务器该发送哪些类型的通知。# 输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何通知被分发。# - K： 键空间通知，所有通知以 __keyspace@__ 为前缀# - E： 键事件通知，所有通知以 __keyevent@__ 为前缀# - g： DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知# - $： 字符串命令的通知# - l： 列表命令的通知# - s： 集合命令的通知# - h： 哈希命令的通知# - z： 有序集合命令的通知# - x： 过期事件：每当有过期键被删除时发送# - e： 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送# - A： 参数 g$lshzxe 的别名# 可参考：[Redis事件通知](https://www.cnblogs.com/tangxuliang/p/10659439.html)# 如： notify-keyspace-events \"Ex\" 表示对过期事件进行通知发送；# notify-keyspace-events \"kx\" 表示想监控某个 key 的失效事件。# 将参数设为字符串 AKE 表示发送所有类型的通知。notify-keyspace-events \"\" 高级配置 Advance Config123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143############################# EVENT NOTIFICATION ############################### Redis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。# Redis 客户端可以订阅任意数量的频道。# 因为开启键空间通知功能需要消耗一些 CPU，所以在默认配置下，该功能处于关闭状态。# &gt; 注意：因为 Redis 目前的订阅与发布功能采取的是发送即忘（fire and forget）策略，所以如果你的程序需要可靠事件通知（reliable notification of events），# &gt; 么目前的键空间通知可能并不适合你：当订阅事件的客户端断线时，它会丢失所有在断线期间分发给它的事件。# 对于每个修改数据库的操作，键空间通知都会发送两种不同类型的事件：键空间通知（key-space）和键事件通知（key-event）。# &gt; 当 del mykey 命令执行时：# &gt; - 键空间频道的订阅者将接收到被执行的事件的名字，在这个例子中，就是 del# &gt; - 键事件频道的订阅者将接收到被执行事件的键的名字，在这个例子中，就是 mykey# 参数可以是以下字符的任意组合， 它指定了服务器该发送哪些类型的通知。# 输入的参数中至少要有一个 K 或者 E，否则的话，不管其余的参数是什么，都不会有任何通知被分发。# - K： 键空间通知，所有通知以 __keyspace@__ 为前缀# - E： 键事件通知，所有通知以 __keyevent@__ 为前缀# - g： DEL 、 EXPIRE 、 RENAME 等类型无关的通用命令的通知# - $： 字符串命令的通知# - l： 列表命令的通知# - s： 集合命令的通知# - h： 哈希命令的通知# - z： 有序集合命令的通知# - x： 过期事件：每当有过期键被删除时发送# - e： 驱逐(evict)事件：每当有键因为 maxmemory 政策而被删除时发送# - A： 参数 g$lshzxe 的别名# 可参考：[Redis事件通知](https://www.cnblogs.com/tangxuliang/p/10659439.html)# 如： notify-keyspace-events \"Ex\" 表示对过期事件进行通知发送；# notify-keyspace-events \"kx\" 表示想监控某个 key 的失效事件。# 将参数设为字符串 AKE 表示发送所有类型的通知。notify-keyspace-events \"\"############################### ADVANCED CONFIG ################################ 数据量小于等于hash-max-ziplist-entries的用ziplist，大于hash-max-ziplist-entries用hash# hash类型的数据结构在编码上可以使用ziplist和hashtable。# ziplist的特点就是文件存储(以及内存存储)所需的空间较小,在内容较小时,性能和hashtable几乎一样。# 因此redis对hash类型默认采取ziplist。如果hash中条目的条目个数或者value长度达到阀值,将会被重构为hashtable。# 这个参数指的是ziplist中允许存储的最大条目个数，默认为512，建议为128hash-max-ziplist-entries 512 # ziplist中允许条目value值最大字节数，默认为64，建议为1024hash-max-ziplist-value 64# 当取正值的时候，表示按照数据项个数来限定每个quicklist节点上的ziplist长度。# 比如，当这个参数配置成5的时候，表示每个quicklist节点的ziplist最多包含5个数据项。# 当取负值的时候，表示按照占用字节数来限定每个quicklist节点上的ziplist长度。这时，它只能取-1到-5这五个值，每个值含义如下：# -5: 每个quicklist节点上的ziplist大小不能超过64 Kb。（注：1kb =&gt; 1024 bytes）# -4: 每个quicklist节点上的ziplist大小不能超过32 Kb。# -3: 每个quicklist节点上的ziplist大小不能超过16 Kb。# -2: 每个quicklist节点上的ziplist大小不能超过8 Kb。（-2是Redis给出的默认值）# -1: 每个quicklist节点上的ziplist大小不能超过4 Kb。list-max-ziplist-size -2# 表示一个quicklist两端不被压缩的节点个数。# 注：这里的节点个数是指quicklist双向链表的节点个数，而不是指ziplist里面的数据项个数。# 实际上，一个quicklist节点上的ziplist，如果被压缩，就是整体被压缩的。# 参数list-compress-depth的取值含义如下：# 0: 是个特殊值，表示都不压缩。这是Redis的默认值。# 1: 表示quicklist两端各有1个节点不压缩，中间的节点压缩。# 2: 表示quicklist两端各有2个节点不压缩，中间的节点压缩。# 3: 表示quicklist两端各有3个节点不压缩，中间的节点压缩。# 依此类推…# 由于0是个特殊值，很容易看出quicklist的头节点和尾节点总是不被压缩的，以便于在表的两端进行快速存取。list-compress-depth 0 # 数据量小于等于set-max-intset-entries用intset，大于set-max-intset-entries用setset-max-intset-entries 512 # 数据量小于等于zset-max-ziplist-entries用ziplist，大于zset-max-ziplist-entries用zsetzset-max-ziplist-entries 128zset-max-ziplist-value 64# value大小小于等于hll-sparse-max-bytes使用稀疏数据结构（sparse）# 大于hll-sparse-max-bytes使用稠密的数据结构（dense），一个比16000大的value是几乎没用的，# 建议的value大概为3000。如果对CPU要求不高，对空间要求较高的，建议设置到10000左右hll-sparse-max-bytes 3000# Streams macro node max size / items. The stream data structure is a radix# tree of big nodes that encode multiple items inside. Using this configuration# it is possible to configure how big a single node can be in bytes, and the# maximum number of items it may contain before switching to a new node when# appending new stream entries. If any of the following settings are set to# zero, the limit is ignored, so for instance it is possible to set just a# max entires limit by setting max-bytes to 0 and max-entries to the desired# value.stream-node-max-bytes 4096stream-node-max-entries 100# Redis将在每100毫秒时使用1毫秒的CPU时间来对redis的hash表进行重新hash，可以降低内存的使用。# 当你的使用场景中，有非常严格的实时性需要，不能够接受Redis时不时的对请求有2毫秒的延迟的话，把这项配置为no。# 如果没有这么严格的实时性要求，可以设置为yes，以便能够尽可能快的释放内存activerehashing yes# 对客户端输出缓冲进行限制可以强迫那些不从服务器读取数据的客户端断开连接，用来强制关闭传输缓慢的客户端。# 对于normal client，第一个0表示取消hard limit，第二个0和第三个0表示取消soft limit，normal client默认取消限制，因为如果没有寻问，他们是不会接收数据的# 对于slave client和MONITER client，如果client-output-buffer一旦超过256mb，又或者超过64mb持续60秒，那么服务器就会立即断开客户端连接。 # 对于pubsub client，如果client-output-buffer一旦超过32mb，又或者超过8mb持续60秒，那么服务器就会立即断开客户端连接。client-output-buffer-limit normal 0 0 0client-output-buffer-limit replica 256mb 64mb 60client-output-buffer-limit pubsub 32mb 8mb 60# Client query buffers accumulate new commands. They are limited to a fixed# amount by default in order to avoid that a protocol desynchronization (for# instance due to a bug in the client) will lead to unbound memory usage in# the query buffer. However you can configure it here if you have very special# needs, such us huge multi/exec requests or alike.## client-query-buffer-limit 1gb# In the Redis protocol, bulk requests, that are, elements representing single# strings, are normally limited ot 512 mb. However you can change this limit# here.## proto-max-bulk-len 512mb# redis执行任务的频率为1s除以hzhz 10# 可选值为yes和no，分别代表开启动态hz和关闭动态hz。默认值为yes。# 当动态hz开启时，您设置的hz参数的值，即configured_hz，将作为基线值，# 而Redis服务中的实际hz值会在基线值的基础上根据已连接到Redis的客户端数量自动调整，# 连接的客户端越多，实际hz值越高，Redis执行定期任务的频率就越高。dynamic-hz yes# 在aof重写的时候，如果打开了aof-rewrite-incremental-fsync开关，系统会每32MB执行一次fsync。# 这对于把文件写入磁盘是有帮助的，可以避免过大的延迟峰值aof-rewrite-incremental-fsync yes# RDB自动触发策略是否启用，默认为yes# RDB手动触发和自动触发：# 1）自动触发：# 如上面配置所示，按配置情况触发# 2）手动触发：# 连接redis后使用命令save、bgsave触发# - save：会阻塞redis服务器，直到完成持久化# - bgsave：会fork一个子进程，由子进程进行持久化。rdb-save-incremental-fsync yes# 可以调整计数器counter的增长速度，lfu-log-factor越大，counter增长的越慢。# lfu-log-factor 10# 是一个以分钟为单位的数值，可以调整counter的减少速度# lfu-decay-time 1 API相关通用命令除了Keys命令的时间复杂度为O(n)，其他都为O(1)。 keys pattern 列出符合pattern的key因为它是一个O(n)的操作且是单线程操作会阻塞其他命令。一般不在生产环境使用。 建议使用方案： 可以在热本从节点时，在从节点执行比较重的命令； 用scan命令：以非阻塞的方式实现key值的查找，绝大多数情况下是可以替代keys命令的，可选性更强 SCAN cursor [MATCH pattern] [COUNT count]是一个基于游标的迭代器，count默认为10。这意味着命令每次被调用都需要使用上一次这个调用返回的游标作为该次调用的游标参数，以此来延续之前的迭代过程。 scan 参数提供了三个参数： 第一个是 cursor 整数值； 第二个是 key 的正则模式； 第三个是遍历的 limit hint。 第一次遍历时，cursor 值为 0，然后将返回结果中第一个整数值作为下一次遍历的 cursor。一直遍历到返回的 cursor 值为 0 时结束。 dbsize 返回当前数据库的 key 的数量可以线上使用，因为redis有计数器会实时记录key的总数，时间复杂度为O(1) exists key 是否存在key，存在1 不存在0 del key... 删除key，可以多个 expire key seconds 过期时间设置，key在n秒后过期 ttl key 查看key剩余的过期时间，返回负数-2说明key已经被删除 persist key 去掉key的过期时间，这时在执行ttl会返回-1，说明key存在，并没有过期时间 type key 返回 key 所储存的值的类型一般为string、hash、list、set、zset、none（key不存在） select db 选择db，共16个db，默认0 MOVE key db 将当前数据库的 key 移动到给定的数据库 db 当中。 RENAME key newkey 修改 key 的名称 RENAMENX key newkey 仅当 newkey 不存在时，将 key 改名为 newkey 。 数据结构5种常见类型String：字符串类型结构：key value。Value的类型可以为字符、数值型、二进制、Json串。 注意：字符串类型的Value的大小不能大于512M； 内部编码 int： 8个字节的长整型。 如果一个字符串的内容可以转换为long，那么该字符串就会被转换成long类型，对象的ptr就会指向该long，并且对象类型也用int类型表示； embstr： 小于等于39个字节的字符串。如果字符串对象的长度小于39字节，就用embstr对象，否则使用传统的raw对象。 raw： 大于39个字节的字符串。 常见命令 get key O(1)操作 del key O(1)操作 set操作：O(1)操作set key value 不管key是否存在都设置setnx key value 当key不存在才设置set key value XX key存在才设置SETEX key seconds value 将值 value 关联到 key ，并将 key 的生存时间设为 seconds (以秒为单位)。如果 key 已经存在， SETEX命令将覆写旧值。PSETEX key milliseconds value 这个命令和 SETEX命令相似，但它以毫秒为单位设置 key 的生存时间，而不是像 SETEX命令那样，以秒为单位。set key value [expiration EX seconds|PX milliseconds] [NX|XX] EX seconds ： 将键的过期时间设置为 seconds 秒。执行 SET key value EX seconds 的效果等同于执行 SETEX key seconds value。 PX milliseconds ： 将键的过期时间设置为 milliseconds 毫秒。执行 SET key value PX milliseconds 的效果等同于执行 PSETEX key milliseconds value 。 NX ： 只在键不存在时， 才对键进行设置操作。执行 SET key value NX 的效果等同于执行 SETNX key value XX ： 只在键已经存在时， 才对键进行设置操作。 批量操作：O(n)操作mget key1 key2 ...批量获取key，原子操作。 n次get = n次网络时间 + n次命令时间（一般是网络时间比较耗时） mset key1 v1 key2 v2 ...批量设置key。 1次mget = 1次网络时间 + n次命令时间 MSETNX key value [key value ...]同时设置一个或多个 key-value 对，当且仅当所有给定 key 都不存在。即使只有一个给定 key 已存在， MSETNX也会拒绝执行所有给定 key 的设置操作。 O(N)操作， N 为要设置的 key 的数量。 当所有 key 都成功设置，返回 1 。如果所有给定 key 都设置失败(至少有一个 key 已经存在)，那么返回 0 。 自增/减命令incr keyO(1)操作。计数，key自增1，如key不存在，自增后get(key)=1decr keyO(1)操作。key自减1，如key不存在，自减后get(key)=-1incrby key kO(1)操作。key自增k，如key不存在，自增后get(key)=kdecr key kO(1)操作。key自减k，如key不存在，自减后get(key)=-k 其他操作：getset key newValueO(1)操作，设置key的新值，返回旧值。append key valueO(1)操作，将value追加到旧的value。strlen keyO(1)操作，返回字符串的长度。incrbyfloat key 3.5O(1)操作，增加key对应的值为3.5getrange key start endO(1)操作，获取字符串下指定下标的值setrange key index valueO(1)操作，设置指定下标所对应的值。 应用1、计数器：记录用户个人主页的访问量 可以使用 incr userId:pageView （单线程无竞争的），来记录每个用户每个页面的访问量 Hash：哈希类型结构：key field value。即类似于Map结构。 内部编码 ziplist压缩链表：当元素个数小于512 , 并且值的大小小于64个字节时 , 采用ziplist。 当哈希类型中元素个数小于 hash-max-ziplist-entries 配置(默认 512 个)，同时所有值都小于 hash-max-ziplist-value 配置(默认 64 字节)时，Redis 会使用 ziplist 作为哈希的内部实现。 ziplist是一种压缩链表，它的好处是更能节省内存空间。因为它所存储的内容都是在连续的内存区域当中的。当列表对象元素不大，每个元素也不大的时候，就采用ziplist存储。但当数据量过大时就ziplist就不是那么好用了。因为为了保证他存储内容在内存中的连续性，插入的复杂度是O(N)，即每次插入都会重新进行realloc。 ziplist最大的优势就是存储的时候是连续的内存，可以极大的提升cpu的缓存命中率。 hashtable哈希表：当元素个数小于512 , 并且值的大小小于64个字节时 , 采用ziplist , 大于的时候采用hashtable。 常见命令 常用命令：O(1) 123456789hget key field 获取hashkey对应的field的valuehset key field valuehdel key fieldhexists key fieldhlen key 获取hash key的field的数量hsetnx key field value 不存在设置，否则失败hincrby key field intCounterhincrbyfloat key field floatCounter 批量操作：O(n) 12hmget key1 field1 field2...hmset key field1 value1 field2 value2... 其他：O(n) 123hgetall key 返回key下所有的field和value。由于单线程，要小心使用此命令，尽量用hmget代替hkeys key 返回key对应的所有field的fieldhvals key 返回key对应的所有field的value 应用 1、计数器：记录网站每个用户某页的访问量1hincrby user:info pageView count 2、缓存：缓存视频的基本信息 List：列表类型结构：key elements。有序的（插入顺序）、可重复的、可以左右两边插入弹出的。 内部编码 linklist双向链表： linkedlist是一种双向链表。它的结构比较简单，节点中存放pre和next两个指针，还有节点相关的信息。当每增加一个node的时候，就需要重新malloc一块内存。 ziplist 压缩列表： 常见命令 增： 12345678rpush key value1 value2 ...O(1~n)，从列表的右端插入lpush key value1 value2 ...O(1~n)，从列表的左端插入linsert key before|after value newValueO(n)，在list指定的value之前或后插入newValue 删： 1234567891011121314151617lpop keyO(1)，从左弹出list中的一个元素rpop keyO(1)，从右弹出list中的一个元素lrem key count valueO(n)，根据count值，从list中删除所有等于value的元素count &gt; 0：从左到右，删除最多count个。count &lt; 0：从右到左，删除最多Math.abs(count)个。count &#x3D; 0：删除所有满足条件的元素。ltrim key start endO(n)，按照索引位置修剪list。保留范围內的元素blpop key timeout 和brpop key timeout O(1)，阻塞删除，timeout是阻塞超时时间，为0表示永远不阻塞 改： 12lset key index newValueO(n)，修改指定位置的值为newValue 查： 1234567891011lrange key start end （包含end）O(n)，获取列表指定索引范围的元素。如：list有6个元素。索引从左：0～5；索引从右：-1～-6；lindex key indexO(n)，获取列表指定索引的元素llen keyO(1)，获取list长度 应用 1、微博时间轴TimeLine：将关注用户的微博由新到旧排列。关注的人更新微博，使用lpush左侧即头部插入；使用lrang可以分页查询； 2、实现栈：lpush + lpop = stack 先进后出 3、实现队列：lpush + rpop = queue 先进先出 4、实现有固定数量的列表：lpush + ltrim = capped collection 5、消息队列：lpush + brpop = message queue 阻塞式先进先出 Set：集合类型结构：key values。元素是无序的、无重复元素、支持集合间的操作，如交/并/差集， 内部编码 intset：intset是一个整数集合，里面存的为某种同一类型的整数。 123#define INTSET_ENC_INT16 (sizeof(int16_t)) #define INTSET_ENC_INT32 (sizeof(int32_t)) #define INTSET_ENC_INT64 (sizeof(int64_t)) 当集合中的元素都是整数，并且集合中的元素个数小于 512 个时，Redis 会选用 intset 作为底层内部实现。 intset是一个有序集合，查找元素的复杂度为O(logN)，但插入时不一定为O(logN)，因为有可能涉及到升级操作。比如当集合里全是int16_t型的整数，这时要插入一个int32_t，那么为了维持集合中数据类型的一致，那么所有的数据都会被转换成int32_t类型，涉及到内存的重新分配，这时插入的复杂度就为O(N)了。但是intset不支持降级操作。 hashtable 哈希表： 常见命令 集合内操作：123456789101112131415161718192021sadd elementO(1)，添加元素，如存在则失败srem key elementO(1) 删除scard key计算集合大小sismember key value判断vlaue是否在key中srandmember key count随机挑count个元素。不会破坏集合的数据spop key从集合中随机弹出一个元素smembers key获取集合所有元素，返回结果无序会造成阻塞，需注意使用，建议使用游标scan 集合间操作：12345sdiff key1 key2 求差集sinter key1 key2 求交集sunion key1 key2 求并集sdiff&#x2F;sinter&#x2F;suion + store destkey将差&#x2F;交&#x2F;并集结果保存到destkey中 应用 1、微博抽奖系统：使用spop或srandmember随机选择一个或多个用户 2、微博点赞、转发等：将点赞用户存在集合中，scard获取其大小 3、标签：给用户添加标签/给标签添加用户 4、共同关注/共同好友等功能：求交集 ZSet：有序集合类型结构：key score value。无重复元素、有序的、有元素+分值构成。时间复杂度比集合类型有所增大。 内部编码 ziplist 压缩列表： skiplist 跳表： 它实现了有序集合中的快速查找，在大多数情况下它的速度都可以和平衡树差不多。但它的实现比较简单，可以作为平衡树的替代品。可参考：随机数据结构：跳表（SkipList） 常见命令 基本操作： 1234567891011121314151617zadd key score1 element1 score2 element2 ...O(logN)，添加score和elementzrem key elementO(1) 删除zscore key elementO(1) 返回元素scorezincrby key incrScore elementO(1)，增加或减少元素的scorezcard keyO(1) 返回key中元素个数zrank key element获取某元素的排名（升序 从小到大） 范围操作： 1234567891011121314151617181920zrange key start end [withscores]返回指定索引范围的升序元素，是否打印分数可选复杂度为O(log(n) + m) ：n指有序集合中元素的个数；m指获取范围内的元素个数zrangebyscore key minScore maxCore [withscores]O(log(n) + m) ，指定分数范围，其余和上面zrange一样zcount key minScore maxScoreO(log(n) + m) ，指定分数范围的个数zremrangebyrank key start endO(log(n) + m) ，删除指定排名內的升序元素zremrangebyscore key start endzremrangebyscore key minScore maxScorezrevrank&#x2F;zrevrange&#x2F;zrevrangebyscore排名从高到低 集合操作： 12zinterstore&#x2F;zunionstore集合间操作，交集&#x2F;并集 应用1、排行榜实现：zadd key score1 element1 score2 element2 ...score可以为：时间戳、销量、关注人数等 高级功能慢查询 SlowLog概念慢查询顾名思义是将redis执行命令较慢的命令记录到慢查询队列中。慢查询是一个先进先出的队列，且队列是固定长度的，保存在内存中的。 生命周期Redis命令执行的完整生命周期： 1client发送命令 -&gt; Redis队列命令排队（单线程） -&gt; 执行命令 -&gt; 返回结果到client 慢查询发生在第3个阶段（执行命令）；客户端超时不一定慢查询，但慢查询是客户端超时的一个可能因素。 两个配置和三个命令两个配置 slowlog-log-slower-than 10000sloglog是用来记录redis运行中执行比较慢的命令耗时。当命令的执行超过了指定时间，就记录在slowlog中（单位是微秒，所以1000000就是1秒），slowlog保存在内存中，所以没有IO操作。 注意：负数时间会禁用慢查询日志，而0则会强制记录所有命令。 slowlog-max-len 128慢查询队列长度(记录多少条慢查询，默认128)一个新的命令满足慢查询条件时被插入到这个列表中。当慢查询日志列表已处于其最大长度时,最早插入的一个命令将从列表中移出。 三个命令 slowlog get [n]获取慢查询日志，参数n可以指定条数返回结果有6个部分组成：1、慢查询日志的唯一ID2、发生的时间戳3、命令耗时，单位微秒4、执行的命令和参数5、客户端网络套接字(ip: port)6、“” slowlog len查询当前慢查询记录数 slowlog reset重置慢查询日志 (实际是对列表做清理操作) 运维经验 slowlog-max-len不要设置太小，通常1000左右。线上建议调大。因为记录慢查询时Redis会对长命令做阶段操作，并不会占用大量内存，增大慢查询列表可以减缓慢查询被剔除的可能。 slowlog-log-slower-than不要设置太大，通常1000微秒（即1ms），根据时间QPS设置。默认值超过10毫秒判定为慢查询，需要根据Redis并发量调整该值。 由于Redis采用单线程响应命令，对于高流量的场景，如果命令执行时间超过1毫秒以上，那么Redis最多可支撑QPS不到1000因此对于高QPS场景下的Redis建议设置为1毫秒。如：qps为10000的话，平均每个时间就为0.1ms，如超过1ms就会对qps造成影响，这样调小阈值慢查询才会被记录下来。 注意Redis命令的生命周期。慢查询只记录命令的执行时间，并不包括命令排队和网络传输时间。因此客户端执行命令的时间会大于命令的实际执行时间，因为命令执行排队机制，慢查询会导致其他命令级联阻塞。因此客户端出现请求超时时，需要检查该时间点是否有对应的慢查询，从而分析是否为慢查询导致的命令级联阻塞。 定期持久化慢查询。由于慢查询日志是一个先进先出的队列，也就是说如果慢查询比较多，队列满的情况下，可能会丢失部分慢查询命令。为了防止这种情况发生，可以定期执行slowlog get命令将慢查询日志持久化到其他存储中(例如:MySQL、ElasticSearch等)，然后可以通过可视化工具进行查询。 管道 Pipelinepipeline，即流水线。1次pipeline（N条命令）= 1次网络时间 + N次命令时间。对于多个命令执行，不再同步等待每个命令的返回结果。我们会在一个统一的时间点来获取结果。 123456789101112131415public static void main(String[] args) &#123; Jedis jedis = new Jedis(\"localhost\", 6379); for (int i = 0; i &lt; 100; i++) &#123; Pipeline pipeline = jedis.pipelined(); for (int j = i * 100; j &lt; (i + 1) * 100; j++) &#123; pipeline.hset(\"hashKey\", \"field-\" + j, \"value-\" + i); &#125; // pipeline.sync() 表示一次性的异步发生，不关注执行结果 // pipeline.syncAndReturnAll() 程序会阻塞，等所有命令完成之后，返回一个list // pipeline不适合组装特别多的命令，要进行命令的拆分 List&lt;Object&gt; list = pipeline.syncAndReturnAll(); List&lt;String&gt; setList = list.stream().map(Object::toString).collect(Collectors.toList());; System.out.println(String.join(\",\", setList)); &#125;&#125; 优点 提高redis的读写能力。 Redis其实是一个基于TCP协议的CS架构的内存数据库，所有的操作都是一个request一个response的同步操作。redis每接收到一个命令就会处理一个命令，并同步返回结果。这样带来的问题就是，一个命令就会产生一次RTT（Round Time Trip，往返时间），这样的话必然会消耗大量的网络IO。 redis客户端执行一条命令分4个过程：发送命令－〉命令排队－〉命令执行－〉返回结果。这个过程称为RTT。mget和mset批量操作，有效节约了RTT，但大部分命令（如hgetall，并没有mhgetall）不支持批量操作，需要消耗N次RTT ，这个时候需要pipeline来解决这个问题 需注意 Redis命令时间是微秒级别的，无瓶颈，也就是pipeline解决了Redis网络的瓶颈。 pipeline中每条命令要注意网络消耗 使用pipeline组装的命令个数不能太多，不然数据量过大，增加客户端的等待时间，还可能造成网络阻塞，可以将大量命令的拆分多个小的pipeline命令完成。 pipeline每次只能作用在一个Redis节点； 与M操作（批处理）对比： 原生批命令操作是原子的（一批命令 要么成功要么失败）。pipeline是非原子的，会将其中命令进行拆分的，但返回的结果是顺序的。 原生批命令一命令多个key, 但pipeline支持多命令（存在事务），非原子性； 原生批命令是服务端实现，而pipeline需要服务端与客户端共同完成。 发布订阅 Pub/SubRedis 发布订阅(pub/sub)是一种消息通信模式：发送者(pub)发送消息，订阅者(sub)接收消息。Redis 客户端可以订阅任意数量的频道。 角色 发布者：Publisher基于客户端实现。 注意：无法做消息堆积，即获取历史信息。 如Pub发布了一条消息到Channel，新的Sub去订阅该Channel，是收不到之前的消息的。 订阅者：Subscribe基于客户端实现，可订阅多个频道。 频道：Channel基于Server段实现。 API123456789101112131415161718publish channel message指定频道发布消息，返回订阅者数量subscribe channel ...可订阅一个或多个频道unsubscribe channel ...取消订阅一个或多个由于Redis的订阅操作是阻塞式的，因此一旦客户端订阅了某个频道或模式，就将会一直处于订阅状态直到退出。在SUBSCRIBE，PSUBSCRIBE，UNSUBSCRIBE和PUNSUBSCRIBE命令中，其返回值都包含了该客户端当前订阅的频道和模式的数量，当这个数量变为0时，该客户端会自动退出订阅状态。psubscribe&#x2F;punsubscribe pattern ...模式匹配。订阅&#x2F;退订一个或多个符合给定模式的频道。pubsub numsub channel ...返回指定channel的订阅数量pubsub numpat列出被订阅模式的数量 对其他消息队列发布订阅的对比： 其他MQ提供持久化功能，但Redis无法对消息持久化存储，一旦消息被发送，如果没有订阅者接收，那么消息就会丢失； 其他MQ提供了消息传输保障，当客户端连接超时或事务回滚等情况发生时，消息会被重新发送给客户端，Redis没有提供消息传输保障。 其他MQ支持多种消息协议。 位图 BitMap概念8bit = 1b = 0.001kb，bitmap就是通过最小的单位 bit来进行0或者1的设置，表示某个元素对应的值或者状态。 一个bit的值，只能是0或1；也就是说一个bit能存储的最多信息是2。位数组是自动扩展的，如设置在某个offset超出来现有范围，就会自动将位数组进行0扩充。 位图并不是一种特殊的数据结构，其实本质上是二进制字符串，也就是byte数组。 可以使用普通的 get/set 直接获取和设置整个位图的内容；也可以使用位图操作 getbit/setbit 等将 byte 数组看成「位数组」来处理。 Bitmaps 并不是实际的数据类型，而是定义在String类型上的一个面向字节操作的集合。因为字符串是二进制安全的块，他们的最大长度是512M，最适合设置成2^32个不同字节。 优势 基于最小的单位bit进行存储，所以非常省空间。 设置时候时间复杂度O(1)、读取时候时间复杂度O(n)，操作是非常快的 二进制数据的存储，进行相关计算的时候非常快 byte二进制数组方便扩容 限制redis中BitMap被限制在512MB之内，所以最大是2^32位。建议每个key的位数都控制下，因为读取时候时间复杂度O(n)，越大的串读的时间花销越多。 常用命令API getbit key offset获取位图指定索引的值。长度超过补为0。 12345678910111213127.0.0.1:6379&gt; set hello redisOK127.0.0.1:6379&gt;127.0.0.1:6379&gt; getbit hello 0(integer) 0127.0.0.1:6379&gt; getbit hello 1(integer) 1127.0.0.1:6379&gt; getbit hello 2(integer) 1127.0.0.1:6379&gt; getbit hello 3(integer) 1127.0.0.1:6379&gt; getbit hello 4(integer) 0 setbit key offset value给位图指定索引设置值，返回该索引位置的原始值 123456789127.0.0.1:6379&gt; get hello&quot;redis&quot;127.0.0.1:6379&gt; getbit hello 3(integer) 1127.0.0.1:6379&gt; setbit hello 3 0(integer) 1127.0.0.1:6379&gt; get hello&quot;bedis&quot;127.0.0.1:6379&gt; bitcount key [start end]获取位图指定范围（start到end，单位为字节，如果不指定就是获取全部）位值为1的个数。 1234127.0.0.1:6379&gt; get hello&quot;bedis&quot;127.0.0.1:6379&gt; bitcount hello(integer) 19 bitpos key targetBit [start] [end]计算位图指定范围（start到end，单位为字节，如果不指定就是获取全部）第一个偏移量对应的值等于targetBit的位置。查找指定范围内出现的第一个0或1。 bitop and|or|not|xor destkey key [key...]做多个bitmap的and（交集）、or（并集）、not（非）、xor（异或）操作并将结果保存到destkey中。 12345678127.0.0.1:6379&gt; set hello bigOK127.0.0.1:6379&gt; set world bigOK127.0.0.1:6379&gt; bitop and destkey hello world(integer) 3127.0.0.1:6379&gt; get destkey&quot;big&quot; bitfield命令已支持的命令列表： 12345- 支持的命令：GET &lt;type&gt; &lt;offset&gt; – 返回指定的位域 - SET &lt;type&gt; &lt;offset&gt; &lt;value&gt; – 设置指定位域的值并返回它的原值 - INCRBY &lt;type&gt; &lt;offset&gt; &lt;increment&gt; – 自增或自减（如果increment为负数）指定位域的值并返回它的新值还有一个命令通过设置溢出行为来改变调用INCRBY指令的后序操作：- OVERFLOW [WRAP|SAT|FAIL] 示例：当需要一个整型时，有符号整型需在位数前加i，无符号在位数前加u。 1234567891011127.0.0.1:6379&gt; get w&quot;hello&quot;127.0.0.1:6379&gt;127.0.0.1:6379&gt; BITFIELD w get u4 01) (integer) 6127.0.0.1:6379&gt; BITFIELD w get u3 21) (integer) 5127.0.0.1:6379&gt; BITFIELD w get i4 01) (integer) 6127.0.0.1:6379&gt; BITFIELD w get i3 21) (integer) -3 setbit和getbit指定的值都是单个位的，如果指定多个位，就需要pipeline来处理。但使用bitfield可以对指定位片段进行读写，但最多只能处理64个连续但位。如超过需使用多个子指令，bitfield可以一次执行多个子指令。 123456一次执行多个子指令：127.0.0.1:6379&gt; BITFIELD w get u4 0 get u3 2 get i4 0 get i3 21) (integer) 62) (integer) 53) (integer) 64) (integer) -3 incrby，它用来对指定范围的位进行自增操作。既然提到自增，就有可能出现溢出。如果增加了正数，会出现上溢，如果增加的是负数，就会出现下溢出。Redis 默认的处理是折返。如果出现了溢出，就将溢出的符号位丢掉。如果是 8 位无符号数 255， 加 1 后就会溢出，会全部变零。如果是 8 位有符号数 127，加 1 后就会溢出变成 -128。 溢出策略：bitfield 指令提供了溢出策略子指令 overflow，用户可以选择溢出行为。默认是折返 (wrap)，还可以选择失败 (fail) 报错不执行，以及饱和截断 (sat)，超过了范围就停留在最大 最小值。overflow 指令只影响接下来的第一条指令，这条指令执行完后溢出策略会变成默认 值折返 (wrap)。 应用 1、UV 独立用户统计：使用set和Bitmap（前提是用户的ID必须是整型）场景一：总共1亿用户，五千万独立用户。 使用Set： 每个userId占用空间：32位(假设userId用的是integer) ； 需要存储的用户量：50,000,000； 内存使用总量：32位 * 50,000,000=200MB使用BItMap： 每个userId占用空间：1位； 需要存储的用户量：100,000,000； 内存使用总量：1位 * 100,000,000=12.5MB 场景二：总共1亿用户，若只有10万独立用户 使用Set 每个userId占用空间：32位(假设userId用的是integer) ； 需要存储的用户量：100,000； 内存使用总量：32位 * 100,000=4MB使用BItMap： 每个userId占用空间：1位； 需要存储的用户量：100,000,000； 内存使用总量：1位 * 100,000,000=12.5MB 2、用户签到数据记录： 1setbit key offset value key主要由用户id组成，设定一个初始时间，每加一天即对应用户的offset的加1。value=1为已签到取数据时，只需要计算时间段差的天数，然后 1bitcount key [start end] 3、用户在线状态：判断某用户是否在线？ 1setbit key offset value 只需要一个key，然后用户id为偏移量offset，如果在线就设置为1，不在线就设置为0。3亿用户只需要大约36.6MB的空间：1位 * 3亿=3亿位/8/1000/1024=36.6M 4、统计活跃用户：setbit key offset value 使用时间作为key，用户id为offset，如果当日活跃过就设置为1。通过bitop and|or|not|xor destkey key [key...]进行二进制计算，就可以算出在某段时间内用户的活跃情况。 注意 string类型最大长度为512M。 注意setbit时的偏移量，当偏移量很大时，可能会有较大耗时。 位图不是绝对的好，有时可能更浪费空间。（如UV统计时的第二种情况）。 HyperLogLog 基数统计概念HyperLogLog 是用来做基数统计的算法。基数统计即统计一个数据集中不重复元素的个数。 提供不精确的去重计数方案，标准误差（即均方根误差，RMSE，Root mean squared error）为0.81% API命令12345678PFADD key element [element ...]添加指定元素到 HyperLogLog 中。PFCOUNT key [key ...]返回给定 HyperLogLog 的基数估算值。PFMERGE destkey sourcekey [sourcekey ...]将多个 HyperLogLog 合并为一个 HyperLogLog 优缺点优点： 在输入元素的数量或者体积非常非常大时，计算基数所需的空间总是固定的、并且是很小的。 每个HyperLogLog 键只需要花费12KB内存，就可以计算接近 2^64 个不同元素的基数。这和计算基数时，元素越多耗费内存就越多的集合形成鲜明对比。 缺点： HyperLogLog 只会根据输入元素来计算基数，而不会储存输入元素本身，所以 HyperLogLog 不能像集合那样，返回输入的各个元素。 HLL这个数据结构需要占据一定12k的存储空间，不适合统计单个用户相关的数据。 为什么占用12K？因为Redis的HLL实现中用到了16384（2^14）个桶，每个桶的maxBits需要6个bits来存储，最大可以表示为maxBits=63。于是总内存为：16384 * 6 / 8 / 1024 = 12k字节 优化Redis对HLL做了优化： 在计数比较小时，存储空间采用稀疏矩阵存储，占用空间小； 计数变大时，稀疏矩阵占用空间超过阈值时，会一次性转变为稠密矩阵，才会占用12K的空间。 稀疏矩阵：在矩阵中，若数值为0的元素数目远远多于非0元素的数目时，则称该矩阵为稀疏矩阵。 只存储在矩阵中极少数的非零元素，为此必须对每一个非零元素，保存它的下标和值。可以采用一个三元Trituple&lt;row,column,value&gt;来唯一地确定一个矩阵元素。因此，稀疏矩阵需要使用一个三元组数组(亦称为三元组表)来表示。 稠密矩阵：与之相反，若非0元素数目占大多数时，则称该矩阵为稠密矩阵。 应用 1、用户的UV独立访问统计12345678910111213127.0.0.1:6379&gt; PFADD uv 1 2 3 4 3 4 2 1(integer) 1127.0.0.1:6379&gt; PFCOUNT uv(integer) 4127.0.0.1:6379&gt; PFADD uv_2 7 8 9 8 7 9(integer) 1127.0.0.1:6379&gt; PFCOUNT uv_2(integer) 3127.0.0.1:6379&gt; PFMERGE result uv uv_2OK127.0.0.1:6379&gt; PFCOUNT result(integer) 7127.0.0.1:6379&gt; GEO 地理位置信息GEO 地理信息定位：存储经纬度、计算两地距离、范围计算等。 原理业界比较通用的地理位置距离排序算法是 GeoHash 算法 GeoHash算法：GeoHash 算法将二维的经纬度数据映射到一维的整数，这样所有的元素都将在挂载到一条线上，距离靠近的二维坐标映射到一维后的点之间距离也会很接近。当我们想要计算「附近的人时」，首先将目标位置映射到这条线上，然后在这个一维的线上获取附近的点就行 了。 映射算法实现： 1、它将整个地球看成一个二维平面，然后划分成了一系列正方形的方格，就好比围棋棋盘，所有的地图元素坐标都将放置于唯一的方格中。方格越小，坐标越精确。 2、然后对这些方格进行整数编码，越是靠近的方格编码越是接近。 最简单的方案就是切蛋糕法：设想一个正方形的蛋糕摆在你面前，二刀下去均分 分成四块小正方形，这四个小正方形可以分别标记为 00,01,10,11 四个二进制整数。然后对每一个小正方形继续用二刀法切割一下，这时每个小小正方形就可以使用 4bit 的二进制整数予以表示。然后继续切去，正方形就会越来越小，二进制整数也会越来越长，精确度就会越来越高。 3、编码之后，每个地图元素的坐标都将变成一个整数，通过这个整数可以还原出元素的坐标，整数越长，还原出来的坐标值的损失程度就越小。 4、GeoHash算法会继续对这个整数做一次 base32编码 (0-9,a-z去掉 a,i,l,o 四个字母) 变成一个字符串。 在Redis里面，经纬度使用52位的整数进行编码，放进了zset里面，zset的 value 是元素的 key，score 是 GeoHash 的 52 位整数值。 5、在使用 Redis 进行 Geo 查询时，它的内部结构实际上只是一个zset(skiplist)。通过 zset 的 score 排序就可以得到坐标附近的其它元素 ，通过将 score 还原成坐标值就可以得到元素的原始坐标。 API命令 geoadd key longitude latitude member [longitude latitude member...]将给定的空间元素(纬度、经度、名字)添加到指定的键里面。 这些数据会以有序集合的形式被储存在键里面，从而使得georadius和georadiusbymember这样的命令可以在之后通过位置查询取得这些元素。geoadd命令以标准的x,y格式接受参数,所以用户必须先输入经度,然后再输入纬度。geoadd能够记录的坐标是有限的：非常接近两极的区域无法被索引的精确的坐标限制由EPSG:900913 / EPSG:3785 / OSGEO:41001 等坐标系统定义， 具体如下 有效的经度介于-180-180度之间 有效的纬度介于-85.05112878 度至 85.05112878 度之间。当用户尝试输入一个超出范围的经度或者纬度时，geoadd命令将返回一个错误。 12127.0.0.1:6379&gt; GEOADD cities:locations 116.28 39.55 beijing(integer) 1 geopos key member [member...]从键里面返回所有给定位置元素的位置(经度和纬度) geopos命令返回一个数组。数组中的每个项都由两个元素组成：第一个元素为给定位置元素的经度,而第二个元素则为给定位置元素的纬度。当给定的位置元素不存在时,对应的数组项为空值. 1234567127.0.0.1:6379&gt; geopos cities:locations tianjin shijiazhuang1) 1) &quot;117.12000042200088501&quot; 2) &quot;39.0800000535766543&quot;2) 1) &quot;114.29000169038772583&quot; 2) &quot;38.01999994251037407&quot;127.0.0.1:6379&gt; geopos cities:locations nanjing1) (nil) geodist key member1 member2 [unit]计算出的距离会以双精度浮点数的形式被返回。如果给定的位置元素不存在,那么命令返回空值。 指定单位的参数unit必须是以下单位的其中一个：m表示单位为米km表示单位为千米mi表示单位为英里ft表示单位为英尺如果用户没有显式地指定单位参数,那么geodist默认使用米作为单位。geodist命令在计算距离时会假设地球为完美的球形,在极限情况下,这一假设最大会造成0.5%的误差。 123456127.0.0.1:6379&gt; geodist cities:locations tianjin shijiazhuang&quot;272929.6477&quot;127.0.0.1:6379&gt; geodist cities:locations tianjin shijiazhuang km&quot;272.9296&quot;127.0.0.1:6379&gt; geodist cities:locations tianjin nanjing km(nil) georadius key longitude latitude radius m|km|ft|mi [withcoord][withdist][withhash][asc|desc][count count]以给定的经纬度为中心,返回键包含的位置元素当中,与中心的距离不超过给定最大距离的所有位置元素。 范围可以使用以下其中一个单位：m 表示单位为米。km 表示单位为千米。mi 表示单位为英里。ft 表示单位为英尺。withdist:在返回位置元素的同时,将位置元素与中心之间的距离也一并返回.距离的单位和用户给定的范围单位保持一致。withcoord:将位置元素的经度和纬度也一并返回。withhash:以52位有符号整数的形式,返回位置元素经过原始geohash编码的有序集合分值。这个选项主要用于底层应用或者调试,实际中的作用不大。命令默认返回未排序的位置元素。通过以下两个参数,用户可以指定被返回位置元素的排序方式： asc:根据中心的位置,按照从近到远的方式返回位置元素desc:根据中心的位置,按照从远到近的方式返回位置元素。 在默认情况下,georadius命令会返回所有匹配的位置元。虽然用户可以使用count选项去获取N个匹配元素,但是因为命令在内部可能会需要对所有被匹配的元素进行处理,所以在对一个非常大的区域进行搜索时,即使只使用count选项去获取少量元素， 123456789127.0.0.1:6379&gt; georadius cities:locations 117 39 200 km withdist1) 1) &quot;baoding&quot; 2) &quot;158.0144&quot;2) 1) &quot;beijing&quot; 2) &quot;87.0941&quot;3) 1) &quot;tianjin&quot; 2) &quot;13.6619&quot;4) 1) &quot;tangshan&quot; 2) &quot;96.7842&quot; georadiusbymember key member radius m|km|ft|mi [withcoord][withdist][withhash][asc|desc][count count]和georadius命令一样,都可以找出位于指定范围内的元素,但是georadiusbymember的中心点是由给定的位置元素决定的。而不是像georadius那样,使用输入的经度和纬度来决定中心点。 1234567127.0.0.1:6379&gt; georadiusbymember cities:locations tianjin 100 km1) &quot;beijing&quot;2) &quot;tianjin&quot;3) &quot;tangshan&quot;127.0.0.1:6379&gt; georadiusbymember cities:locations beijing 100 km1) &quot;beijing&quot;2) &quot;tianjin&quot; geohash key member [member...]使用geohash将二维经纬度转换为一维字符串，字符串越长表示位置更精确,两个字符串越相似表示距离越近。 123456127.0.0.1:6379&gt; geohash cities:locations tangshan baoding1) &quot;wx5bj2um070&quot;2) &quot;wwcgp6x9580&quot;127.0.0.1:6379&gt; geohash cities:locations beijing tianjin1) &quot;wx48ypbe2q0&quot;2) &quot;wwgq34k1tb0&quot; zremGEO没有提供删除成员的命令，但是因为GEO的底层实现是zset，所以可以借用zrem命令实现对地理位置信息的删除. 1zrem cities:locations tianjin 应用 1、查看附近的人、餐厅、公司等12georadiusbymember company huoli 20 km count 3 asc范围 20 公里以内最多 3 个元素按距离正排，它不会排除自身 事务 Transaction MULTI标记一个事务块的开始。事务块内的多条命令会按照先后顺序被放进一个队列当中，最后由 EXEC命令原子性(atomic)地执行。O(1)操作； EXEC执行所有事务块内的命令。假如某个(或某些) key 正处于 WATCH命令的监视之下，且事务块中有和这个(或这些) key 相关的命令，那么 EXEC命令只在这个(或这些) key 没有被其他命令所改动的情况下执行并生效，否则该事务被打断(abort)。时间复杂度：事务块内所有命令的时间复杂度的总和。返回：事务块内所有命令的返回值，按命令执行的先后顺序排列。当操作被打断时，返回空值 nil DISCARD取消事务，放弃执行事务块内的所有命令。如果正在使用 WATCH命令监视某个(或某些) key，那么取消所有监视，等同于执行命令 UNWATCHO(1)操作，总是返回ok WATCH key [key ...]监视一个(或多个) key ，如果在事务执行之前这个(或这些) key 被其他命令所改动，那么事务将被打断。O(1)操作 UNWATCH取消 WATCH命令对所有 key 的监视。如果在执行 WATCH命令之后， EXEC命令或DISCARD命令先被执行了的话，那么就不需要再执行 UNWATH了。 因为 EXEC命令会执行事务，因此 WATCH命令的效果已经产生了；而 DISCARD命令在取消事务的同时也会取消所有对 key 的监视，因此这两个命令执行之后，就没有必要执行 UNWATCH了。 内部原理持久化概述Redis 的数据全部在内存里，如果突然宕机，数据就会全部丢失，因此必须有一种机制 来保证 Redis 的数据不会因为故障而丢失，这种机制就是 Redis 的持久化机制。 持久化就是：redis将所有的数据保存在内存中，对数据的更新它会异步地保存到磁盘上。 主流数据库的持久化方式： 快照：如：MySQL的Dump、Redis的RDB 写日志：如：MySQL的Binlog、Hbase的HLog、Redis的AOF日志两者区别： 1、快照是一次全量备份，AOF 日志是连续的增量备份； 2、快照是内存数据的二进制序列化形式，在存储上非常紧凑，而 AOF 日志记录的是内存数据修改的指令记录文本； 3、AOF 日志在长期的运行过程中会 变的无比庞大，数据库重启时需要加载 AOF 日志进行指令重放，这个时间就会无比漫长。所以需要定期进行 AOF 重写，给 AOF 日志进行瘦身。 三种方式RDB快照RDB快照，也就是定时快照（snapshot），是存储在硬盘中的二进制文件，是一个复制媒介用于一次全量备份。RDB快照持久化，也就是是将redis数据库某个时点的数据信息以快照文件的形式保存到磁盘的持久化方法。 主要思想：RDB方式实际就是在Redis内部存在一个定时器机制，扫描进程按照配置文件中的要求去检查数据的变化情况，即根据指定时间内的数据变化次数决定是否进行持久化。当达到持久化的触发条件时，操作系统会单独创建（fork）一个子进程来进行数据持久化的操作，子进程默认与父进程有共同的地址空间，这样子进程就可以遍历整个内存来进行存储操作，主进程此时仍然可以正常提高服务，只是不进行I/O操作，有写入请求时，由操作系统按照内存页（Page）为单位进行写时复制Copy-on-Write，从而保证主进程的高效性能。 子进程数据写入时是将数据先写入一个临时文件中，当整个数据写入完毕后，才会用临时文件覆盖上一个持久化好的快照文件，这样保证了系统可以随时的进行数据备份，数据文件总是可用的。 由上可知：RDB模式的持久化，数据的完整性没有保障。 触发复制的三种方式： 手动触发：save一个同步的命令：O(n)操作该指令会阻塞当前 Redis 服务器，执行 save 指令期间，Redis 不能处理其他命令，直到 RDB 过程完成为止。如存在老的RDB文件，会新建一个临时文件，执行完毕后替换老文件，再删除老文件。bgsave 一个异步命令：O(n)操作。执行该命令时，Redis 会在后台异步执行快照操作，此时 Redis 仍然可以相应客户端请求。如存在老的RDB文件，会新建一个临时文件，执行完毕后替换老文件。 具体操作是Redis进程执行linux的fork函数 操作创建子进程，RDB持久化过程由子进程负责，完成后自动结束。Redis 只会在 fork 期间发生阻塞，但是一般时间都很短。但是如果 Redis 数据量特别大，fork 时间就会变长，而且占用内存会加倍，这一点需要特别注意。 自动触发：（redis.conf 配置）参考：配置中的持久化模块可以设置指定时间内key的变化数量来自动触发。 其他触发机制：（不可忽视）全量复制：涉及到主从复制，在没有触发手动和自动的时候，主从复制时（全量复制），主会生成rdb文件。debug reload操作：进行debug级别的重启，也会生成rdb文件。命令 shutdown [nosave|save]：关闭服务指定save时，也会生成 Shutdown 命令执行以下操作： 停止所有客户端 如果有至少一个保存点在等待，执行 SAVE 命令 如果 AOF 选项被打开，更新 AOF 文件 关闭 redis 服务器(server) 原理 背景：单线程同时在服务线上的请求还要进行文件 IO 操作，文件IO操作会严重拖垮服务器请求的性能。 Redis 是单线程程序，这个线程要同时负责多个客户端套接字的并发读写操作和内存数据结构的逻辑读写。在服务线上请求的同时，Redis还需要进行内存快照，内存快照要求 Redis 必须进行文件IO操作，可文件 IO 操作是不能使用多路复用API。 COW 写时复制（copy-on-write）为了不阻塞线上的业务，就需要边持久化边响应客户端请求。持久化的同时，内存数据结构还在改变： 比如一个大型的 hash 字典正在持久化，结果一个请求过来把它给删掉了，还没持久化完呢，这要怎么办? 所以，Redis 使用操作系统的fork多进程 COW(Copy On Write) 机制来实现快照持久化。 大多数操作系统都采用写时复制（copy-on-write）来优化子进程的使用效率。 实现原理： fork是类Unix操作系统上创建进程的主要方法。fork用于创建子进程(等同于当前进程的副本)。新的进程要通过老的进程复制自身得到，这就是fork！ fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份。 优点：1、COW技术可减少分配和复制大量资源时带来的瞬间延时。2、可减少不必要的资源分配。比如fork进程时，并不是所有的页面都需要复制，父进程的代码段和只读数据段都不被允许修改，所以无需复制。 缺点：1、如果在fork()之后，父子进程都还需要继续进行写操作，那么会产生大量的分页错误(页异常中断page-fault)，这样就得不偿失。 fork多进程操作： Redis 在持久化时会调用 glibc 的函数 fork 产生一个子进程，快照持久化完全交给子进程来处理，父进程继续处理客户端请求。 子进程刚刚产生时，它和父进程共享内存里面的代码段和数据段。 进程分离的逻辑：fork 函数会在父子进程同时返回，在父进程里返回子进程的pid，在子进程里返回零。如果操作系统内存资源不足，pid 就会是负数，表示 fork 失败。 子进程做数据持久化，它不会修改现有的内存数据结构，它只是对数据结构进行遍历读取，然后序列化写到磁盘中。但是父进程不一样，它必须持续服务客户端请求，然后对内存数据结构进行不间断的修改。 这个时候就会使用操作系统的COW机制（写时复制, copy-on-write）来进行数据段页面的分离。 数据段是由很多操作系统的页面组合而成，当父进程对其中一个页面的数据进行修改时，会将被共享的页面复制一份分离出来，然后对这个复制的页面进行修改。这时子进程相应的页面是没有变化的，还是进程产生时那一瞬间的数据。随着父进程修改操作的持续进行，越来越多的共享页面被分离出来，内存就会持续增长。但是也不会超过原有数据内存的2倍大小。另外一个 Redis 实例里冷数据占的比例往往是比较高的，所以很少会出现所有的页面都会被分离，被分离的往往只有其中一部分页面。每个页面的大小只有 4K，一个 Redis 实例里面一般都会有成千上万的页面。子进程因为数据没有变化，它能看到的内存里的数据在进程产生的一瞬间就凝固了，再也不会改变，这也是为什么 Redis 的持久化叫「快照」的原因。接下来子进程就可以非常安心的遍历数据了进行序列化写磁盘了。 AOF追写文件AOF 日志是连续的增量备份，记录的是内存数据修改的指令记录文本。就是把执行过的写指令按照执行顺序写在记录文件的尾部，重启时读取文件指令明细按照顺序执行一遍就能完成恢复。 主要思想总结：配置文件redis.conf中的appendonly参数就是控制AOF功能的启动与关闭，yes表示开启，如果在有写操作，指令就会被追加到记录文件的尾部。 AOF默认的存储策略是每秒钟执行一次，术语称之为fsync。 即把缓存中的写指令记录到文件中，这是redis持久化与性能的最佳平衡点，此策略既能保证 redis 有很好的性能表现又能保障数据完整性，最多存在 1 秒钟的数据丢失。 在文件追加过程中，如果发生了意外错误，例如系统宕机等意外状况，导致记录文件写入不完整的缺陷，这种情况下，redis提供了一个叫redis-check-aof 的工具可以对不完整的日志文件进行修复处理。 AOF文件一定会随着数据量变动越来越大，有可能导致日志空间不足等意外风险，为了避免这个低级的错误发生，redis 提供了一个方便实用的自我保护机制-重写（rewrite）机制， 就是管理员预先设定 AOF 文件大小的阈值，当实际大小超过阈值时，redis 就会启动了文件内容压缩，只保留了能保障数据恢复的最小可用的指令集。文件重写功能仍然采用了先创建并写入临时文件，当重写过程结束后，才更名及覆盖上一个可用的 aof 文件模式来保障备份文件的随时可用。 AOF 文件本身是可读且可编辑的。 可读可编辑的好处：假设我们在操作 redis 时，不小心执行了 flushall，内存数据全部清空了，但是开启了AOF功能且AOF文件没有被重写的前提下，我们可以暂停 redis 并对aof文件进行编辑，删除文件末尾保存的 flushall 指令，重启 redis，内存数据就能恢复。 RDB快照的问题 1、耗时、耗性能。将内存中的数据dump到硬盘，是一个O(n)过程，比较耗时；bgsave中的fork()：消耗内存，copy-on-write策略硬盘I/O：IO性能问题 2、不可控、容易丢失数据。如该场景：T1时间 执行多个写命令；T2时间 满足RDB自动创建的条件；T3时间 再次执行多个写命令；T4时间 宕机，就会出现数据丢失 原理AOF 日志存储的是 Redis服务器的顺序指令序列，只记录对内存进行修改的指令记录。 假设 AOF 日志记录了自 Redis 实例创建以来所有的修改性指令序列，那么就可以通过 对一个空的 Redis 实例顺序执行所有的指令，也就是「重放」，来恢复 Redis 当前实例的内存数据结构的状态。 Redis 会在收到客户端修改指令后，先进行参数校验，如果没问题，就立即将该指令文本存储到 AOF 日志中，也就是先存到磁盘，然后再执行指令。这样即使遇到突发宕机，已经存储到 AOF 日志的指令进行重放一下就可以恢复到宕机前的状态。 Redis 在长期运行的过程中，AOF 的日志会越变越长。如果实例宕机重启，重放整个 AOF 日志会非常耗时，导致长时间 Redis 无法对外提供服务。所以需要对 AOF 日志瘦身。 AOF重写（提高效率）Redis 提供了 bgrewriteaof 指令用于对 AOF 日志进行瘦身。日志瘦身：对执行的命令进行合并，如String类型多次赋值只保留最后一次，多次操作改为批量命令操作等。 其原理就是：对redis内存中的内容进行回溯，回溯成aof文件。fork开辟一个子进程对内存进行遍历转换成一系列 Redis 的操作指令，序列化到一个新的 AOF 日志文件中。序列化完毕后再将操作期间发生的增量 AOF 日志追加到这个新的 AOF 日志文件中，追加完毕后就立即替代旧的 AOF 日志文件了，瘦身工作就完成了。 AOF重写配置：12345auto-aof-rewrite-min-size 64mbAOF文件重写需要的尺寸auto-aof-rewrite-percentage 100AOF文件增长率 fsync操作（宕机AOF丢失数据问题）AOF 日志是以文件的形式存在的，当程序对 AOF 日志文件进行写操作时，实际上是将内容写到了硬盘的缓冲区（内核为文件描述符分配的一个内存缓存中），然后内核会异步将脏数据刷回到磁盘的。这就意味着如果机器突然宕机，AOF 日志内容可能还没有来得及完全刷到磁盘中，这个 时候就会出现日志丢失。那该怎么办? Linux 的 glibc 提供了 fsync(int fd)函数可以将指定文件的内容强制从内核缓存刷到磁 盘。只要 Redis 进程实时调用 fsync 函数就可以保证 aof 日志不丢失。但是 fsync 是一个磁盘IO操作，它很慢。如果 Redis 执行一条指令就要 fsync 一次，那么 Redis 高性能的地位就不保了。 所以在生产环境的服务器中，Redis 通常是每隔 1s 左右执行一次 fsync 操作，周期 1s 是可以配置的。这是在数据安全性和性能之间做了一个折中，在保持高性能的同时，尽可能使得数据少丢失。 Redis 同样也提供了另外两种策略：一个是永不 fsync，让操作系统来决定合适同步磁 盘，很不安全；另一个是来一个指令就 fsync 一次，非常慢。 三种配置策略：具体参考：aof持久化策略的配置123no 表示不执行fsync，由操作系统保证数据同步到磁盘，速度最快。always 表示每次写入都执行fsync，以保证数据同步到磁盘。everysec 表示每秒执行一次fsync，可能会导致丢失这1s数据 混合持久化重启 Redis 时，我们很少使用rdb 来恢复内存状态，因为会丢失大量数据（rdb的缺点）。我们通常使用 AOF 日志重放，但是重放 AOF 日志性能相对 rdb 来说要慢很多，这样在 Redis 实例很大的情况下，启动需要花费很长的时间。Redis 4.0 为了解决这个问题，带来了一个新的持久化选项：混合持久化。 生效的两个配置：12appendonly yesaof-use-rdb-preamble yes 思想：将 rdb 文件的内容和增量的 AOF 日志文件存在一起。这里的 AOF 日志不再是全量的日志，而是自持久化开始到持久化结束的这段时间发生的增量 AOF 日志，通常这部分 AOF 日志很小。于是在Redis重启的时候，可以先加载rdb的内容，然后再重放增量 AOF 日志就可以完全替代之前的 AOF全量文件重放，重启效率因此大幅得到提升。 RDB和AOF对比 rdb持久化：故障数据丢失比aof严重，但是服务重启恢复数据快 aof持久化：故障数据丢失较rdb少，但是服务启动时恢复数据慢，因为要把aof文件中指令执行一遍。 RDB 启动优先级低、体积小、恢复速度快、容易丢数据、比较重的操作；AOF 启动优先级高、体积大、恢复速度慢、丢数据要根据策略决定、比较轻的操作； 运维常见问题 通常 Redis 的主节点是不会进行持久化操作，持久化操作主要在从节点进行。从节点是备份节点，没有来自客户端请求的压力，它的操作系统资源往往比较充沛。 因为： 快照（bgsave）是通过开启子进程的方式进行的，它是一个比较耗资源的操作；遍历整个内存，大块写磁盘会加重系统负载；AOF 的 fsync 是一个耗时的 IO 操作，它会降低 Redis 性能，同时也会增加系统 IO 负担。 但是如果出现网络问题，从节点长期连不上主节点，就会出现数据不一致的问题。特别是在网络分区出现的情况下又不小心主节点宕机了，那么数据就会丢失，所以在生产环境要做好实时监控工作，保证网络畅通或者能快速修复。 还应该再增加一个从节点以降低网络分区的概率，只要有一个从节点数据同步正常，数据也就不会轻易丢失。 子进程开销和优化： CPU：RDB和AOF文件生成，属于CPU密集型;不做CPU绑定，不和CPU密集型部署。 内存：fork内存开销，copy-on-write，即父子进程共享只读分段文件时，父进程某个分段文件发生写入，会将其拷贝出一份新的分段文件，造成内存开销。单机部署时，不允许产生大量重写， 硬盘：AOF和RDB文件写入，可以集合iostat和iotop分析；1、不要和高硬盘负载的服务部署在一起，如：存储服务、消息队列等；2、no-appendfsync-no-rewrite = yes，表示rewrite期间对新写操作不fsync,暂时存在内存中,等rewrite完成后再写入，3、根据写入量决定磁盘类型：如SSD4、单机多实例持久化文件目录可以考虑分盘 主从复制概述Redis数据库在单机时：机器故障问题、容量瓶颈、QPS的瓶颈。 主从复制就是对主节点进行数据备份、读写分离对读进行分流。 可以为数据提供副本，扩展redis的读的性能。 1、一个Master可以有多个Slave；2、一个Slave只能有一个Master；3、数据流向是单向的，Master到Salve；4、默认情况下，Redis都是主节点 主要思想： 从服务器启动并与主服务器成功建立连接后，它会主动发起 SYNC请求，Master 接收到同步请求时会调用 BGSAVE 指令来创建一个专用子进程来完成数据持久化处理。 全量数据持久化处理可以分成两个阶段： 首先，将主服务器的存量数据都写入 RDB 文件，Master 在数据持久化期间产生的增量数据会启动另一个后台存盘进程，把增量的写指令记录全部缓存在内存中，等待存量数据持久化完成后，Master 把 RDB 数据库文件传送给 Slave，Slave 接收到数据库文件后将其存放在磁盘上并逐步完成数据加载，这样存量数据就同步结束了；然后，要进行同步的是持久化期间的增量数据，Master 将所有缓存在内存中的写指令按照约定的 redis 协议格式发给 Slave，Slave 接收后在本地执行这些数据写命令，从而达到最终的数据完全同步。 不论是那一种逻辑结构，Master只会执行一次持久化动作无论有多少个slave有同步请求，然后把持久化好的 RDB 文件分发下去。Redis2.8 的版本提供了数据增量同步策略：Master和Slave如果断开连接，之后又重新连接时。在连接成功后，可以尝试进行增量数据同步。 增量数据同步策略是主服务器会在内存中维护一个缓冲区来存放待同步数据，主从连接成功后，Slave会把“申请同步的主服务器ID”和“请求的数据的偏移量（replication offset）”发送给Master，Master 收到增量同步请求时，根据上送的申请同步的主服务器ID去匹配自己的ID信息，匹配成功后检查自己的缓存区数据是否能满足申请的数据偏移量，如果都两个条件都满足，则能完成master-slave 的增量数据同步。如果runid和本机id不一致或者双方offset差距超过了复制积压缓冲区大小，那么就会返回FULLRESYNC runid offset，Slave将runid保存起来，并进行完整同步。 步骤 1、执行slaveof后，slave只保存master的地址信息，直接返回； 2、主从建立socket连接；slave内部通过每秒执行的定时任务维护复制相关逻辑，当发现新的matser时，尝试建立网络连接，slave会建立一个socket套接字，用于接收master发送的复制命令；如slave无法建立连接，定时任务会一直重连到成功或执行slaveof no one取消复制。 3、发送ping命令：连接成功后slave发送ping请求首次通信，检测MS之间套接字是否可用、是否可接收处理命令；如slave没收到master的pong回复或超时，下次定时任务会重连； 4、权限验证：如Master设置了requirepass参数，需要密码验证。如验证失败复制将终止，slave重新发起复制流程。 5、同步数据集：主从连接正常通信后，如首次建立，master会把持有的数据全部发送给slave。（通过rdb或socket的方式） 6、命令持续复制：当master把数据同步给slave复制流程建立成功后，后面M会持续的把写命令发送给S，保证主从数据一致性。 两种配置1、slaveof命令：异步的操作slave上执行命令slaveof MasterHost 6379来异步复制，slave机器重启就会丢失，不建议。取消复制：slaveof no one 取消时slave不会清除已经同步的数据； slave配置新的Master时，会清除历史数据； 2、配置文件replicaof &lt;masterip&gt; &lt;masterport&gt;对Slave机器，替换为对应的主服务器IP和主服务器的端口号。如果主服务器（redis）有设置密码的话，则需要配置密码masterauth 注意：修改需要重启 全量/部分复制：涉及知识点 1、runid每个Redis服务器都会有一个表明自己身份的ID。在PSYNC中发送的这个ID是指之前连接的Master的ID，如果没保存这个ID，PSYNC的命令会使用PSYNC ? -1 这种形式发送给Master，表示需要全量复制。 2、复制偏移量offset：通过对比主从节点的复制偏移量，可以判断主从节点数据是否一致。在主从复制的Master和Slave双方都会各自维持一个offset。Master成功发送N个字节的命令后会将Master的offset加上N，Slave在接收到N个字节命令后同样会将Slave的offset增加N。Master和Slave如果状态是一致的那么它的的offset也应该是一致的。 3、复制积压缓冲区backlog：当从节点在一段时间内断开连接时，主节点会收集数据到backlog这个缓冲区。因此当一个从节点想要重新连接时，通常不需要完全的重新同步，但是部分的重新同步就足够了，只是通过在断开连接的时候传递数据的一部分。 是由Master维护的一个固定长度的FIFO队列，默认大小为1M。它的作用是缓存已经传播出去的命令。当Master进行命令传播时，不仅将命令发送给所有Slave，还会将命令写入到复制积压缓冲区里面。因此当一个slave想要重新连接时，如runingid与M一致且偏移量与M相差没超过缓冲区大小，通常不需要完全的重新同步，增量同步缓冲区的命令就足够了。 4、psync命令：从节点使用psync命令完成部分复制和全量复制功能。 PSYNC执行过程中比较重要的概念有3个：runid、offset（复制偏移量）以及复制积压缓冲区。 1、客户端向服务器发送SLAVEOF命令，让当前服务器成为Slave； 2、 当前服务器根据自己是否保存Master runid来判断是否是第一次复制，如果是第一次同步则跳转到3，否则跳转到4； 3、 向Master发送PSYNC ? -1 命令来进行完整同步； 4、 向Master发送PSYNC runid offset； 5、 Master接收到PSYNC 命令后首先判断runid是否和本机的id一致，如果一致则会再次判断offset偏移量和本机的偏移量相差有没有超过复制积压缓冲区大小，如果没有那么就给Slave发送CONTINUE，此时Slave只需要等待Master传回失去连接期间丢失的命令； 6、 如果runid和本机id不一致或者双方offset差距超过了复制积压缓冲区大小，那么就会返回FULLRESYNC runid offset，Slave将runid保存起来，并进行完整同步。 全量复制一般用于初次复制场景，Redis早期支持的复制功能只有全量复制。它会把主节点全部数据一次性发送给从节点。当数据量较大时，会对主从节点和网络造成很大的开销。 1、发送psync命令进行数据同步，由于是第一次进行复制，从节点没有复制偏移量和主节点的运行ID，所以发送psync-1； 2、主节点根据psync-1解析出当前为全量复制，回复+FULLRESYNC响应； 3、从节点接收主节点的响应数据保存运行ID和偏移量offset； 4、主节点执行bgsave异步快照命令，保存RDB文件到本地； 5、主节点发送RDB给从节点，从节点把接收的RDB文件保存在本地并直接作为从节点的数据文件,接收完RDB后从节点打印相关日志； 6、对于从节点开始接收RDB快照到接收完成期间，主节点仍然响应读写命令。因此主节点会把这期间写命令数据保存在复制客户端缓冲区内，当从节点加载完RDB文件后，主节点再把缓冲区内的数据发送个从节点，保证主从之间数据一致性；全量复制注意： 如果主节点创建和传输RDB的时间过长，对于高流量写入场景非常容易造成主节点复制客户端缓冲区溢出。client-output-buffer-limit replica 256mb 64mb 60 如果60秒内缓冲区消耗持续大于64MB或者直接超过256MB时，主节点将直接关闭复制客户端连接，造成全量同步失败；对于主节点，当发送完所有的数据后就认为全量复制完成； 7、从节点接收完主节点传送来的全部数据后会清空自身旧数据； 8、从节点清空数据后开始加载RDB文件，对于较大的RDB文件，这一步操作依然比较耗时，可以通过计算日志之间的时间差来判断加载RDB的总耗时； 9、从节点成功加载完RDB后，如果当前节点开启了AOF持久化功能，它会立刻做bgrewriteaof AOF日志瘦身操作，为了保证全量复制后AOF持久化文件立刻可用。 全量复制比较耗时： Master进行bgsave快照持久化时间； RDB快照文件网络传输时间； Slave清空老数据时间； 可能存在的AOF重写时间； 部分复制部分复制主要是Redis针对全量复制的过高开销做出的一种优化措施。使用psync {runId}{offset}命令实现。用于处理在主从复制中因网络闪断等原因造成的数据丢失场景，当从节点再次连上主节点后，如果条件允许，主节点会补发丢失数据给从节点。因为补发的数据远远小于全量数据，可以有效避免全量复制的过高开销。如复制缓冲区 repl-backlog-xx的配置 流程： 1、当主节点直接网络出现中断时，如果超过repl-timeout时间，主节点会认为从节点故障并中断复制连接； 2、主从连接中断期间主节点依然响应命令，但因复制连接中断，命令无法发送给从节点，不过主节点内部存在的复制积压缓冲区，依然可以保存最近一段时间的写命令数据，默认最大缓存1MB，可以通过into replication 查看； 3、当从节点网络恢复后，从节点会再次连上主节点； 4、当主从连接恢复后，由于从节点之前保存了自身已复制的偏移量和主节点的运行ID。因此会把它们当做psync参数发送个主节点，要求进行部分复制操作； 5、主节点接到psync命令后首先核对参数runId是否与自身一致，如果一致，说明之前复制的是当前主节点；之后根据参数offset在自身复制积压缓冲区查找，如果偏移量之后的数据存在缓冲区中，则对从节点发送+COUTINUE响应，表示可以进行部分复制； 6、主节点根据偏移量把复制积压缓冲区里的数据发送给从节点，保证主从复制进入正常状态。 心跳检测主从节点在建立复制后，它们之间维护着长连接并彼此发送心跳命令。 主从心跳检测机制： 1、主从节点彼此都有心跳检测机制，各自模拟对方的客户端进行通信，主节点的连接状态为flags=M,从节点连接状态为flags=S 2、主节点默认每隔10秒对从节点发送ping命令，判断从节点的存活性和连接状态。可以通过repl-ping-replica-period 10 控制发送频率 3、从节点在主线程中每隔一秒发送replconf ack{offset} 命令，给主节点上报自身当前的复制偏移量。 主节点根据replconf命令判断从节点超时时间，体现在info replication 统计中的lag信息中，lag表示从节点最后一次通信延迟的秒数，正常延迟应该在0到1之间。 如果超过repl-timeout配置的值(默认60秒),则判定从节点下线并断开复制客户端连接。即使主节点判定从节点下线后，如果从节点重新恢复，心跳检测和继续执行. 故障转移Master故障假如主从都没数据持久化，此时千万不要立即重启服务，否则可能会造成数据丢失。应该： 在slave上执行SLAVEOF ON ONE，来断开主从关系并把slave升级为主库； 此时重新启动主数据库，执行SLAVEOF,把它设置为从库，自动备份数据。 Slave故障如满足业务需求，可以将宕机的slave的连接转移到其他slave。在Redis中从库重新启动后会自动加入到主从架构中，自动完成同步数据；如果从数据库实现了持久化，只要重新假如到主从架构中会实现增量同步。 自动故障转移？哨兵机制Redis提供了sentinel（哨兵）机制通过sentinel模式启动redis后，自动监控master/slave的运行状态。基本原理是：心跳机制+投票裁决。 每个sentinel会向其它sentinal、master、slave定时发送消息，以确认对方是否“活”着，如果发现对方在指定时间（可配置）内未回应，则暂时认为对方已挂（所谓的“主观认为宕机” Subjective Down，简称SDOWN）。 若&quot;哨兵群&quot;中的多数sentinel，都报告某一master没响应，系统才认为该master&quot;彻底死亡&quot;(即：客观上的真正down机，Objective Down，简称ODOWN)， 通过一定的vote算法，从剩下的slave节点中，选一台提升为master，然后自动修改相关配置。 sentinel哨兵故障自动转移流程： 1、通过心跳机制，多个sentinel发现并确认master有问题； 2、选举出一个sentinel作为领导； 3、选出一个slave作为新的master； 4、通知其余slave成为新master的slave； 5、通知客户端主从发生变化；（客户端连接哨兵即可获取主从的信息） 6、等待老的master复活成为新master的slave； 读写分离默认是读写分离的：replica-read-only yes对于读占比较高的场景，可以通过把一部分读流量分摊到slave来减轻master压力，同时需要注意永远只对主节点执行写操作。建议大家在做读写分离之前，可以考虑使用Redis Cluster 等分布式解决方案。 常见问题1、读写分离：默认是读写分离的：replica-read-only yes用于读多写少的场景，将流量分配到Slave节点，减少Master的压力，扩展读的能力。可能问题： 复制数据延迟，出现读写不一致的情况； 读到过期数据； 过期策略：a. 懒惰性策略（操作key时才会看是否过期）b. 定时采样key，看是否过期；因为slave只要读操作不能del处理，要靠master将过期删除的命令发送过来再执行，会造成Slave读到过期数据。 从节点发送故障； 2、主从配置不一致：如： maxmemory不一致：会出现丢失数据； 数据结构优化参数不一致，如hash-max-ziplist-entries：会出现内存不一致问题； 3、规避全量复制：1、新加slave第一次全量复制不可避免：可以注意： 小主节点，控制内存； 低峰时间处理；2、节点runningid不匹配： 主节点重启，runningid变化； 故障转移，哨兵或集群；3、复制积压缓冲区不足： 网络中断，部分复制无法满足； 增大缓冲区的配置rel_backlog_size； 4、规避复制风暴：如一主多从，主挂重启，需要生成rdb并复制到从节点； 单主节点复制风暴：问题：主节点重启，多从节点复制；解决：更换复制拓扑，slave下挂slave。 单机器复制风暴：机器上节点都是master，机器宕机，会有大量的全量复制；可以主节点分散多机器。 Sentinel哨兵概述因为主从复制的缺陷：1、手动故障转移；2、写能力和存储能力受限；引出哨兵机制：Redis的哨兵机制是官方推荐的一种高可用（HA）方案。哨兵机制主要三个功能： 1、监控：不停监控Redis主从节点是否安装预期运行； 2、提醒：如果Redis运行出现问题可以按照配置文件中的配置项 通知客户端或者集群管理员； 3、自动故障转移：当主节点下线之后，哨兵可以从主节点的多个从节点中选出一个为主节点，并更新配置文件和其他从节点的主节点信息。 客户端连接步骤： 1、获取所有的sentinel节点和masterName。遍历sentinel集合找到可用节点； 2、在找到的可用sentinel节点上，执行命令sentinel get-master-addr-by-name masterName；会获取到master节点真正地址和端口。 3、获取master节点信息后去role验证真伪； 4、如redis节点发生了变化，client会感知到。内部基于发布订阅感知：client会订阅sentinel端某个频道，里面有谁是master端信息，有了变化会通知client。 实现原理客户端高可用案例：（故障转移） Redis Sentinel Failover故障选举测试：死循环对redis哨兵主从进行读写故障转移恢复案例： 执行该死循环程序； 将其中的7000节点进行强制宕机；这时程序会大量的报错：Connection refused。 过了n秒后，sentinel自动进行完故障转移后，程序就会正常执行打印； 服务端日志分析：数据节点和sentinel节点日志中故障转移大致流程： 1、发现master不可用，进入主观不可用(SDOWN)； 2、进行投票，如达到了quorum（配置文件指定），进入客观不可用(ODOWN) 3、当前配置版本被更新； 4、达到failover条件，正等待其他sentinel的选举：开始要选择一个slave当选新master；找到了一个适合的slave来担当新master；当把选择为新master的slave的身份进行切换； 5、Failover状态变为reconf-slaves 6、sentinel发送SLAVEOF命令把它重新配置，重新配置到新主；将其他slave配置到新master； 7、新的master对新的slave进行数据复制同步； 8、老的master离开客观不可用（ODOWN），failover成功完成。 9、master地址发生改变，变为新的master 10、检测slave并添加到slave列表。 三个定时任务： 1、每10秒每个sentinel会对master和slave进行info操作：作用就是发现slave节点，并且确认主从关系，因为redis-Sentinel节点启动的时候是知道 master节点的，只是没有配置相应的slave节点的信息 2、每隔2秒，sentinel都会通过master节点内部的channel来交换信息（pub/sub订阅模式）：作用是通过master节点的频道来交互每个Sentinel对master节点的判断信息 3、每隔一秒每个sentinel对其他的redis节点（master，slave，sentinel）执行ping操作：对于master来说若超过30s没回复，就对该master进行主观下线并询问其他的Sentinel节点是否可以客观下线。心跳检测的过程，用来判断上下线的依据。 主观下线和客观下线： 12sentinel monitor mymaster 127.0.0.1 6379 2#主节点名称 IP 端口号 选举次数 主观下线：每个Sentinel节点对Redis节点失败的“偏见”。 客观下线：所有Sentinel节点对Redis节点失败达成共识。 Sentinel节点领导者选举：因为：只有一个sentinel节点完成故障转移即可。 选举：通过sentinel is-master-down-by-addr命令都有希望成为leader。 该命令的作用：a.交换master节点的失败判定；b.进行领导者选举。 1、每个做主观下线的sentinel节点向其他sentinel节点发命令，要求它设为领导者； 2、收到命令的sentinel节点如目前还没同意通过其他sentinel节点发的命令，就会同意当前请求，否则拒绝； 3、如该sentinel节点的票数超过sentinel集合半数且超过指定的quorum，它就成为领导者； 4、如果有多个sentinel节点成为了领导者，就会等一段时间继续重新选举。 故障转移：（sentinel领导者完成） 1、从slave节点选择一个合适的节点作为新的master； 2、对上面的slave节点执行slaveof on one命令，让它成为master； 3、向剩余的slave节点发送slaveof命令，让它们成为新master的slave； 4、进行新主从数据的复制同步； 5、更新老的master为slave，并一直关注它，当重启生效后就去复制新的master节点的数据。 如何选择合适的slave节点作为新的master？ 1、选择slave-priority优先级最高的slave节点，如存在返回，否则继续； 2、选择复制偏移量最大的slave节点（数据最完整，类似zookeeper），如存在返回，否则继续； 3、选择runningid最小的slave节点（也就是最早启动的节点）； 注意 1、sentinel集群节点大于等于3且为奇数 2、redis的sentinel是配置中心不是代理，其中的数据节点和普通数据节点没区别。客户端初始化连接的是sentinel节点集合，不是具体的redis节点；它通过3个定时任务实现了sentinel节点对于master和slave和其余sentinel节点的监控； Cluster集群为什么需要集群？ 并发问题：redis最高的ops并发量为10w，如果业务需要ops为100万就无法解决； 数据量问题：单机的内存太小，无法满足需求； 集群架构 单机架构（主从模式也是单主机架构） 分布式架构：服务端多个节点，每个节点都可读写，节点间都是可以通信的，节点间互相了解各自对应的槽。client访问任意节点，读key时，如在该节点会直接返回，否则返回key真实的槽所在的节点信息，在做对应跳转获取； 数据分布： 两种分区方式： 顺序分布：（上图3个节点，平均每个节点33个数据）顺序分区的数据量不可确定性会导致倾斜，支持顺序访问，但不支持批量操作。 哈希分布： 节点取余分区 hash(key)%nodes数据分散度高，无法顺序访问，支持批量操作； 1、节点取余分区：hash(key)%nodes 会有节点伸缩：数据节点关系变化，导致数据迁移； 迁移数量和添加节点的数量有关，建议翻倍扩容，迁移数据量会比较小。如3个节点变为6个节点，这样数据迁移量在50%左右； 如对节点进行扩容时：如3个节点变为4个节点。问题： 如果要增加分区，数据迁移量在80%左右； 数据迁移第一次是无法从缓存中取到的，数据库需要回写到新节点； 2、一致性哈希分区：哈希 + 顺时针（优化取余）将数据作为一个0～2^ 32大小的token环中，有4个node，为每个node分配一个token，每个node负责范围内的数据；如某key进行hash计算落在node3和4范围内，它会顺时针找离自己最近的node，即node3。 节点伸缩：只影响邻近节点，但是还是有数据迁移； 翻倍伸缩：保证最小迁移数据和负载均衡； 多用在节点非常多的时候。 节点扩容的情况：如上图，添加节点node5，会进行数据的漂移，但不会影响node3和4。尤其节点非常多的时候效率提高太多； 3、虚拟槽分区：（共享消息模式，集群默认） 预设虚拟槽（redis cluster范围0-16383）：每个槽映射一个数据子集，一般比节点数大； 良好的哈希函数：例如CRC16； 服务端管理节点、槽、数据：例如Redis Cluster； 假如有10w数据，有16384个槽，5个节点，对槽进行分配，对key按照一定的hash规则计算后，再对16383进行取余，会把取余对结果发生给cluster中的任意一个节点，而每个节点都知道自己负责的槽，如落在自己槽的范围内，就由它管理。如不在该槽，因为节点间会共享消息，所以就会知道该key对应的真实的槽。 集群伸缩伸缩原理 集群伸缩 = Slot槽和数据在节点之间的移动。 集群扩容：增加新节点 1、准备新节点：集群模式下，配置和其他节点统一，目前启动后仍是孤儿节点； 2、加入集群：作用：为它迁移槽和数据实现扩容；作为slave节点负责故障转移； 3、迁移槽和数据： 迁移数据过程： 对目标节点发送：cluster setslot {slot) importing {sourceNodeld)命令，让目标节点准备导入槽的数据。 对源节点发送：cluster setslot {slot) migrating {targetNodeld)命令，让源节点准备迁出槽的数据。 源节点循环执行cluster getkeysinslot {slot) {count)命令，每次获取count个属于槽的健。 在源节点上执行migrate {targetlp} {targetPort} key 0 {timeout}命令把指定key迁移。 重复执行步骤3~4直到槽下所有的键数据迁移到目标节点。 向集群内所有主节点发送cluster setslot {slot）node {targetNodeld)命令，通知槽分配给目标节点。 集群缩容：下线节点和槽 客户端路由：（实际开发会遇到的问题）moved重定向client接收到moved异常后，会拿到正确的目标节点需自己去执行； 注意：client不会自动找到目标节点进行跳转，需要二次写的逻辑进行功能开发； 槽命中，直接返回（可查看key的slot） 槽未命中：返回moved异常：客户端不会自己找到异常节点，需要自己写逻辑； 集群和非集群环境下：集群环境下会自动完成：捕获moved异常和重新写的操作； ask重定向在进行集群伸缩时，会出现数据slot迁移，出现ask重定向。ask是槽还在迁移中；moved是槽已经完成了迁移； smart（智能）客户端：JedisCluster、追求性能 工作原理：（具体可看源码:redis.clients.jedis.JedisClusterCommand#runWithRetries） 1.从集群中选一个可运行节点，使用cluster slots初始化槽和节点映射。 2.将cluster slots的结果映射到本地，为每个节点创建JedisPool。 3.准备执行命令。 集群原理批量操作 四种批量操作实现优化（mget,mset必须在一个槽） 串行mget：相当于for循环遍历keys去对应的集群节点get值，最后将结果汇总；简单效率低，需要n次的网络时间； 串行IO：对串行mget优化，在client本地做內聚合将key的槽计算出，对key根据节点分组，之后通过几次pipeline操作即可；只需要节点个数次网络时间； 并行IO：对串行IO优化，使用多线程，只需1次网络时间； hash_tag：将key进行hash_tag包装，使所有key都在一个节点，只需要1次网络时间即可； 故障转移Redis Sentinel的故障转移依赖外部节点sentinel来实现；而Redis Cluster自身实现了高可用，当前节点出了问题其他节点会监控得知，实现故障转移； 故障发现：通过节点间的ping/pong消息实现，不需要sentinel。 主观下线：某个节点认为另一个节点不可用。 客观下线：客观下线：半数以上持有槽点主节点标记某节点主观下线。 故障恢复： 资格检查： 准备选举时间：保证偏移量大的slave有更小的延迟达到选举时间，保证数据一致性更高。 选举投票： 替换主节点： 常见问题集群完整性cluster-require-full-coverage默认为yes表示是否需要所有集群节点都是在线的状态，所有的16384个槽是全部可用的，才会认为集群是完整的，才可以对外提供服务。注意：如为yes 节点故障或者正在故障转移时会有：(error)CLUSTERDOWN The cluster is down 大多数业务无法容忍，cluster-require-full-coverage建议设置为no 宽带消耗 官方建议节点不超过1000个，因为节点间进行ping/pong操作，过多会带来比较大的带宽消耗； 优化： 避免“大”集群：避免多业务使用一个集群，大业务可以多集群。 cluster-node-timeout：带宽和故障转移速度的均衡。 尽量均匀分配到多机器上：保证高可用和带宽 Pub/Sub广播模式的局限性：问题：发布一条消息，每个节点都会接收到，加重带宽消耗。解决：单独“走”一套Redis Sentinel。 集群倾斜问题：数据倾斜和请求倾斜。 数据倾斜：内存不均。4种原因： 节点和槽分配不均； 不同槽对应键值数量差异较大； 包含bigkey； 内存相关配置不一致； 请求倾斜：热点数据（缓存常见问题） 集群的读写分离：只读连接：集群模式下从节点不接受任何读写请求。如进行了读操作：会重定向到负责槽点主节点；使用readonly命令可以读，是一个连接级别的命令。上图7000为Master，7003为它的Salve。 集群的读写分离更复杂： 同样的问题：复制延迟、读取过期数据、从节点故障 修改客户端：cluster slaves {nodeld) 集群VS单机（sentinel/主从/单点）： 针对集群 分布式集群redis不一定好。大部分场景下Redis Sentinel就足够了。 总结 Redis Cluster数据分区规则采用虚拟槽方式（16384个槽），每个节点负责一部分槽和相关数据，实现数据和请求的负载均衡。 搭建集群包括四个步骤：准备节点、节点握手、分配槽、复制。 集群伸缩通过在节点之间移动槽和相关数据实现。扩容时：根据槽迁移计划，把槽从源节点迁移到新节点；缩容时：如果下线的节点有负责的槽，就需要迁移到其他节点上，再通过cluster forget命令让集群内所有节点忘记并下线该节点。 使用smart客户端操作集群打到通信效率最大化，客户端内部负责计算维护键-&gt;槽-&gt;节点的映射，用于快速定位到目标节点。 集群自动故障转移过程包括：故障发现和节点恢复。节点下线包括主观下线和客观下线，当超过半数主节点认为故障节点为主观下线时，标记它为客观下线状态。从节点负责对客观下线的主节点触发故障恢复流程，保证集群的可用性。 经典案例Redis缓存缓存的收益和成本？收益： 1、加速读写速度： 2、降低后端负载：后端服务器通过前端缓存降低负载：业务端使用Redis降低后端MySQL负载等 成本： 1、数据不一致：缓存层和数据层有时间窗口不一致，和更新策略有关； 2、代码维护成本：要多加一层缓存逻辑； 3、运维成本：如Redis Cluster维护； 缓存更新策略：常见策略三种缓存算法：（FIFO/LRU/LFU） FIFO算法：先进先出（FIFO，队列）。即如果一个数据是最先进入的，那么可以认为在将来它被访问的可能性很小。空间满的时候，最先进入的数据会被最早置换（淘汰）掉。 LRU算法：LRU是Least Recently Used的缩写，即最近最少使用，是一种常用的页面置换算法，如果空间不足淘汰掉最近最少使用的数据。。思想是：如果一个数据在最近一段时间没有被访问到，那么可以认为在将来它被访问的可能性也很小。因此，当空间满时，最久没有访问的数据最先被置换（淘汰）。实现可参考：LRU算法实现测试 LFU算法：LFU（Least Frequently Used ，最近最不常用算法），也就是淘汰一定时期内被访问次数最少的数据。LFU 算法本质上可以看做是一个 top K 问题(K = 1)，即选出频率最小的元素。因此可以用二项堆来选择频率最小的元素，这样的实现比较高效。最终实现策略为小顶堆+哈希表。 超时剔除：时间过期时间 主动更新：开发来控制缓存的生命周期； redis的内存驱逐策略：配置参数：maxmemory-policy noeviction驱逐策略：内存容量超过maxmemory后的处理策略。 volatile-lru：利用LRU算法移除设置过过期时间的key。 LRU是Least Recently Used的缩写，即最近最少使用，是一种常用的页面置换算法，选择最近最久未使用的页面予以淘汰。 volatile-random：随机移除设置过过期时间的key。 volatile-ttl：移除即将过期的key，根据最近过期时间来删除（辅以TTL） allkeys-lru：利用LRU算法移除任何key。 allkeys-random：随机移除任何key。 noeviction：不移除任何key，只是返回一个写错误。 volatile-lfu：从已经设置过期时间的数据中，挑选最不经常使用的数据淘汰。 allkeys-lfu：当内存不足以容纳新写入数据时，在键空间中，移除最不经常使用的key。 一致性问题 低一致性：最大内存和淘汰策略 高一致性：超时剔除和主动更新结合，最大内存和淘汰策略兜底。 常见缓存问题：缓存穿透缓存穿透，即大量缓存中不存在的请求key访问直接落到数据库，一般是恶意攻击； 解决方案：有很多种方法可以有效地解决缓存穿透问题，最常见的则是采用布隆过滤器。 将所有可能存在的数据哈希到一个足够大的bitmap中，一个一定不存在的数据会被这个bitmap拦截掉，从而避免了对底层存储系统的查询压力。 另外也有一个更为简单粗暴的方法：如果一个查询返回的数据为空（不管是数据不存在，还是系统故障），我们仍然把这个空结果进行缓存，但它的过期时间会很短，最长不超过五分钟。 缓存击穿缓存击穿，指一个key非常热点，在不停的扛着大并发，大并发集中对这一个点进行访问，当这个key在失效的瞬间，持续的大并发就穿破缓存，直接请求数据库，就像在一个屏障上凿开了一个洞。这个和缓存雪崩的区别在于这里针对某一key缓存，前者则是很多key。 解决方案：添加互斥锁：结合上面的击穿的情况，在第一个请求去查询数据库的时候对他加一个互斥锁，其余的查询请求都会被阻塞住，直到锁被释放，从而保护数据库。但是也是由于它会阻塞其他的线程，此时系统吞吐量会下降。需要结合实际的业务去考虑是否要这么做。 缓存雪崩缓存雪崩，是指在某一个时间段，缓存集中过期失效。 如：redis服务器挂掉导致请求大量涌至数据库； 而缓存服务节点的宕机，对数据库服务器造成的压力是不可预知的，很有可能瞬间就把数据库压垮。 案例：比如双十二活动，马上就要到双十二零点，很快就会迎来一波抢购，这波商品时间比较集中的放入了缓存，假设缓存一个小时。那么到了凌晨一点钟的时候，这批商品的缓存就都过期了。而对这批商品的访问查询，都落到了数据库上，对于数据库而言，就会产生周期性的压力波峰。 一般采取不同分类商品，缓存不同周期。在同一分类中的商品，加上一个随机因子。这样能尽可能分散缓存过期时间，而且，热门类目的商品缓存时间长一些，冷门类目的商品缓存时间短一些，也能节省缓存服务的资源。 解决方案： 事前：使用集群缓存，保证缓存服务的高可用。 这种方案就是在发生雪崩前对缓存集群实现高可用，如果是使用 Redis，可以使用 主从+哨兵 ，Redis Cluster 来避免 Redis 全盘崩溃的情况。 事中：加本地缓存 + Hystrix限流&amp;降级，避免MySQL被hit死。 使用本地缓存的目的也是考虑在Redis Cluster 完全不可用的时候，本地缓存还能够支撑一阵。 使用 Hystrix进行限流 &amp; 降级 ，比如一秒来了5000个请求，我们可以设置假设只能有一秒 2000个请求能通过这个组件，那么其他剩余的 3000 请求就会走限流逻辑。 然后去调用我们自己开发的降级组件（降级），比如设置的一些默认值之类的。以此来保护最后的 MySQL 不会被大量的请求给打死。 事后：开启Redis持久化机制，尽快恢复缓存集群。一旦重启，就能从磁盘上自动加载数据恢复内存中的数据。 Redis实现分布式锁分布式锁一般有三种实现方式： 数据库乐观锁； 基于Redis的分布式锁； 基于ZooKeeper的分布式锁。 确保分布式锁可用，我们至少要确保锁的实现同时满足以下四个条件： 互斥性。在任意时刻，只有一个客户端能持有锁。 不会发生死锁。即使有一个客户端在持有锁的期间崩溃而没有主动解锁，也能保证后续其他客户端能加锁。 具有容错性。只要大部分的Redis节点正常运行，客户端就可以加锁和解锁。 解铃还须系铃人。加锁和解锁必须是同一个客户端，客户端自己不能把别人加的锁给解了。 加锁1234567891011121314151617181920212223242526272829303132private static final String LOCK_SUCCESS = \"OK\";private static final String SET_IF_NOT_EXIST = \"NX\";private static final String SET_WITH_EXPIRE_TIME = \"PX\";/** * 尝试获取分布式锁 * * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @param expireTime 超期时间 * @return 是否获取成功 */public static boolean tryLock(Jedis jedis, String lockKey, String requestId, int expireTime) &#123; /* * 执行下面的set()方法就只会导致两种结果： * 1. 当前没有锁（key不存在），那么就进行加锁操作，并对锁设置个有效期，同时value表示加锁的客户端。 * 2. 已有锁存在，不做任何操作。 * * 参数： * - 第一个为key，我们使用key来当锁，因为key是唯一的。 * - 第二个为value，我们传的是requestId，因为分布式锁要满足第四个条件解铃还须系铃人， * 通过给value赋值为requestId，我们就知道这把锁是哪个请求加的了，在解锁的时候就可以有依据。 * requestId可以使用UUID.randomUUID().toString()方法生成。 * - 第三个为nxxx，这个参数我们填的是NX，意思是SET IF NOT EXIST， * 即当key不存在时，我们进行set操作；若key已经存在，则不做任何操作； * - 第四个为expx，这个参数我们传的是PX，意思是我们要给这个key加一个过期的设置，具体时间由第五个参数决定。 * - 第五个为time，与第四个参数相呼应，代表key的过期时间。 */ String result = jedis.set(lockKey, requestId, SET_IF_NOT_EXIST, SET_WITH_EXPIRE_TIME, expireTime); return LOCK_SUCCESS.equals(result);&#125; 加锁代码满足我们可靠性里描述的三个条件。 首先，set()加入了NX参数，可以保证如果已有key存在，则函数不会调用成功，也就是只有一个客户端能持有锁，满足互斥性。 其次，由于我们对锁设置了过期时间，即使锁的持有者后续发生崩溃而没有解锁，锁也会因为到了过期时间而自动解锁（即key被删除），不会发生死锁。 最后，因为我们将value赋值为requestId，代表加锁的客户端请求标识，那么在客户端在解锁的时候就可以进行校验是否是同一个客户端。 由于我们只考虑Redis单机部署的场景，所以容错性我们暂不考虑。 解锁123456789101112131415161718192021222324private static final Long RELEASE_SUCCESS = 1L;/** * 释放分布式锁 * * @param jedis Redis客户端 * @param lockKey 锁 * @param requestId 请求标识 * @return 是否解锁成功 */public static boolean releaseLock(Jedis jedis, String lockKey, String requestId) &#123; // Lua脚本代码：保证命令执行的原子性。 // 即eval命令执行Lua代码的时候，Lua代码将被当成一个命令去执行，并且直到eval命令执行完成，Redis才会执行其他命令。 // 首先获取锁对应的value值，检查是否与requestId相等，如果相等则删除锁（解锁） String script = \"if redis.call('get', KEYS[1]) == ARGV[1] \" + \"then return redis.call('del', KEYS[1]) \" + \"else return 0 end\"; // 将Lua代码传到jedis.eval()方法里，并使参数KEYS[1]赋值为lockKey，ARGV[1]赋值为requestId。 // eval()方法是将Lua代码交给Redis服务端执行。 Object result = jedis.eval(script, Collections.singletonList(lockKey), Collections.singletonList(requestId)); return RELEASE_SUCCESS.equals(result);&#125;","categories":[{"name":"Redis","slug":"Redis","permalink":"https://bubblewu.github.io/categories/Redis/"}],"tags":[{"name":"Redis","slug":"Redis","permalink":"https://bubblewu.github.io/tags/Redis/"}]},{"title":"并发模式-2：Immutable不变模式","slug":"Java/并发/并发模式-2：Immutable不变模式","date":"2020-07-30T07:54:19.000Z","updated":"2020-08-18T07:25:05.104Z","comments":true,"path":"ckde6cvxs0000a5yd0wtz6h6h/","link":"","permalink":"https://bubblewu.github.io/ckde6cvxs0000a5yd0wtz6h6h/","excerpt":"Immutable不变模式就是指：确保实例的内部状态不会发生改变，这样在访问这些实例时就不需要增加耗时的互斥处理（如Single Threaded Execution模式中的对临界区进行互斥保护）。 如String类就是一个Immutable类。因为String类中使用final关键字修饰字符串数组private final char value[];来保存字符串，并没有修改字符串内容的方法。所以，String的实例所表示的字符串的内容不会发生变化。","text":"Immutable不变模式就是指：确保实例的内部状态不会发生改变，这样在访问这些实例时就不需要增加耗时的互斥处理（如Single Threaded Execution模式中的对临界区进行互斥保护）。 如String类就是一个Immutable类。因为String类中使用final关键字修饰字符串数组private final char value[];来保存字符串，并没有修改字符串内容的方法。所以，String的实例所表示的字符串的内容不会发生变化。 Immutable不变模式是什么？Immutable角色是一个类，在这个角色中，字段的值是不可以修改的，也不存在修改字段内容的方法。 Immutable角色的实例被创建后，状态就不会再发生变化，也就不需要使用Single Threaded Execution模式使用synchronized去保护临界区。 何时使用？Immutable模式该在哪些情况下使用呢？ 实例创建后，状态不再发生变化时： 实例创建后，状态不再发生变化是必要条件。实例的状态是由字段的值决定的，所以将字段声明为final字段，且不存在setter方法是重点所在。但即使这样，也有可能是可变的，因为即使字段的值不发生变化，但字段引用的实例有可能会发生变化。 实例是共享的，且被频繁访问时：Immutable模式的优点是不使用synchronized来保护临界区。就意味着能够在不失去安全性和生存性的前提下提高性能。所以在当实例被多个线程共享时，且有可能被频繁访问时，Immutable模式的优点就会极大的凸显出来。 成对的mutable可变类和immutable不可变类假设一个类，被多线程访问，使用synchronized进行保护，但类中存在setter方法。这样看起来Immutable模式是不成立的。 场景一：如果这个setter方法并未被使用，就可以将字段声明为final并删除setter方法，这样就遵守了不可变性，就成功改造为Immutable模式了。 场景二：如果setter方法被使用了，这个类就是mutable可变模式了。我们可以分析该类，如可以分为使用setter方法和不使用的情况，就可以将这个类拆分为mutable类和immutable类，然后设计成可以根据mutable实例创建immutable实例，也可以反过来根据immutable实例创建mutable实例。如：StringBuffer类和String类。StringBuffer类是mutable类，表示的字符能够随便改写，使用了synchronized保护。而String类表示字符串不可以被改写，也没使用synchronized保护，所以性能比较高。但StringBuffer类中有一个以String为参数的构造函数，而String类中有一个以StringBuffer为参数的构造函数。也就是，两者的实例是可以互相转换的。 1234567891011// String类的构造函数 public String(StringBuffer buffer) &#123; synchronized(buffer) &#123; this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); &#125; &#125;//StringBuffer类的构造函数 public StringBuffer(String str) &#123; super(str.length() + 16); append(str); &#125; 所以，如果需要频繁改变字符串内容，就使用StringBuffer类，如果不需要改变，只是引用其内容，就使用String类。但当多个字符串组成新的字符串时，StringBuffer类的速度比String类快。 注意：在Immutable类中调用mutable类时需注意安全性，需要对mutable类进行安全保护，否则，可变类中的值可能会被其他线程使用该类的setter方法改写字段值，导致值发生变化。如： 12345public String(StringBuffer buffer) &#123; synchronized(buffer) &#123; this.value = Arrays.copyOf(buffer.getValue(), buffer.length()); &#125; &#125; 标准类库中的Immutable模式 表示字符串的java.lang.String类：再创建完实例后，字符串的内容不会发生变化，因为使用final关键字修饰字符串数组private final char value[];来保存字符串，并没有修改字符串内容的方法。 表示大数字的java.math.BigInteger类和java.math.BigDecimal类： 表示正则表达式模式的java.util.regex.Pattern类：Pattern类表示正则表达式的模式，即使在处理模式匹配时，值也不会发生变化。 java.lang.Integer类等：Integer和Short等基本类型的包装类（wrapper class）都是immutable类型的，创建好实例后，也都不会发生变化。 案例创建一个Person类，并启动三个线程来访问该实例，会发现它们都是线程安全的。 Person类 123456789101112131415161718192021222324252627282930313233343536373839/** * 表示人的类： * - 线程安全的： * 字段值仅可以通过构造函数来设置，没有setXX方法。 * 所以，Person类的实例一旦创建，其字段的值就不会发生变化。 * 这时，即使多个线程同时访问同一个实例，该类也是安全的。 * Person类中的所有方法无需声明为synchronized，就可以允许多个线程同时执行。 * * - 防止子类修改其字段值： * 1、Person声明为final类型。表示我们无法创建其类的子类，也是防止子类修改其字段值的一种措施。 * 2、字段的可见性都为private。表示这2个字段都只有从该类的内部才可以访问。 * 3、字段都声明为final类型。表示一旦字段被赋值一次，就不会再被赋值。 * * @author wugang * date: 2020-07-31 18:55 **/public final class Person &#123; private final String name; private final String address; public Person(String name, String address) &#123; this.name = name; this.address = address; &#125; public String getName() &#123; return name; &#125; public String getAddress() &#123; return address; &#125; @Override public String toString() &#123; return \"[Person: \" + \"name = \" + name + \", address = \" + address + ']'; &#125;&#125; PrintPersonThread类： 123456789101112131415161718192021222324252627/** * 显示Person实例的线程的类 * * @author wugang * date: 2020-07-31 18:55 **/public class PrintPersonThread extends Thread &#123; private Person person; public PrintPersonThread(Person person) &#123; this.person = person; &#125; @Override public void run() &#123; while (true) &#123; try &#123; // sleep 让各线程可以清晰的交叉打印 TimeUnit.MILLISECONDS.sleep(100); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; System.out.println(Thread.currentThread().getName() + \" prints \" + person.toString()); &#125; &#125;&#125; Main类： 123456789/** * 创建一个Person类，并启动三个线程来访问该实例 */ public static void main(String[] args) &#123; Person person = new Person(\"Bubble\", \"北京\"); new PrintPersonThread(person).start(); new PrintPersonThread(person).start(); new PrintPersonThread(person).start(); &#125; 输出： 12345Thread-1 prints [Person: name &#x3D; Bubble, address &#x3D; 北京]Thread-2 prints [Person: name &#x3D; Bubble, address &#x3D; 北京]Thread-0 prints [Person: name &#x3D; Bubble, address &#x3D; 北京]Thread-2 prints [Person: name &#x3D; Bubble, address &#x3D; 北京]Thread-0 prints [Person: name &#x3D; Bubble, address &#x3D; 北京] 扩展相关的设计模式Single Threaded Execution模式Immutable模式下，实例的状态不会发生变化，所以无需进行保护。而STE模式，当一个线程正在修改实例状态时，不允许其他的线程来访问该实例。这时会出现下面两种情况之一： 写入与写入的冲突（write-write conflict）：当一个线程正在修改实例状态，而其他线程也试图修改其状态时发生的冲突。 读取和写入的冲突（read-write conflict）：当一个线程正在读取实例状态，而其他线程试图修改其状态时发生的冲突。 而immutable模式中，只会发生read-read当情况，不会出现conflict。 Read-Wrire Lock模式在Read-Write Lock模式中，读取操作和写入操作是分开考虑的。在执行读取操作之前，线程必须获取用于读取的锁；在执行写入操作之前，线程必须获取用于写入的锁。所以： 当一个线程在读取时，其他线程可以读取，但是不可以写入。 当一个线程正在写入时，其他线程不可以读取或写入。因为执行互斥处理会降低程序的性能，但是如果把写入的互斥处理和读取的互斥处理分开来考虑，就可以提高系统性能。 Immutable模式中，只会发生read-read当情况，不会出现conflict。所以多线程可以自由的访问实例。而Read-Write Lock模式也利用了read-read不会引起冲突的特点。它执行read的线程和执行write的线程是分开考虑的。能够提高程序的性能。 Flyweight模式（享元模式）享元模式的主要目的是实现对象的共享，即共享池，当系统中对象多的时候可以减少内存的开销，通常与工厂模式一起使用。在Flyweight模式中，为了提高内存的使用效率，会共享实例。所以，Immutable模式和Flyweight模式有时是可以同时使用的。 final关键字final类主要用在三个地方：类、方法、变量。 Java中的final类有多种不同的用途，含义也不同。 final类：当final修饰一个类时，表示该类不能被继承，即无法扩展。也就是说无法创建final类的子类，所以final类中声明的方法也就不会被重写。final类中的所有成员方法都会被隐式地指定为final方法； final方法：实例方法使用final，表示该方法不会被子类的方法重写。即可以把方法锁定，以防止任何继承类修改它的含义。静态方法使用final，表示该方法不会被子类的方法隐藏，如果试图重写或隐藏编译时会提示错误。类中所有的private方法都被隐式地指定为final。 final变量：对于一个final变量，如果是基本数据类型的变量，则其数值一旦初始化之后就不能更改；如是引用类型的变量，则对其初始化之后便不能再让它指向另一个对象。 final字段：final字段只能被赋值一次。对final实例字段赋值的方法有2种：1、一种在字段声明时赋上初始值；2、一种在构造函数中对字段赋值；对final静态字段赋值的方法也有2种：1、一种在字段声明时赋上初始值；2、在static静态代码块中对字段赋值；注意：final字段不可以使用setter方法再次赋值。 final变量和final参数：局部变量和方法的参数，也可以声明为final，可以赋值一次。但final参数不可以赋值，因为调用方法时，已经对其赋值了。 集合类和多线程非线程安全的ArrayList类java.util.ArrayList类用于提供可调整大小的数组，是非线程安全的。 Collections.synchronizedList同步集合类java.util.ArrayList类是非线程安全的类，可以使用Collections.synchronizedList方法对其进行同步，就能得到线程安全的实例。 1final List&lt;String&gt; list = Collections.synchronizedList(new ArrayList&lt;&gt;()); 写时复制（copy-on-write）的CopyOnWriteArrayList类java.util.concurrent.CopyOnWriteArrayList类是线程安全的。与使用Collections.synchronizedList不同，它采用了写时复制Copy-On-Write技术来避免读写冲突。如果使用Copy-On-Write，当对集合执行写操作时，内部已确保安全的数组就会被整体复制。复制之后，就不需在使用迭代器依次读取元素时担心元素会被修改了。 1234567891011121314public boolean add(E e) &#123; final ReentrantLock lock = this.lock; lock.lock(); try &#123; Object[] elements = getArray(); int len = elements.length; Object[] newElements = Arrays.copyOf(elements, len + 1); newElements[len] = e; setArray(newElements); return true; &#125; finally &#123; lock.unlock(); &#125;&#125; 但在使用copy-on-write时，每次执行写操作时，都会执行复制，会耗费较多时间。所以该类适合在写少读多，且读操作频率非常高的场景。","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://bubblewu.github.io/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://bubblewu.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"并发模式-1：Single Threaded Execution模式：能通过这座桥的只能有一个人","slug":"Java/并发/并发模式-1： Single Threaded Execution模式：能通过这座桥的只能有一个人","date":"2020-07-30T06:54:19.000Z","updated":"2020-08-18T07:25:09.929Z","comments":true,"path":"ckd8g12ck0000v1yd2ymng4um/","link":"","permalink":"https://bubblewu.github.io/ckd8g12ck0000v1yd2ymng4um/","excerpt":"Single Threaded Execution模式，即&quot;以一个线程执行&quot;。就像独木桥一样，同一时间内只允许一个人通过，该模式用于设置限制，以确保同一时间内只能让一个线程执行处理。 其实主要思想也就是： 当我们修改多个线程共享的实例时，实例就会失去安全性。所以我们找出这个不安全的范围，将这个范围设置为临界区，并对临界区进行保护（使用synchronized），使其只允许一个线程同时执行。","text":"Single Threaded Execution模式，即&quot;以一个线程执行&quot;。就像独木桥一样，同一时间内只允许一个人通过，该模式用于设置限制，以确保同一时间内只能让一个线程执行处理。 其实主要思想也就是： 当我们修改多个线程共享的实例时，实例就会失去安全性。所以我们找出这个不安全的范围，将这个范围设置为临界区，并对临界区进行保护（使用synchronized），使其只允许一个线程同时执行。 Single Threaded Execution模式概述Single Threaded Execution模式中会有一个发挥SharedResource（共享资源）作用的类。如下面案例中的门Gate这个类。 SharedResource角色是可以被多个线程访问的类，包含很多方法，主要分类下面两类： safeMethod：线程安全方法。多线程下不会发生问题。 unsafeMethod：非线程安全方法。多个线程调用会出现问题，需进行保护，使其不被多个线程同时访问。 Single Threaded Execution模式会保护unsafeMethod，使其只能由一个线程访问，Java可以使用synchronized关键字。我们将允许单个线程执行的程序范围称为临界区。 什么时候使用？ 多线程时：单线程时不需要，使用的前提是多线程环境下。 多个线程访问时： 当SharedResource角色的实例有可能被多个线程同时访问时，就需要使用Single Threaded Execution模式。 即使是多线程程序，如果所有线程都是完全独立操作的，那么就不需要使用该模式，当前状态为线程互不干涉（interfere）。在某些多线程框架中，有时线程的独立性是由框架保证的，这时也不需使用该模式。 状态有可能发生变化时：如果SharedResource角色的状态会发生变化时，就需使用该模式。 如果创建实例后，实例的状态再也不会发生变化，则不需使用。如只读不写的情况。如Immutable模式时，实例的状态不会发生改变，也就不需要。 需要确保安全性时：只有在需要确保安全性时，才需要使用该模式。如：Java的集合类大多为非线程安全的，在使用时，这是为了在不需要考虑安全性的时候提高程序的运行速度。 线程安全的方法：Java提供了下列方法，可以确保集合类是线程安全的。 synchronizedCollection方法； synchronizedList方法； synchronizedMap方法； synchronizedSet方法； synchronizedSortedMap方法； synchronizedSortedSet方法； 安全性和synchronizedJava使用关键字synchronized来实现执行线程的互斥处理。同步方法（synchronized方法）： 在方法前加synchronized关键字，每次只允许一个线程处理该方法。 synchronized实例方法、synchronized静态方法和synchronized代码块： synchronized代码块可以精确的控制互斥处理的执行范围。 synchronized静态方法和synchronized实例方法使用的锁是不一样的。synchronized静态方法是使用该类的类对象的锁来执行线程的互斥处理的，和synchronized代码块锁类时是等效的。 需注意： 某个线程在运行synchronized方法时，只会停止想要获取当前同一个实例的锁的线程； 非synchronized方法可以在任意时间被多个线程执行，即使存在正在运行其他的synchronized方法的线程，非synchronized方法也仍然可以由多个线程运行。 同一个实例的synchronized实例方法同时只能有一个线程运行，如实例不同，锁也就不同，所有就算是synchronized实例方法，也可以由多个线程同时运行。 同一个类下的多个synchronized静态方法不可以由多个线程同时运行，因为锁的是当前类对象。 synchronized方法通常会降低生存性，如容易引起死锁；添加不必要的synchronized，性能会降低，如吞吐量； synchronized保护哪个对象的实例，就需对哪个对象加锁。synchronized方法执行的操作，是不可分割的，能够防止多个线程交错的执行赋值操作，是原子操作（Atomic）。 注意：如在一个bean实体中，分别对两个字段的set方法加锁也是不安全的，因为线程会单独赋值，需要将字段合在一起保护。 synchronized和lock/unlock 如果在lock和unlock之间出现return语句或异常处理，会导致unlock不会被调用。而synchronized方法和代码块，无论是执行return还是抛出异常，都一定能释放锁。 不过lock和unlock操作，可以使用finally块来执行unlock。这样调用lock方法后，无论执行什么操作，都会调用unlock方法解锁。 synchronized和volatile和juc包下的AtomicXXX不使用synchronized，而在声明该字段的时候加上volatile关键字，对该字段的操作也是原子的了。juc包下的AtomicXXX等类也是通过封装volatile功能而得到的类库。 所以： 基本类型、引用类型的赋值和引用是原子操作； 但long和double在线程间共享时，需要加synchronized或声明为volatile。将其变为原子操作。 生存性和死锁生存性是指无论什么时候，必要的处理都一定能够被执行。是程序正常运行的必要条件之一。有时候安全性和生存性会互相制约。有时只重视安全性，生存性就会下降。典型代表就是死锁（deadlook），即多个线程互相等待对方释放锁的情形。 发生死锁的线程都无法再继续运行，程序也就失去了生存性。 如：仅有勺子和叉子各一把，A和B都要吃意大利面，勺子和叉子缺一不可。A拿走了勺子，B拿走了叉子，两人互相僵持，最终谁也吃不了。 在Single Threaded Execution模式中，满足下列条件时，死锁就会发生： 存在多个SharedResource角色； 多个SharedResource角色相当于勺子和叉子 线程在持有着某个SharedResource角色的锁的同时，还想获取其他SharedResource角色的锁； 相当于A拿着勺子同时还想拿叉子，B则相反。 获取SharedResource角色的锁的顺序并不固定。（SharedResource角色是对称的） SharedResource角色是对称的，相当于“拿勺子-&gt;拿叉子”和“拿叉子-&gt;拿勺子”这两种操作。也就是说勺子和叉子二者并不分优先顺序。 只要破坏上面任何一个条件，就可以防止死锁的情况发生。如： 多个线程按照相同的顺序去获取实例资源； 将多个实例资源封装起来一齐拿，对整体做同步，如new Pair(A, B); 直接对pair做同步处理。 可复用性和继承反常如果编写一个SharedResource角色的子类，如子类能访问SharedResource角色的字段，那么子类编写时，就容易出现unsafeMethod。如果不将子类在内的所有unsafeMethod都声明为synchronized方法，那就无法确保SharedResource角色的安全性。 对于多线程来说，继承会引起一些麻烦的问题，称为继承反常（inheritance anomaly） 临界区的大小和性能我们将允许单个线程执行的程序范围称为临界区。 延长临界区的大小，可以使线程的安全性异常更早的暴露出来。如可以使用Thread.sleep()方法来提高检查出错误的可能性。在临界区也可以调用Thread类等yield方法，加快线程的切换。 Thread.yield()方法作用是：暂停当前正在执行的线程对象，并执行其他线程。yield()应该做的是让当前运行线程回到可运行状态，以允许具有相同优先级的其他线程获得运行机会。因此，使用yield()的目的是让相同优先级的线程之间能适当的轮转执行。但是，实际中无法保证yield()达到让步目的，因为让步的线程还有可能被线程调度程序再次选中。结论：yield()从未导致线程转到等待/睡眠/阻塞状态。在大多数情况下，yield()将导致线程从运行状态转到可运行状态，但有可能没有效果。 一般情况下Single Threaded Execution模式会降低程序的性能。 获取锁耗费时间：进入synchronized方法时，线程需要获取锁的对象，会耗费一定时间。如果SharedResource角色的数量少了，那么要获取锁的数量也会减少，从而能够抑制性能的下降。 线程冲突引起的等待：当线程A进入临界区内处理时，其他想要进临界区的线程会阻塞。这种状况称为线程冲突（conflict）。发生冲突时，程序的整体性能会随线程等待时间的增加而下降。 不容易发生线程冲突的ConcurrentHashMap：ConcurrentHashMap将内部数据结构分成多段，针对各段操作的线程互不干涉，因此无需针对其他线程执行互斥处理。 案例模拟三个人频繁地通过一个门，且该门一次只允许一个人经过的场景。当人从该门通过时，统计人数会增加，同时还会记录通行者的姓名和出生地。 不使用Single Threaded Execution模式面对该需求，如果不使用Single Thread Execution模式，在多线程环境下无法正确执行的程序会引发什么现象？将该程序设计为三个类： 类名 说明 Main 创建门，并让三个人不断通过的类 Gate 表示门的类。会记录通行者的姓名和出生地 UserThread 表示人的类。将不断有人通过门 实现Main类123456789101112131415161718192021222324package com.bubble.demo.single_thread_execution;/** * 创建门，并让三个人不断通过的类 * * @author wugang * date: 2020-07-29 15:53 **/public class Main &#123; /** * 由于Gate是非线程安全的，所以输出结果是混乱的。 * */ public static void main(String[] args) &#123; System.out.println(\"测试开始，按[Ctrl + C]键退出\"); // 创建一个门，让三个人不断地通过 Gate gate = new Gate(); new UserThread(gate,\"A小王\", \"A北京\").start(); new UserThread(gate,\"B小李\", \"B上海\").start(); new UserThread(gate,\"C小苏\", \"C南京\").start(); &#125;&#125; Gate类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556import java.util.concurrent.TimeUnit;/** * 表示门的类。会记录通行者的姓名和出生地 * 非线程安全/pass/toString方法加synchronized为线程安全 * * @author wugang * date: 2020-07-29 15:55 **/public class Gate &#123; /** * 表示到目前为止已经通过这道门的人数 **/ private int counter = 0; /** * 表示最后一个通行者的姓名 **/ private String name = \"NoBody\"; /** * 表示最后一个通行者的出生地 **/ private String address = \"NoWhere\"; /** * 表示通过门 */ public void pass(String name, String address) &#123; this.counter++; this.name = name; // 在name和address赋值之间调用sleep，延长临界区，可以提高检查出错误的可能性，不需等数万次执行才发现。 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; this.address = address; check(); &#125; /** * 检查门的最后一个通行者的记录数据是否正确。 * 注意：不需要添加synchronized。 * 因为check方法只有pass方法会调用。且时私有的，也就是不会被其他类调用，所以是安全的 */ private void check() &#123; // 如姓名和首字母不同，说明数据异常 if (name.charAt(0) != address.charAt(0)) &#123; System.out.println(\"*** 异常 *** :\" + toString()); &#125; &#125; @Override public String toString() &#123; return \"No.\" + counter + \": name='\" + name + \", address=\" + address; &#125;&#125; UserThread类123456789101112131415161718192021222324252627282930package com.bubble.demo.single_thread_execution;/** * 表示人的类。将不断有人通过门 * * @author wugang * date: 2020-07-29 16:04 **/public class UserThread extends Thread &#123; private final Gate gate; private final String name; private final String address; public UserThread(Gate gate, String name, String address) &#123; this.gate = gate; this.name = name; this.address = address; &#125; @Override public void run() &#123; System.out.println(name + \" BEGIN\"); // 反复调pass方法，表示这个人在门里不断地穿梭通过 while (true) &#123; this.gate.pass(this.name, this.address); &#125; &#125;&#125; 结果由于Gate是非线程安全的，pass方法会被多个线程执行。 线程改写共享的实例字段时，并未考虑其他线程的操作。 对于name字段，互相竞争的线程获取的一方会先写入值，对于address同样如此，线程会再次竞争，获胜的一方先写入值。也就是所谓的数据竞争（Data Race）。 所以输出结果是混乱的。如下： 123*** 异常 *** :No.88434: name&#x3D;&#39;A小王, address&#x3D;B上海*** 异常 *** :No.88657: name&#x3D;&#39;A小王, address&#x3D;C南京*** 异常 *** :No.88828: name&#x3D;&#39;C小苏, address&#x3D;C南京 由上面执行日志可知： Gate类是非线程安全的。 测试无法证明安全性。执行了上万次才发现异常，如仅执行几次就可能发现不了。 调试信息不可靠。如：*** 异常 *** :No.88828: name=&#39;C小苏, address=C南京，输出了异常日志，但check验证的toString内容是正确的，好像并没有错误。 因为某个线程在执行check方法时，其他线程不断地执行pass方法，改写了name和address的值。 使用Single Threaded Execution模式该案例在不使用Single Threaded Execution模式时，即Gate是非线程安全的类时，会出现数据竞争的情况，导致不符合程序执行的安全性标准。 实现将Gate类修改为线程安全的类，只需要分别在pass方法和toString方法前添加synchronized关键字，这样Gate类就变成了线程安全的类。如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263import java.util.concurrent.TimeUnit;/** * 表示门的类。会记录通行者的姓名和出生地 * 非线程安全/pass/toString方法加synchronized为线程安全 * * @author wugang * date: 2020-07-29 15:55 **/public class Gate &#123; /** * 表示到目前为止已经通过这道门的人数 **/ private int counter = 0; /** * 表示最后一个通行者的姓名 **/ private String name = \"NoBody\"; /** * 表示最后一个通行者的出生地 **/ private String address = \"NoWhere\"; /** * 表示通过门 */ public synchronized void pass(String name, String address) &#123; this.counter++; this.name = name; // 在name和address赋值之间调用sleep，延长临界区，可以提高检查出错误的可能性，不需等数万次执行才发现。 try &#123; TimeUnit.SECONDS.sleep(1); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; this.address = address; check(); &#125; /** * 检查门的最后一个通行者的记录数据是否正确。 * 注意：不需要添加synchronized。 * 因为check方法只有pass方法会调用。且时私有的，也就是不会被其他类调用，所以是安全的 */ private void check() &#123; // 如姓名和首字母不同，说明数据异常 if (name.charAt(0) != address.charAt(0)) &#123; System.out.println(\"*** 异常 *** :\" + toString()); &#125; &#125; /** * 一般来说，多个线程共享的字段必须使用synchronized或者volatile来保护。 * * 假设当线程A正在执行pass方法时，其他线程B调用了toString方法。 * 在线程B引用了name字段的值，但尚未引用address期间，线程A可能会修改address的值。 * 这样，toString方法对线程B创建时使用name和address对首字母就可能会不一致。 */ @Override public synchronized String toString() &#123; return \"No.\" + counter + \": name='\" + name + \", address=\" + address; &#125;&#125; 这样的话，无论等待多久，都不会出现异常情况。 1234测试开始，按[Ctrl + C]键退出A小王 BEGINB小李 BEGINC小苏 BEGIN 因为：Java使用关键字synchronized来实现执行线程的互斥处理。 在方法前加synchronized关键字，每次只允许一个线程处理该方法。 针对该案例添加了synchronized方法：在线程A执行pass方法时，线程B就无法再执行pass方法，会阻塞在pass方法的入口处，直到线程A执行释放了pass方法的锁，线程B才可以去获取pass方法的锁，获得锁后再执行。 扩展相关的设计模型许多与多线程、并发性相关的模式都跟Single Threaded Execution模式有关联。 Guarded Suspension模式Guarded Suspension模式：如果执行现在的处理会造成问题，就让执行处理的线程等待。这种模式通过让线程等待来保证实例的安全性。 在Single Threaded Execution模式中，是否发生线程等待取决于是否有其他线程正在执行受保护的unsafeMethod。而在Guarded Suspension模式中，取决于对象的状态是否合适。在检查对象状态的部分就使用了STE模式。 Read-Write Lock模式在Read-Write Lock模式中，读取操作和写入操作是分开考虑的。在执行读取操作之前，线程必须获取用于读取的锁；在执行写入操作之前，线程必须获取用于写入的锁。所以： 当一个线程在读取时，其他线程可以读取，但是不可以写入。 当一个线程正在写入时，其他线程不可以读取或写入。因为执行互斥处理会降低程序的性能，但是如果把写入的互斥处理和读取的互斥处理分开来考虑，就可以提高系统性能。 在STE模式中，如受保护的unsafeMethod正在被一个线程执行，那么想要执行该方法的其他线程必须等待该线程执行结束。 而Read-Write Lock模式中，多个线程可以同时执行read方法，这时需要等待的只有想要执行的write方法的线程。在Read-Write Lock模式中，检查线程种类和个数部分，就使用了STE模式。 Immutable模式一个对象的状态在对象被创建之后就不再变化，这就是所谓的不变模式。在STE模式中，unsafeMethod必须要加以保护，确保只允许一个线程执行。而在Immutable不变模式中，其对象的状态不会发生变化，所以所有方法都不需要进行保护，也就是Immutable模式中的所有方法都是safeMethod。 Thread-Specific Storage模式在STE模式中，会有多个线程访问SharedResource角色，所以需要保护方法，对线程进行交通管制。而Thread-Specific Storage模式会确保每个线程都有其固有的区域，且这块固有区域仅由一个线程访问。所以也无需保护方法。如:ThreadLocal类 一个线程会有自己独立的储物柜。 信号量：SemaphoreSTE模式用于确保某个区域只能由一个线程来执行。如果保证某个区域最多只能由N个线程执行，那就需要使用juc包下的计数信号量Semaphore来控制线程数量。 资源的许可个数permits通过Semaphore的构造函数来制定：123public Semaphore(int permits, boolean fair) &#123; sync = fair ? new FairSync(permits) : new NonfairSync(permits); &#125; acquire方法：用于确保存在可用资源。在存在可用资源时，程序会立即从acquire方法返回，同时信号量内部的资源个数会减1.如无可用资源，线程则阻塞在acquire方法内，直到有可用资源。 release方法：用于释放资源。释放资源后，信号量内部的资源个数会加1。同时，如果acquire中存在等待的线程，那么其中一个线程会被唤醒，并从acquire方法返回。 案例10个线程交替使用资源，但同时使用的资源最多只能是3个。 Main类：12345678public static void main(String[] args) &#123; // 设置3个资源 BoundedResource resource = new BoundedResource(3); // 10个线程交替使用资源，但同时使用的资源最多只能是3个 for (int i = 0; i &lt; 10; i++) &#123; new UserThread(resource).start(); &#125; &#125; 输出： 1234567Thread-0: -&gt; Begin: used &#x3D; NO.1Thread-1: -&gt; Begin: used &#x3D; NO.2Thread-2: -&gt; Begin: used &#x3D; NO.3Thread-2: &lt;--- End: used &#x3D; NO.3Thread-3: -&gt; Begin: used &#x3D; NO.3Thread-0: &lt;--- End: used &#x3D; NO.3... UserThread用户线程类： 123456789101112131415161718192021public class UserThread extends Thread &#123; private final static Random random = new Random(2020); private final BoundedResource resource; public UserThread(BoundedResource resource) &#123; this.resource = resource; &#125; @Override public void run() &#123; while (true) &#123; try &#123; this.resource.use(); TimeUnit.MILLISECONDS.sleep(random.nextInt(3000)); &#125; catch (InterruptedException e) &#123; e.printStackTrace(); &#125; &#125; &#125;&#125; BoundedResource使用资源类： 123456789101112131415161718192021222324252627public class BoundedResource &#123; private final Semaphore semaphore; private final int permits; private final static Random random = new Random(2020); public BoundedResource(int permits) &#123; this.semaphore = new Semaphore(permits); this.permits = permits; &#125; public void use() throws InterruptedException &#123; semaphore.acquire(); try &#123; doSomething(); &#125; finally &#123; semaphore.release(); &#125; &#125; private void doSomething() throws InterruptedException &#123; Log.println(\"-&gt; Begin: used = NO.\" + (this.permits - this.semaphore.availablePermits())); TimeUnit.MILLISECONDS.sleep(random.nextInt(1000)); Log.println(\"&lt;--- End: used = NO.\" + (this.permits - this.semaphore.availablePermits())); &#125;&#125; Log日志类： 123456public class Log &#123; public static void println(String s) &#123; System.out.println(Thread.currentThread().getName() + \": \" + s); &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://bubblewu.github.io/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://bubblewu.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"并发：多线程程序的评价标准","slug":"Java/并发/并发：多线程程序的评价标准","date":"2020-07-29T06:57:19.000Z","updated":"2020-08-18T07:25:07.681Z","comments":true,"path":"ckd70wo7j0017qlydgj2w1nq3/","link":"","permalink":"https://bubblewu.github.io/ckd70wo7j0017qlydgj2w1nq3/","excerpt":"针对多线程程序，我们不能单纯的来指出是好还是坏，需要遵循一定的评价标准来规范的指出好在哪里、差在哪里？ 其实也就是： 安全性和生存性：程序的必要条件； 可复用性和性能：提高程序质量条件；","text":"针对多线程程序，我们不能单纯的来指出是好还是坏，需要遵循一定的评价标准来规范的指出好在哪里、差在哪里？ 其实也就是： 安全性和生存性：程序的必要条件； 可复用性和性能：提高程序质量条件； 主要标准有下面四个主要标准： 安全性（Safety）：不损坏对象安全性就是不损坏对象，是程序正常执行的必要条件之一。对象损坏是指对象的状态和设计者的原意不一致，通常是指对象的字段的值并非预期值。如果一个类即使被多个线程同时使用，也可以确保安全性，那么这个类就是线程安全类（Thread Safe）。如集合类中的Vector类是线程安全的，而ArrayList类则是非线程安全的。 生存性（Liveness）：必要的处理能够被执行生存性是指无论什么时候，必要的处理都一定能够被执行。也是程序正常运行的必要条件之一。 需注意，即使对象没有损坏，也不一定代表程序一定好。如程序在运行过程中突然停止，而对象的状态未改变，所以对象的状态就不会出现异常，也就是符合了安全性条件，但是程序的执行无任何意义，不符合生存性的条件。 有时候安全性和生存性会互相制约。有时只重视安全性，生存性就会下降。典型代表就是死锁（deadlook），即多个线程互相等待对方释放锁的情形。 可复用性（Reusability）：类可重复利用可复用性是指类能够重复利用。是提高程序质量的必要条件。类如果能作为组件从正常运行的程序中分割出来，那么说明这个类有很高的可复用性。 性能（Performance）：能快速、大批量地执行处理性能是指能快速、大批量地执行处理。也是提高程序质量的必要条件。 影响性能的因素有多种： 吞吐量（throughpt）：指单位时间内完成的处理数量。能完成的处理越多，表示吞吐量越大。 响应性（responsiveness）：指从发出请求到收到响应的时间。响应性好即等待时间（latency）短。 容量（capacity）：指可以同时进行的处理数量。如服务器能同时处理的客户端数或文件数等。 效率（efficiency）： 可伸缩性（scalability）： 降级（degradation）： 有时这些要素之间会相互制约，如提高吞吐量，可能会导致程序的响应性下降。 总结安全性和生存性是程序必备的条件。即既不能损坏对象，也一定要执行必要的处理。在此基础之上，还需考虑如何提高程序的高可复用性和性能。","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://bubblewu.github.io/categories/Java/%E5%B9%B6%E5%8F%91/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://bubblewu.github.io/tags/%E5%B9%B6%E5%8F%91/"}]},{"title":"动手实现：检查程序名称规范的编译器插件","slug":"Java/动手实现：检查程序名称规范的编译器插件","date":"2020-07-28T10:23:19.000Z","updated":"2020-07-28T10:23:52.854Z","comments":true,"path":"ckd70wo70000bqlyd3k4v9lhx/","link":"","permalink":"https://bubblewu.github.io/ckd70wo70000bqlyd3k4v9lhx/","excerpt":"该案例主要为实现一个检查Java代码规范的编译器插件功能，编码规范遵循下面标准： 类或接口：符合驼式命名法，首字母大写。 方法：符合驼式命名法，首字母小写。 字段：类或实例变量。符合驼式命名法，首字母小写。常量。要求全部由大写字母或下划线构成，并且第一个字符不能是下划线。 驼式命名法（Camel Case Name）是当前Java语言中主流的命名规范，我们的实战目标就是为Javac编译器添加一个额外的功能，在编译程序时检查程序名是否符合上述对类（或接口）、方法、字段的命名要求。","text":"该案例主要为实现一个检查Java代码规范的编译器插件功能，编码规范遵循下面标准： 类或接口：符合驼式命名法，首字母大写。 方法：符合驼式命名法，首字母小写。 字段：类或实例变量。符合驼式命名法，首字母小写。常量。要求全部由大写字母或下划线构成，并且第一个字符不能是下划线。 驼式命名法（Camel Case Name）是当前Java语言中主流的命名规范，我们的实战目标就是为Javac编译器添加一个额外的功能，在编译程序时检查程序名是否符合上述对类（或接口）、方法、字段的命名要求。 编码实现AbstractProcessor抽象类实现注解处理器的代码需要继承抽象类javax.annotation.processing.AbstractProcessor，这个抽象类中只有一个子类必须实现的抽象方法process()。 它是Javac编译器在执行注解处理器代码时要调用的过程。 我们可以从这个方法的第一个参数annotations中获取到此注解处理器所要处理的注解集合； 从第二个参数roundEnv中访问到当前这个轮次（Round）中的抽象语法树节点，每个语法树节点在这里都表示为一个Element。 AbstractProcessor抽象类还有一个很重要的实例变量processingEnv。 1234/** * Processing environment providing by the tool framework. */protected ProcessingEnvironment processingEnv; 它是AbstractProcessor中的一个protected变量，在注解处理器初始化的时候（init()方法执行的时候）创建，继承了AbstractProcessor的注解处理器代码可以直接访问它。它代表了注解处理器框架提供的一个上下文环境，要创建新的代码、向编译器输出信息、获取其他工具类等都需要用到这个实例变量。 ElementKind枚举类在javax.lang.model.ElementKind中定义了17类Element，已经包括了Java代码中可能出现的全部元素。 javax.lang.model.ElementKind枚举类：1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586import javax.lang.model.element.Element;public enum ElementKind &#123; /** 包 */ PACKAGE, // Declared types /** 枚举 */ ENUM, /** 类 */ CLASS, /** 注解 */ ANNOTATION_TYPE, /** * 接口 */ INTERFACE, // Variables /** 枚举值. */ ENUM_CONSTANT, /** * 字段值 */ FIELD, /** 参数 */ PARAMETER, /** 本地变量. */ LOCAL_VARIABLE, /** 异常. */ EXCEPTION_PARAMETER, // Executables /** 方法. */ METHOD, /** 构造函数. */ CONSTRUCTOR, /** 静态语句块 即static&#123;&#125;块. */ STATIC_INIT, /** 实例语句块 即&#123;&#125;块. */ INSTANCE_INIT, /** 参数化类型：泛型尖括号内的类型. */ TYPE_PARAMETER, /** * 未定义的其他语法树节点 */ OTHER, /** * 资源变量：try-resource中定义d变量. */ RESOURCE_VARIABLE; /** * Returns &#123;@code true&#125; if this is a kind of class: * either &#123;@code CLASS&#125; or &#123;@code ENUM&#125;. * * @return &#123;@code true&#125; if this is a kind of class */ public boolean isClass() &#123; return this == CLASS || this == ENUM; &#125; /** * Returns &#123;@code true&#125; if this is a kind of interface: * either &#123;@code INTERFACE&#125; or &#123;@code ANNOTATION_TYPE&#125;. * * @return &#123;@code true&#125; if this is a kind of interface */ public boolean isInterface() &#123; return this == INTERFACE || this == ANNOTATION_TYPE; &#125; /** * Returns &#123;@code true&#125; if this is a kind of field: * either &#123;@code FIELD&#125; or &#123;@code ENUM_CONSTANT&#125;. * * @return &#123;@code true&#125; if this is a kind of field */ public boolean isField() &#123; return this == FIELD || this == ENUM_CONSTANT; &#125;&#125; 两个注解注解处理器除了process()方法及其参数之外，还有两个经常配合着使用的注解，分别是： @SupportedAnnotationTypes：代表了这个注解处理器对哪些注解感兴趣，可以使用星号 * 作为通配符代表对所有的注解都感兴趣。 @SupportedSourceVersion：指出这个注解处理器可以处理哪些版本的Java代码。 每一个注解处理器在运行时都是单例的，如果不需要改变或添加抽象语法树中的内容，process()方法就可以返回一个值为false的布尔值，通知编译器这个轮次中的代码未发生变化，无须构造新的JavaCompiler实例，在这次实战的注解处理器中只对程序命名进行检查，不需要改变语法树的内容，因此process()方法的返回值一律都是false。 实现注解处理器NameCheckProcessor12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455package com.bubble.processor;import javax.annotation.processing.*;import javax.lang.model.SourceVersion;import javax.lang.model.element.TypeElement;import java.util.Set;/** * 插入式注解处理器：对Java程序命名进行检查 * * @author wugang * date: 2020-07-28 16:23 **/// 表示支持所有的Annotations@SupportedAnnotationTypes(\"*\")// 只支持JDK8的Java代码@SupportedSourceVersion(SourceVersion.RELEASE_8)public class NameCheckProcessor extends AbstractProcessor &#123; private NameChecker nameChecker; /** * 初始化名称检查插件 * * @param processingEnv 它是AbstractProcessor中的一个protected变量，在注解处理器初始化的时候（init()方法执行的时候）创建， * 继承了AbstractProcessor的注解处理器代码可以直接访问它。 * 它代表了注解处理器框架提供的一个上下文环境，要创建新的代码、向编译器输出信息、获取其他工具类等都需要用到这个实例变量 */ @Override public void init(ProcessingEnvironment processingEnv) &#123; super.init(processingEnv); nameChecker = new NameChecker(processingEnv); &#125; /** * 对输入的语法树的各个节点进行名称检查 * * 该方法是Javac编译器在执行注解处理器代码时要调用的过程： * 每一个注解处理器在运行时都是单例的，如果不需要改变或添加抽象语法树中的内容， * process() 方法就可以返回一个值为false的布尔值，通知编译器这个轮次中的代码未发生变化，无须构造新的 JavaCompiler实例。 * 自定义的此注解处理器中只对程序命名进行检查，不需要改变语法树的内容，因此process()方法的返回值一律都是false。 * * @param annotations 获取到此注解处理器所要处理的注解集合 * @param roundEnv 参数“roundEnv”中访问到当前这个轮次（Round）中的抽象语法树节点， * 每个语法树节点在这里都表示为一个Element。 * 在javax.lang.model.ElementKind中定义了18类Element。 * @return false */ @Override public boolean process(Set&lt;? extends TypeElement&gt; annotations, RoundEnvironment roundEnv) &#123; if (!roundEnv.processingOver()) &#123; roundEnv.getRootElements().forEach(element -&gt; nameChecker.checkNames(element)); &#125; return false; &#125;&#125; 命名检查器NameChecker它通过一个继承于javax.lang.model.util.ElementScanner8的NameCheckScanner类，以Visitor模式来完成对语法树的遍历，分别执行visitType()、visitVariable()和visitExecutable()方法来访问类、字段和方法，这3个visit*()方法对各自的命名规则做相应的检查，checkCamelCase()与checkAllCaps()方法则用于实现驼式命名法和全大写命名规则的检查。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184package com.bubble.processor;import javax.annotation.processing.Messager;import javax.annotation.processing.ProcessingEnvironment;import javax.lang.model.element.*;import javax.lang.model.util.ElementScanner8;import java.util.EnumSet;import static javax.tools.Diagnostic.Kind.WARNING;/** * 检查程序名称规范的编译器插件： * 如果程序命名不符合规范，会输出一个编译器的WARNING信息 * * @author wugang * date: 2020-07-28 16:27 **/public class NameChecker &#123; /** * Messager用于向编译器发送信息 */ private final Messager messager; private NameCheckScanner nameCheckScanner = new NameCheckScanner(); public NameChecker(ProcessingEnvironment processingEnv) &#123; this.messager = processingEnv.getMessager(); &#125; /** * 对Java程序命名进行检查，根据《Java语言规范》Java程序命名应当符合下列格式： * - 类或接口：符合驼式命名法，首字母大写。 * - 方法：符合驼式命名法，首字母小写。 * - 字段： * 类或实例变量。符合驼式命名法，首字母小写。 * 常量。要求全部由大写字母或下划线构成，并且第一个字符不能是下划线。 * * @param element */ public void checkNames(Element element) &#123; nameCheckScanner.scan(element); &#125; /** * 名称检查器实现类。 * 继承了ElementScanner8，会以Visitor模式访问抽象语法树中的元素。 * 命名规则判断中将不对语法树进行修改，因此全部返回值都为null。 */ private class NameCheckScanner extends ElementScanner8&lt;Void, Void&gt; &#123; /** * 用于检查Java类 */ @Override public Void visitType(TypeElement e, Void p) &#123; scan(e.getTypeParameters(), p); checkCamelCase(e, true); super.visitType(e, p); return null; &#125; /** * 检查方法名是否合法 */ @Override public Void visitExecutable(ExecutableElement e, Void p) &#123; if (e.getKind() == ElementKind.METHOD) &#123; Name name = e.getSimpleName(); if (name.contentEquals(e.getEnclosingElement().getSimpleName())) &#123; messager.printMessage(WARNING, \"一个普通方法[\" + name + \"]不应当与类名重复，避免与构造函数产生冲突\"); checkCamelCase(e, false); &#125; &#125; super.visitExecutable(e, p); return null; &#125; /** * 检查变量命名是否合法 */ @Override public Void visitVariable(VariableElement e, Void p) &#123; // 如果这个Variable是枚举或常量，则按大写命名检查，否则按照驼式命名法规则检查 if (e.getKind() == ElementKind.ENUM_CONSTANT || e.getConstantValue() != null || heuristicallyConstant(e)) &#123; checkAllCaps(e); &#125; else &#123; checkCamelCase(e, false); &#125; return null; &#125; /** * 判断一个变量是否是常量 */ private boolean heuristicallyConstant(VariableElement e) &#123; if (e.getEnclosingElement().getKind() == ElementKind.INTERFACE) &#123; return true; &#125; else if (e.getKind() == ElementKind.FIELD || e.getModifiers().containsAll(EnumSet.of(Modifier.PUBLIC, Modifier.STATIC, Modifier.FINAL))) &#123; return true; &#125; return false; &#125; /** * 检查传入的Element是否符合驼式命名法，如果不符合，则输出警告信息 */ private void checkCamelCase(Element e, boolean initialCaps) &#123; String name = e.getSimpleName().toString(); // 前缀首字母大写 boolean previousUpper = false; boolean conventional = true; int firstCodePoint = name.codePointAt(0); if (Character.isUpperCase(firstCodePoint)) &#123; previousUpper = true; if (!initialCaps) &#123; messager.printMessage(WARNING, \"名称[\" + name + \"]应当以小写字母开头\", e); return; &#125; &#125; else if (Character.isLowerCase(firstCodePoint)) &#123; if (initialCaps) &#123; messager.printMessage(WARNING, \"名称[\" + name + \"]应当以大写字母开头\", e); return; &#125; &#125; else &#123; conventional = false; &#125; if (conventional) &#123; int cp = firstCodePoint; for (int i = Character.charCount(cp); i &lt; name.length(); i += Character.charCount(cp)) &#123; cp = name.codePointAt(i); if (Character.isUpperCase(cp)) &#123; if (previousUpper) &#123; conventional = false; break; &#125; previousUpper = true; &#125; else &#123; previousUpper = false; &#125; &#125; &#125; if (!conventional) &#123; messager.printMessage(WARNING, \"名称[\" + name + \"]应当符合驼式命名法（Camel Case Names）\", e); &#125; &#125; /** * 大写命名检查，要求第一个字母必须是大写的英文字母，其余部分可以是下划线或大写字母 */ private void checkAllCaps(Element e) &#123; String name = e.getSimpleName().toString(); boolean conventional = true; int firstCodePoint = name.codePointAt(0); if (!Character.isUpperCase(firstCodePoint)) &#123; conventional = false; &#125; else &#123; boolean previousUnderscore = false; int cp = firstCodePoint; for (int i = Character.charCount(cp); i &lt; name.length(); i += Character.charCount(cp)) &#123; cp = name.codePointAt(i); if (cp == (int) '_') &#123; if (previousUnderscore) &#123; conventional = false; break; &#125; previousUnderscore = true; &#125; else &#123; previousUnderscore = false; if (!Character.isUpperCase(cp) &amp;&amp; !Character.isDigit(cp)) &#123; conventional = false; break; &#125; &#125; &#125; &#125; if (!conventional) &#123; messager.printMessage(WARNING, \"常量[\" + name + \"]应当全部以大写字母或下划线命名，并且以字母开头\"); &#125; &#125; &#125;&#125; 编译测试命名规范的“反面教材”代码123456789101112131415161718192021222324252627282930package com.bubble.processor;/** * 命名规范的“反面教材”代码： * 使用： * 可以通过Javac命令的“-processor”参数来执行编译时需要附带的注解处理器， * 如果有多个注解 处理器的话，用逗号分隔。 * 还可以使用-XprintRounds和-XprintProcessorInfo参数来查看注解处理器运作的详细信息。 * * @author wugang * date: 2020-07-28 17:38 **/public class BADLY_NAMED_CODE &#123; enum colors &#123; red, blue, green; &#125; static final int _FORTY_TWO = 42; public static int NOT_A_CONSTANT = _FORTY_TWO; protected void BADLY_NAMED_CODE() &#123; return; &#125; public void NOTcamelCASEmethodNAME() &#123; return; &#125;&#125; 编译测试们可以通过Javac命令的-processor参数来执行编译时需要附带的注解处理器，如果有多个注解处理器的话，用逗号分隔。还可以使用-XprintRounds和-XprintProcessorInfo参数来查看注解处理器运 作的详细信息。 编译： 12345cd code/java/multi-dev/data-structure/src/main/java/javac com/bubble/processor/NameChecker.javajavac com/bubble/processor/NameCheckProcessor.javajavac -processor com.bubble.processor.NameCheckProcessor com/bubble/processor/BADLY_NAMED_CODE.java 输出： 123456789101112131415com&#x2F;bubble&#x2F;processor&#x2F;BADLY_NAMED_CODE.java:13: 警告: 名称[BADLY_NAMED_CODE]应当符合驼式命名法（Camel Case Names）public class BADLY_NAMED_CODE &#123; ^com&#x2F;bubble&#x2F;processor&#x2F;BADLY_NAMED_CODE.java:15: 警告: 名称[colors]应当以大写字母开头 enum colors &#123; ^警告: 常量[red]应当全部以大写字母或下划线命名，并且以字母开头警告: 常量[blue]应当全部以大写字母或下划线命名，并且以字母开头警告: 常量[green]应当全部以大写字母或下划线命名，并且以字母开头警告: 常量[_FORTY_TWO]应当全部以大写字母或下划线命名，并且以字母开头警告: 一个普通方法[BADLY_NAMED_CODE]不应当与类名重复，避免与构造函数产生冲突com&#x2F;bubble&#x2F;processor&#x2F;BADLY_NAMED_CODE.java:22: 警告: 名称[BADLY_NAMED_CODE]应当以小写字母开头 protected void BADLY_NAMED_CODE() &#123; ^8 个警告","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"Tool","slug":"Java/Tool","permalink":"https://bubblewu.github.io/categories/Java/Tool/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"Tool","slug":"Tool","permalink":"https://bubblewu.github.io/tags/Tool/"}]},{"title":"002 虚拟机对象","slug":"Java/JVM/002 虚拟机对象","date":"2020-06-29T10:32:19.000Z","updated":"2020-06-29T10:32:36.692Z","comments":true,"path":"ckd70wo7k0018qlyd6k1i1bxu/","link":"","permalink":"https://bubblewu.github.io/ckd70wo7k0018qlyd6k1i1bxu/","excerpt":"本文主要讲述HotSpot虚拟机在Java堆中对象分配、布局和访问的全过程。","text":"本文主要讲述HotSpot虚拟机在Java堆中对象分配、布局和访问的全过程。 虚拟机对象对象的创建对象的创建流程 使用new指令来创建对象； 首先检查这个指令的参数是否在常量池中定位到一个类的符号引用，并检查这个符号引用代表的类是否已经被加载、解析和初始化； 如果没有，说明是新建，就先执行相应的类加载的过程； 类加载检查通过后，为虚拟机新生对象分配堆内存； 堆内存分配成功后，再把分配到的内存空间（不包括对象头）都初始化为零值； 再执行类文件的()方法，按照Dev的设定来进行构造，把对象进行初始化，得到一个真正的对象。 对象的内存布局在HotSpot虚拟机里，对象在堆内存中的存储布局可以划分为三个部分：对象头(Header)、实例 数据(Instance Data)和对齐填充(Padding)。 对象头（Header）对象头包括两类信息：一是用于存储对象自身的运行时数据；二是类型指针。 1、存储对象自身的运行时数据如HashCode、GC分代年龄、锁状态标志、线程持有的锁、偏向线程ID、偏向时间戳等。这部分数据的长度在32位和64位的虚拟机(未开启压缩指针)中分别为32个比特和64个比特，官方称它为Mark Word。 Mark Word被设计成一个有着动态定义的数据结构，以便在极小的空间内存储尽量多的数据，根据对象的状态复用自己的存储空间。 2、类型指针对象头的另外一部分是类型指针，即对象指向它的类型元数据的指针，Java虚拟机通过这个指针来确定该对象是哪个类的实例。 并不是所有的虚拟机实现都必须在对象数据上保留类型指针，换句话说，查找对象的元数据信息并不一定要经过对象本身 如果对象是一个Java数组，那在对象头中还必须有一块用于记录数组长度的数。因为虚拟机可以通过普通 Java对象的元数据信息确定Java对象的大小，但是如果数组的长度是不确定的，将无法通过元数据中的 信息推断出数组的大小。 实例数据（Instance Data）实例数据是对象真正存储等有效信息。也就是我们所定义的各种类型的字段内容，无论是从父类继承下来的，还是在子类中定义的字段都必须记录起来。这部分的存储顺序会受到虚拟机分配策略参数(-XX:FieldsAllocationStyle参数)和字段在Java源码中定义顺序的影响。 HotSpot虚拟机默认的分配顺序为longs/doubles、ints、shorts/chars、bytes/booleans、oops(Ordinary Object Pointers，OOPs)，由上可知：相同宽度的字段总是被分配到一起存放，在满足这个前提条件的情况下，在父类中定义的变量会出现在子类之前。如果HotSpot虚拟机的 +XX:CompactFields参数值为true(默认就为true)，那子类之中较窄的变量也允许插入父类变量的空隙之中，以节省出一点点空间。 对齐填充（Padding）对齐填充不是必然存在的，它仅仅起着占位符的作用。由于HotSpot虚拟机的自动内存管理系统要求对象起始地址必须是8字节的整数倍。换句话说就是任何对象的大小都必须是8字节的整数倍。对象头部分已经被精心设计成正好是8字节的倍数(1倍或者2倍)，因此，如果对象实例数据部分没有对齐的话，就需要通过对齐填充来补全。 对象的访问定位创建了对象就需要使用它，Java Dev会通过栈上的reference数据来操作堆上的具体对象。由于reference类型在《Java虚拟机规范》里面只规定了它是一个指向对象的引用，并没有定义这个引用应该通过什么方式去定位、访问到堆中对象的具体位置。所以对象访问方式也是由虚拟机实现而定的，主流的访问方式主要有使用句柄和直接指针两种。 两种方式使用句柄访问对象如果使用句柄访问的话，Java堆中将可能会划分出一块内存来作为句柄池，reference中存储的就是对象的句柄地址，而句柄中包含了对象实例数据与类型数据各自具体的地址信息。 使用直接指针访问对象如果使用直接指针访问的话，Java堆中对象的内存布局就必须考虑如何放置访问类型数据的相关信息，reference中存储的直接就是对象地址，如果只是访问对象本身的话，就不需要多一次间接访问的开销。 对比 使用句柄来访问的最大好处就是reference中存储的是稳定句柄地址，在对象被移动（垃圾收集时移动对象是非常普遍的行为）时只会改变句柄中的实例数据指针，而reference本身不需要被修改。 使用直接指针来访问最大的好处就是速度更快，它节省了一次指针定位的时间开销，由于对象访 问在Java中非常频繁，因此这类开销积少成多也是一项极为可观的执行成本。","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://bubblewu.github.io/categories/Java/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://bubblewu.github.io/tags/JVM/"}]},{"title":"String类的intern()方法","slug":"Java/String类的intern()方法","date":"2020-06-14T07:52:19.000Z","updated":"2020-06-14T08:15:44.917Z","comments":true,"path":"ckd70wo6w0009qlyd1yu5dnit/","link":"","permalink":"https://bubblewu.github.io/ckd70wo6w0009qlyd1yu5dnit/","excerpt":"概述String::intern()是一个Native方法，用于返回该对象在常量池中的引用。 1public native String intern(); 作用：如果字符串常量池中已经包含一个等于该String对象的字符串，则返回代表池中这个字符串的String对象的引用；否则，会将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。","text":"概述String::intern()是一个Native方法，用于返回该对象在常量池中的引用。 1public native String intern(); 作用：如果字符串常量池中已经包含一个等于该String对象的字符串，则返回代表池中这个字符串的String对象的引用；否则，会将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。 案例 示例1： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * - 在JDK 6中运行，会得到三个false； * 在JDK 6中，intern()方法会把首次遇到的字符串实例复制到永久代（方法区）的字符串常量池中存储， * 返回的也是永久代里面这个字符串实例的引用，而由StringBuilder创建的字符串对象实例在Java堆上， * 所以必然不可能是同一个引用，结果将返回false。 * * - 而在JDK 7后中运行，会得到一个true、一个false和一个true； * 因为JDK7中，intern()方法实现就不需要再拷贝字符串的实例到永久代了，既然字符串常量池已经移到Java堆中， * 那只需要在常量池里记录一下首次出现的实例引用即可。 * 因此intern()返回的引用和由StringBuilder创建的那个字符串实例就是同一个。 * 而对str2比较返回false，这是因为java这个字符串在执行StringBuilder()之前就已经出现过了，(在加载sun.misc.Version这个类的时候进入常量池的) * 字符串常量池中已经有它的引用，不符合intern()方法要求“首次遇到”的原则，“JVM调优”这个字符串则是首次出现的，因此结果返回true。 * 而str3和str1一样，\"JDKJVM\"这个字符串则是首次出现。 * */private static void compare() &#123; String str1 = new StringBuilder().append(\"JVM\").append(\"调优\").toString(); System.out.println(str1.intern() == str1); // java这个字符串在执行StringBuilder()之前就已经出现过了，在加载sun.misc.Version这个类的时候进入常量池的。 /* * 参考：https://www.zhihu.com/question/51102308/answer/124441115 * sun.misc.Version类会在JDK类库的初始化过程中被加载并初始化， * 而在初始化时它需要对静态常量字段根据指定的常量值（ConstantValue）做默认初始化， * 此时被 sun.misc.Version.launcher 静态常量字段所引用的\"java\"字符串字面量就被intern到HotSpot VM的字符串常量池StringTable里了。 */ String str2 = new StringBuilder().append(\"ja\").append(\"va\").toString(); System.out.println(str2.intern() == str2); // 而JDKJVM这个字符串则是首次出现 String str3 = new StringBuilder().append(\"JDK\").append(\"JVM\").toString(); System.out.println(str3.intern() == str3);&#125;/** * java中的String是引用类型。创建的String对象，实际上存储的是一个地址。 * 所以下面a和b都是引用类型，其存储的是字符串的地址。它们本身存储在Java虚拟机栈的局部变量表中。 * - a：直接将字符串存储在常量池中，然后将a指向常量池种中的\"JVM\"。 * - b：先将字符串\"JVM\"存储在常量池中，然后在heap中创建一个对象，该对象指向常量池中的\"JVM\"，最后将b指向heap中创建的这个对象。 * * 也就是说，a和b存储的内容是一样的，都是\"JVM\"，但地址不一样：a中保存的是常量池中\"JVM\"的地址，b保存的是heap中那个对象的地址， * * 双等于号\"==\"比较的是地址，equals()比较的是内容。 */private static void compareStr() &#123; String a = \"JVM\"; // new一个对象 String b = new String(\"JVM\"); // == 比较地址是否相等 // 都在运行时常量池中 System.out.println(\"JVM\" == a); // true System.out.println(a.intern() == a); // true // a为字符字面量（存储在运行时常量池中），b为对象（存储在堆中），所以不等。 System.out.println(a == b); // false System.out.println(a.intern() == b); // false System.out.println(a.equals(b)); // true&#125; 示例2：123456789101112131415161718public static void main(String[] args) &#123; /* 双等号\"==\"比较的是地址；equals()比较的是内容。 */ String s1 = \"abc\"; String s2 = \"abc\"; System.out.println(s1 == s2); // true System.out.println(s1.equals(s2)); // true String s3 = new String(\"abc\"); System.out.println(s1 == s3); // false System.out.println(s1.equals(s3)); // true System.out.println(s1 == s3.intern()); // true String s4 = new String(\"abc\"); System.out.println(s3 == s4); // false System.out.println(s3.intern() == s4.intern()); // true &#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"}]},{"title":"基于Neo4j的时光网电影数据可视化【附源码】","slug":"Neo4j/基于Neo4j的时光网电影数据可视化【附源码】","date":"2020-06-11T12:32:19.000Z","updated":"2020-07-29T06:59:22.770Z","comments":true,"path":"ckd70wo74000fqlydd4c020y6/","link":"","permalink":"https://bubblewu.github.io/ckd70wo74000fqlydd4c020y6/","excerpt":"基于Neo4j的电影数据可视化本文主要内容为： 基于requests + BeautifulSoup抓取时光网电影数据； 基于电影数据构建电影和关系实体信息； 数据导入neo4j进行存储分析； 基于Bottle框架的对neo4j数据进行查询可视化展示。 效果展示：","text":"基于Neo4j的电影数据可视化本文主要内容为： 基于requests + BeautifulSoup抓取时光网电影数据； 基于电影数据构建电影和关系实体信息； 数据导入neo4j进行存储分析； 基于Bottle框架的对neo4j数据进行查询可视化展示。 效果展示： 环境配置新建虚拟环境并安装所需包 新建虚拟环境：12345678# 查看本机已经安装的python虚拟环境conda env list# 新建graph-37环境conda create -n graph-37 python&#x3D;3.7# 生效新建的虚拟环境conda activate graph-37## 退出#conda deactivate 安装所需包：根据requirements.txt文件来安装：1pip install -r requirements.txt requirements.txt文件：12345678910111213141516171819202122232425beautifulsoup4&#x3D;&#x3D;4.9.1bs4&#x3D;&#x3D;0.0.1certifi&#x3D;&#x3D;2020.4.5.1chardet&#x3D;&#x3D;3.0.4Click&#x3D;&#x3D;7.0colorama&#x3D;&#x3D;0.4.3et-xmlfile&#x3D;&#x3D;1.0.1idna&#x3D;&#x3D;2.9jdcal&#x3D;&#x3D;1.4.1lxml&#x3D;&#x3D;4.5.1neobolt&#x3D;&#x3D;1.7.17neotime&#x3D;&#x3D;1.7.4numpy&#x3D;&#x3D;1.18.5openpyxl&#x3D;&#x3D;3.0.3pandas&#x3D;&#x3D;1.0.4prompt-toolkit&#x3D;&#x3D;2.0.10py2neo&#x3D;&#x3D;4.3.0Pygments&#x3D;&#x3D;2.3.1python-dateutil&#x3D;&#x3D;2.8.1pytz&#x3D;&#x3D;2020.1requests&#x3D;&#x3D;2.23.0six&#x3D;&#x3D;1.15.0soupsieve&#x3D;&#x3D;2.0.1urllib3&#x3D;&#x3D;1.24.3wcwidth&#x3D;&#x3D;0.2.4 数据获取本文数据来自时光网电影Top100。基于python对该源进行数据抓取，并将数据生成相应的实体和关系：可参考：GitHub：时光网数据抓取处理 实体和关系如下：： 电影： 1234index:ID,rank,src,name,movie_en,year,image,:LABEL10000,1,http:&#x2F;&#x2F;movie.mtime.com&#x2F;12231&#x2F;,肖申克的救赎,The Shawshank Redemption,1994,http:&#x2F;&#x2F;img31.mtime.cn&#x2F;mt&#x2F;2014&#x2F;03&#x2F;07&#x2F;123549.37376649_96X128.jpg,电影表10001,2,http:&#x2F;&#x2F;movie.mtime.com&#x2F;99547&#x2F;,盗梦空间,Inception,2010,http:&#x2F;&#x2F;img31.mtime.cn&#x2F;mt&#x2F;2014&#x2F;01&#x2F;06&#x2F;105446.89493583_96X128.jpg,电影表... 演员： 123456index:ID,actor,:LABEL30000,杰伊·巴鲁切尔,演员表30001,维果·莫腾森,演员表30002,布拉德·皮特,演员表30003,李·科布,演员表... 导演： 123456index:ID,director,:LABEL20000,彼得·索恩,导演表20001,克里斯托弗·诺兰,导演表20002,朴赞郁,导演表20003,赛尔乔·莱昂内,导演表... 关系： 电影与导演关系： 12345:START_ID,:END_ID,relation,:TYPE20069,10000,导演,导演20001,10001,导演,导演20010,10002,导演,导演... 电影与主演关系： 123456:START_ID,:END_ID,relation,:TYPE30156,10000,主演,主演30026,10000,主演,主演30063,10001,主演,主演30031,10001,主演,主演... 导演和演员关系： 12345:START_ID,:END_ID,relation,:TYPE20069,30156,相关,相关20069,30026,相关,相关20001,30063,相关,相关... Neo4j存储数据导入必须停止neo4j；只能生成新的数据库，而不能在已存在的数据库中插入数据。 通过下面的命令导入定义好的实体和关系数据： 123456789101112131415161718192021222324252627282930313233#!&#x2F;bin&#x2F;sh# 脚本来执行将csv文件（节点和关系）导入neo4j# 注意：必须停止neo4j；只能生成新的数据库，而不能在已存在的数据库中插入数据。db_name&#x3D;MovieMTime.dbneo4j_path&#x3D;&#x2F;Users&#x2F;wugang&#x2F;env&#x2F;neo4j-community-4.0.4base_path&#x3D;&#x2F;Users&#x2F;wugang&#x2F;code&#x2F;python&#x2F;moive-kg&#x2F;data&#x2F;mtimeimport() &#123; cd $&#123;neo4j_path&#125; .&#x2F;bin&#x2F;neo4j stop rm -rf &#x2F;Users&#x2F;wugang&#x2F;env&#x2F;neo4j-community-4.0.4&#x2F;data&#x2F;databases&#x2F;$&#123;db_name&#125; .&#x2F;bin&#x2F;neo4j-admin import --verbose \\ --database $&#123;db_name&#125; \\ --id-type STRING \\ --input-encoding&#x3D;UTF-8 \\ --ignore-extra-columns&#x3D;false \\ --trim-strings&#x3D;true \\ --delimiter&#x3D;, \\ --array-delimiter&#x3D;&#39;;&#39; \\ --processors&#x3D;4 \\ --nodes $&#123;base_path&#125;&#x2F;mtime_movie_entity.csv \\ --nodes $&#123;base_path&#125;&#x2F;mtime_actor_entity.csv \\ --nodes $&#123;base_path&#125;&#x2F;mtime_director_entity.csv \\ --relationships $&#123;base_path&#125;&#x2F;mtime_director_actor_relationship.csv \\ --relationships $&#123;base_path&#125;&#x2F;mtime_movie_actor_relationship.csv \\ --relationships $&#123;base_path&#125;&#x2F;mtime_movie_director_relationship.csv # 需要修改neo4j.conf配置文件中的默认db才能展示新建的db，否则还是默认的。（只能指定一个db）# .&#x2F;bin&#x2F;neo4j start# .&#x2F;bin&#x2F;neo4j stop&#125;import 数据查看修改配置将默认db改为刚才新建的电影的db，否则还是默认的库。vim conf/neo4j.conf 1dbms.active_database&#x3D;MovieMTime.db 启动neo4j服务（neo4j版本为4.0.3）: 1.&#x2F;bin&#x2F;neo4j start 进入管理界面：http://127.0.0.1:7474 查看实体数据： 查看关系数据： 数据查询可视化查询可视化基于Bottle框架的Web服务。参考：GitHub: 可视化 效果如下图： 源码地址 movie-neo4j","categories":[{"name":"Neo4j","slug":"Neo4j","permalink":"https://bubblewu.github.io/categories/Neo4j/"},{"name":"Python","slug":"Python","permalink":"https://bubblewu.github.io/categories/Python/"}],"tags":[{"name":"Neo4j","slug":"Neo4j","permalink":"https://bubblewu.github.io/tags/Neo4j/"},{"name":"Python","slug":"Python","permalink":"https://bubblewu.github.io/tags/Python/"}]},{"title":"001 运行时数据区域和OutOfMemoryError异常","slug":"Java/JVM/001 运行时数据区域和OutOfMemoryError异常","date":"2020-06-09T02:52:19.000Z","updated":"2020-06-29T11:00:01.226Z","comments":true,"path":"ckd70wo7m001aqlyd0ltzhlb8/","link":"","permalink":"https://bubblewu.github.io/ckd70wo7m001aqlyd0ltzhlb8/","excerpt":"本文主要讲解JVM运行时数据区域，并通过简单的案例来实现说明各个区域中的常见OOM异常。","text":"本文主要讲解JVM运行时数据区域，并通过简单的案例来实现说明各个区域中的常见OOM异常。 运行时数据区域运行时数据区域图： Java内存区域：JVM内存区域主要分为线程私有区域【程序计数器、虚拟机栈、本地方法栈】、线程共享区域【Java堆、方法区】、直接内存。 线程私有区域：线程私有数据区域生命周期与线程相同, 依赖用户线程的启动/结束 而 创建/销毁(在Hotspot VM内,每个线程都与操作系统的本地线程直接映射, 因此这部分内存区域的存/否跟随本地线程的生/死对应)。 线程共享区域：线程共享区域随虚拟机的启动/关闭而创建/销毁。 JVM主要区域溢出异常在Java虚拟机规范中规定，除了程序计数器外，虚拟机的其他几个运行时区域都有发生OOM异常的可能，如：方法区（运行时常量池）、Java堆、虚拟机栈（局部变量表）、本地方法栈和直接内存。 下面将通过案例来验证各个运行时区域的溢出异常，并分析我们来如何解决和避免这些异常。 注：下面的代码基于JDK8进行开发测试； 线程独占区程序计数器（无OOM）程序计数器（Program Counter Register）是一块较小的内存空间, 是当前线程所执行的字节码的行号指示器，每条线程都要有一个独立的程序计数器，这类内存也称为线程私有的内存。 正在执行java方法的话，计数器记录的是虚拟机字节码指令的地址(当前指令的地址)。 如果是Native方法，则为空（undefined）。 这个内存区域是唯一一个在虚拟机中没有规定任何OutOfMemoryError 情况的区域。 虚拟机栈和本地方法栈溢出虚拟机栈虚拟机栈描述的是Java方法执行的线程内存模型。 栈帧（Stack Frame）：每个方法被执行的时候，Java虚拟机都会同步创建一个栈帧用于存储局部变量表、操作数栈、动态连接、方法出口等信息。每一个方法被调用直至执行完毕的过程，就对应着一个栈帧在虚拟机栈中从入栈到出栈的过程。 局部变量表：局部变量表存放了编译期可知的： 各种Java虚拟机基本数据类型：boolean、byte、char、short、int、 float、long、double； 对象引用 ：reference类型，它并不等同于对象本身，可能是一个指向对象起始地址的引用指针，也可能是指向一个代表对象的句柄或者其他与此对象相关的位置； returnAddress类型：指向了一条字节码指令的地址。 这些数据类型在局部变量表中的存储空间以局部变量槽(Slot)来表示。其中64位长度的long和double类型的数据会占用两个变量槽，其余的数据类型只占用一个。局部变量表所需的内存空间在编译期间完成分配，当进入一个方法时，这个方法需要在栈帧中分配多大的局部变量空间是完全确定 的，在方法运行期间不会改变局部变量表的大小。 两种异常：栈/堆溢出 如果线程请求的栈深度大于虚拟机所允许的深度，将抛出StackOverflowError异常； 如果Java虚拟机栈容量可以动态扩展，当栈扩展时无法申请到足够的内存会抛出OutOfMemoryError异常。 虚拟机栈&amp;本地方法栈Java虚拟机栈（Java Virtual Machine Stack）和本地方法栈（Native Method Stacks）非常相似，都属于线程独占区，区别是： 虚拟机栈为虚拟机执行Java方法（也就是字节码）服务； 本地方法栈为虚拟机使用到的本地方法（Native方法）服务； Hot-Spot虚拟机直接就把本地方法栈和虚拟机栈合二为一。与虚拟机栈一样，本地方法栈也会在栈深度溢出或者栈扩展失败时分别抛出StackOverflowError和OutOfMemoryError异常。 虚拟机栈和本地方法栈溢出案例栈容量参数：-XssHotSpot虚拟机中并不区分虚拟机栈和本地方法栈，因此对于HotSpot来说，-Xoss参数(设置本地方法栈大小)虽然存在，但实际上是没有任何效果的，栈容量只能由-Xss参数来设定。 栈/堆溢出的场景《Java虚拟机规范》明确允许Java虚拟机实现自行选择是否支持栈的动态扩展，而HotSpot虚拟机的选择是不支持扩展。所以除非在创建线程申请内存时就因无法获得足够内存而出现 OutOfMemoryError异常，否则在线程运行时是不会因为扩展而导致内存溢出的，只会因为栈容量无法容纳新的栈帧而导致StackOverflowError异常。 测试案例将实验范围限制在单线程中操作，尝试下面两种行为是否能让HotSpot虚拟机产生OutOfMemoryError异常： 使用-Xss参数减少栈内存容量。结果：抛出StackOverflowError异常，异常出现时输出的堆栈深度相应缩小。 定义大量的本地变量，增大此方法帧中本地变量表的长度。结果：抛出StackOverflowError异常，异常出现时输出的堆栈深度相应缩小。 单线程下：使用-Xss参数减少栈内存容量（SOF异常）12345678910111213141516171819202122232425262728/** * Java虚拟机栈和本地方法机栈异常（单线程操作下） * VM Args: -Xss160k（Mac 64Bit要求最低栈内存为160K） * 使用-Xss参数减少栈内存容量。 * 结果：抛出StackOverflowError异常，异常出现时输出的堆栈深度相应缩小。 * * @author wugang * date: 2020-06-04 15:23 **/public class VMStackSOF &#123; private int stackLength = 1; private void stackLeak() &#123; stackLength++; stackLeak(); &#125; public static void main(String[] args) &#123; VMStackSOF stackSOF = new VMStackSOF(); try &#123; stackSOF.stackLeak(); &#125; catch (Throwable e) &#123; System.out.println(\"stack length: \" + stackSOF.stackLength); throw e; &#125; &#125;&#125; 输出： 1234stack length: 773Exception in thread &quot;main&quot; java.lang.StackOverflowError at com.bubble.jvm.error.VMStackSOF.stackLeak(VMStackSOF.java:16)... 单线程下：定义大量的本地变量，增大此方法帧中本地变量表的长度（SOF异常）1234567891011121314151617181920212223242526272829303132333435363738/** * Java虚拟机栈和本地方法机栈异常（单线程操作下） * 定义大量的本地变量，增大此方法帧中本地变量表的长度 * 结果：抛出StackOverflowError异常，异常出现时输出的堆栈深度相应缩小。 * * @author wugang * date: 2020-06-04 15:23 **/public class VMStackSOF02 &#123; private static int stackLength = 1; public static void test() &#123; long unused1, unused2, unused3, unused4, unused5, unused6, unused7, unused8, unused9, unused10, unused11, unused12, unused13, unused14, unused15, unused16, unused17, unused18, unused19, unused20, unused21, unused22, unused23, unused24, unused25, unused26, unused27, unused28, unused29, unused30, unused31, unused32, unused33, unused34, unused35, unused36, unused37, unused38, unused39, unused40, unused41, unused42, unused43, unused44, unused45, unused46, unused47, unused48, unused49, unused50, unused51, unused52, unused53, unused54, unused55, unused56, unused57, unused58, unused59, unused60, unused61, unused62, unused63, unused64, unused65, unused66, unused67, unused68, unused69, unused70, unused71, unused72, unused73, unused74, unused75, unused76, unused77, unused78, unused79, unused80, unused81, unused82, unused83, unused84, unused85, unused86, unused87, unused88, unused89, unused90, unused91, unused92, unused93, unused94, unused95, unused96, unused97, unused98, unused99, unused100; stackLength++; test(); unused1 = unused2 = unused3 = unused4 = unused5 = unused6 = unused7 = unused8 = unused9 = unused10 = unused11 = unused12 = unused13 = unused14 = unused15 = unused16 = unused17 = unused18 = unused19 = unused20 = unused21 = unused22 = unused23 = unused24 = unused25 = unused26 = unused27 = unused28 = unused29 = unused30 = unused31 = unused32 = unused33 = unused34 = unused35 = unused36 = unused37 = unused38 = unused39 = unused40 = unused41 = unused42 = unused43 = unused44 = unused45 = unused46 = unused47 = unused48 = unused49 = unused50 = unused51 = unused52 = unused53 = unused54 = unused55 = unused56 = unused57 = unused58 = unused59 = unused60 = unused61 = unused62 = unused63 = unused64 = unused65 = unused66 = unused67 = unused68 = unused69 = unused70 = unused71 = unused72 = unused73 = unused74 = unused75 = unused76 = unused77 = unused78 = unused79 = unused80 = unused81 = unused82 = unused83 = unused84 = unused85 = unused86 = unused87 = unused88 = unused89 = unused90 = unused91 = unused92 = unused93 = unused94 = unused95 = unused96 = unused97 = unused98 = unused99 = unused100 = 0; &#125; public static void main(String[] args) &#123; try &#123; test(); &#125; catch (Throwable e) &#123; System.out.println(\"stack length: \" + stackLength); throw e; &#125; &#125;&#125; 输出： 1234stack length: 8121Exception in thread &quot;main&quot; java.lang.StackOverflowError at com.bubble.jvm.error.VMStackSOF02.test(VMStackSOF02.java:26)... 多线程下：OOM异常12345678910111213141516171819202122232425262728/** * 多线程下，Java虚拟机栈和本地方法栈OOM异常 * VM Args:-Xss2M * * @author wugang * date: 2020-06-04 16:38 **/public class VMStackOOM &#123; private void dontStop() &#123; while (true) &#123; &#125; &#125; public void stackLeakByThread() &#123; while (true) &#123; Thread thread = new Thread(() -&gt; dontStop()); thread.start(); &#125; &#125; public static void main(String[] args) &#123; VMStackOOM vmStackOOM = new VMStackOOM(); vmStackOOM.stackLeakByThread(); &#125;&#125; 输出： 1Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: unable to create native thread 结论实验结果表明： 单线程下： 无论是由于栈帧太大还是虚拟机栈容量太小，当新的栈帧内存无法分配的时候，HotSpot虚拟机抛出的都是StackOverflowError异常。如果在允许动态扩展栈容量大小的虚拟机上，相同代码则会导致不一样的情况，如第二个代码（定义大量的本地变量，增大此方法帧中本地变量表的长度）示例就会抛出OutOfMemoryError异常。 多线程下：如果通过不断建立线程的方式，在HotSpot上也是可以产生内存溢出异常的，如第三个代码。但是这样产生的内存溢出异常和栈空间是否足够并不存在任何直接的关系，主要取决于操作系统本身的内存使用状态。甚至可以说，在这种情况下，给每个线程的栈分配的内存越大，反而越容易产生内存溢出异常。 因为：操作系统分配给每个进程的内存是有限制的。如32位Windows的单个进程最大内存限制为2GB。HotSpot虚拟机提供了参数可以控制Java堆和方法区这两部分的内存的最大值，那剩余的内存（由虚拟机栈和本地方法栈来分配的内存）为2GB(操作系统限制)减去最大堆容量，再减去最大方法区容量。 注意：由于程序计数器消耗内存很小，可以忽略掉，如果把直接内存和虚拟机进程本身耗费的内存也去掉的话。 因此为每个线程分配到的栈内存越大，可以建立的线程数量自 然就越少，建立线程时就越容易把剩下的内存耗尽。 通过减少内存的手段来解决内存溢出的方式：如果是建立过多线程导致的内存溢出，在不能减少线程数量或者更换64位虚拟机的情况下，就只通过减少最大堆和减少栈容量来换取更多的线程。 线程共享区Java堆溢出概念Java堆（Java Heap）是虚拟机管理的内存中的最大一块区域，也是垃圾回收的主要区域，它属于线程共享区，用于存储对象实例。 Java堆时垃圾收集器管理的内存区域Java堆也被称为GC堆（Garbage Collected Heap）。 从回收内存角度来看：垃圾收集器大部分都是基于分代收集理论设计的，会有 新生代、老年代、永久代（JDK8改为元空间）、Eden空间、From Survivor空间、To Survivor空间等名词。这些区域划分仅仅是一部分垃圾收集器的共同特性或者说设计风格，而非某个Java虚拟机具体实现的固有内存布局，更不是《Java虚拟机规范》里对Java堆的进一步细致划分。 从分配内存角度来看：所有线程共享的Java堆中可以划分出多个线程私有的分配缓冲区（TLAB, Thread Local Allocation Buffer），可以提升对象分配时的效率。不过无论从什么角度，无论如 何划分，都不会改变Java堆中存储内容的共性，无论是哪个区域，存储的都只能是对象的实例，将Java 堆细分的目的只是为了更好地回收内存，或者更快地分配内存。 物理存储空间Java堆可以处于物理上不连续的内存空间中，但在逻辑上它应该被视为连续的。就像我们用磁盘空间去存储文件一样，并不要求每个文件都连续存放。 注意：但对于大对象(典型的如数组对象)，多数虚拟机实现出于实现简单、存储高效的考虑，很可能会要求连续的内存空间。 配置参数Java堆可以设置为固定大小，也可以为可动态扩展的。通过参数-Xmx和-Xms来设定堆的最大和最小内存容量。将堆的最小值-Xms参数与最大值-Xmx参数设置为一样即可避免堆自动扩展。 如果在Java堆中没有内存完成实例分配，并且堆也无法再扩展时，Java虚拟机将会抛出OutOfMemoryError异常。 为什么会堆溢出？当我们不断地创建新对象时，并且使GC Roots到对象之间有可达路径来避免垃圾回收机制清除这些对象，这时候，对象数量不断增加，总容量超过最大堆的容量限制后，就会发生内存溢出异常。 OMM的两种情况可以通过内存映像分析工具对dump出的堆存储快照进行分析。首先应确认内存中导致OOM的对象是否是必要的，也就是要先分清楚到底是出现了内存泄漏(Memory Leak)还是内存溢出(Memory Overflow)。 内存泄露（Memory Leak）如果是内存泄漏（内存中的对象不是必须存活的，垃圾收集器未收集），可进一步通过工具查看泄漏对象到GC Roots的引用链，找到泄漏对象是通过怎 样的引用路径、与哪些GC Roots相关联，才导致垃圾收集器无法回收它们，根据泄漏对象的类型信息 以及它到GC Roots引用链的信息，一般可以比较准确地定位到这些对象创建的位置，进而找出产生内存泄漏的代码的具体位置。 内存溢出（Memory Overflow）如果不是内存泄漏，换句话说就是内存中的对象确实都是必须存活的，那就应当： 检查Java虚拟机的堆参数(-Xmx与-Xms)设置，与机器的内存对比，看看是否还有向上调整的空间。 再从代码上检查 是否存在某些对象生命周期过长、持有状态时间过长、存储结构设计不合理等情况，尽量减少程序运行期的内存消耗。 溢出案例和dump快照分析使用虚拟机参数： 1VM Args:-Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError 限制Java堆的大小为20M B，不可扩展。通过参数-XX:+HeapDumpOnOutOf-MemoryError可以让虚拟机在出现内存溢出异常的时候Dump出当前的内存堆转储快照，以便进行事后分析。(文件存储在该项目父目录下，如：java_pid80802.hprof) 12345678910111213141516/** * Java堆内存异常测试 * VM Args: -Xms20m -Xmx20m -XX:+HeapDumpOnOutOfMemoryError **/public class JavaHeapOOM &#123; private static class OOMObject &#123; &#125; public static void main(String[] args) &#123; List&lt;OOMObject&gt; list = Lists.newArrayList(); while (true) &#123; list.add(new OOMObject()); &#125; &#125;&#125; 输出： 1234567891011java.lang.OutOfMemoryError: Java heap spaceDumping heap to java_pid80802.hprof ...Heap dump file created [27964242 bytes in 0.193 secs]Exception in thread &quot;main&quot; java.lang.OutOfMemoryError: Java heap space at java.util.Arrays.copyOf(Arrays.java:3210) at java.util.Arrays.copyOf(Arrays.java:3181) at java.util.ArrayList.grow(ArrayList.java:265) at java.util.ArrayList.ensureExplicitCapacity(ArrayList.java:239) at java.util.ArrayList.ensureCapacityInternal(ArrayList.java:231) at java.util.ArrayList.add(ArrayList.java:462) at com.bubble.jvm.error.JavaHeapOOM.main(JavaHeapOOM.java:23) 可以在目录/Users/wugang/code/java/multi-dev下看到java_pid80802.hprof文件。 分析dump文件：可以通过内存映像分析工具(如Eclipse Memory Analyzer)对Dump出来的堆转储快照进行分析，也可以通过JDK自带的工具jvisualvm来可视化分析。12# 控制行执行命令jvisualvm 会打开下面的窗口，打开对应的堆dump文件： 主要内容为：由上图可知：导致 OutOfMemoryError 异常错误的线程是 main 查看dump的类信息：由上图可知：dump文件记录的堆中的实例总大小约19M，指定的堆的固定大小为20M。 用第一行的实例大小除以百分比就能算出来：堆中实例大小：12965216B/1024/1024=12.36M，占了总大小的65%。堆中实例总大小：12.36M/0.65=19.02M 说明：dump文件中的实例列表其实是反映了使用的堆的情况，而使用的堆内存并没有达到预先设置的最大堆内存，只是在申请堆内存的过程中超出了预先设置的最大堆内存，然后内存溢出。 方法区和运行时常量池溢出方法区（Method Area）方法区与Java堆一样，属于线程共享区，它用于存储已被虚拟机加载的类型信息、常量、静态变量、即时编译器编译后的代码缓存等数据。 《Java虚拟机规范》对方法区的约束是非常宽松的，除了和Java堆一样不需要连续的内存和可以选择固定大小或者可扩展外，甚至还可以选择不实现垃圾收集。 注意： 关于方法区和永久代（元空间）：在JDK8以前，很多人把方法区称呼为永久代（Permanent Generation，或将两者混为一谈。本质上这两者并不是等价的，仅因为HotSpot使用永久代来实现方法区而已，使得HotSpot的垃圾收集器能够像管理Java堆一样管理这部分内存，省去专门为方法区编写内存管理代码的工作。到了JDK 7的HotSpot，已经把原本放在永久代的字符串常量池、静态变量等移出；而到了JDK 8，完全废弃了永久代的概念，改用与JRockit、J9一样在本地内存中实现的元空间(Metaspace)来代替，把JDK 7中永久代还剩余的内容(主要是类型信息)全部移到元空间中。 参数JDK8之前：老年代（Permanent Gennration） 如：-XX:PermSize=10M 指定老年代的初始空间大小（10M），以字节为单位。 如：-XX:MaxPermSize=10M 设置老年代最大值，默认是-1，即不限制，或者说只受限于本地内存大小。 JDK8始：元空间（Metaspace）Metaspace使用的是本地内存，而不是堆内存，也就是说在默认情况下Metaspace的大小只与本地内存大小有关。 -XX:MetaspaceSize：指定元空间的初始空间大小，以字节为单位。 达到该值就会触发垃圾收集进行类型卸载，同时收集器会对该值进行调整：如果释放了大量的空间，就适当降低该值；如果释放了很少的空间，那么在不超过-XX:MaxMetaspaceSize(如果设置了的话)的情况下，适当提高该值。 该值越大触发Metaspace GC的时机就越晚。随着GC的到来，虚拟机会根据实际情况调控Metaspace的大小，可能增加上限也可能降低。在默认情况下，这个值大小根据不同的平台在12M到20M浮动。使用java -XX:+PrintFlagsInitial命令查看本机的初始化参数，-XX:Metaspacesize为21810376B（大约20.8M） 。 -XX:MaxMetaspaceSize：设置元空间最大值，默认是-1，即不限制，或者说只受限于本地内存大小。 防止因为某些情况导致Metaspace无限的使用本地内存，影响到其他程序。在本机上该参数的默认值为4294967295B（大约4096MB）。 -XX:MinMetaspaceFreeRatio：作用是在Metaspace GC收集之后，控制最小的元空间剩余容量的百分比，可减少因为元空间不足导致的垃圾收集的频率。 当进行过Metaspace GC之后，会计算当前Metaspace的空闲空间比。如果空闲比小于这个参数，那么虚拟机将增长Metaspace的大小。在本机该参数的默认值为40，也就是40%。设置该参数可以控制Metaspace的增长的速度，太小的值会导致Metaspace增长的缓慢，Metaspace的使用逐渐趋于饱和，可能会影响之后类的加载。而太大的值会导致Metaspace增长的过快，浪费内存。 -XX:MaxMetaspaceFreeRatio：用于控制大的元空间剩余容量的百分比。 当进行过Metaspace GC之后， 会计算当前Metaspace的空闲空间比，如果空闲比大于这个参数，那么虚拟机会释放Metaspace的部分空间。在本机该参数的默认值为70，也就是70%。 -XX:MaxMetaspaceExpansion： Metaspace增长时的最大幅度。在本机上该参数的默认值为5452592B（大约为5MB）。 -XX:MinMetaspaceExpansion： Metaspace增长时的最小幅度。在本机上该参数的默认值为340784B（大约330KB为）。 运行时常量池（Runtime Constant Pool）运行时常量池是方法区的一部分。Class文件中除了有类的版本、字段、方法、接口等描述信息外，还有一项信息是常量池表(Constant Pool Table)，用于存放编译期生成的各种字面量与符号引用，这部分内容将在类加载后存放到方法区的运行时常量池中。 运行时常量池相对于Class文件常量池的另外一个重要特征是具备动态性，Java语言并不要求常量一定只有编译期才能产生，在运行期间也可以将新的常量放入池中，如使用String类的intern()方法。 OOM异常运行时常量池是方法区的一部分，自然受到方法区内存的限制，当常量池无法再申请到内存时会抛出OutOfMemoryError异常。 案例HotSpot从JDK7开始逐步“去永久代”的计划，并在JDK8中完全使用元空间来代替永久代。 方法区12345678910111213141516171819202122232425262728293031323334353637383940/** * 方法区的OOM异常： * - JDK8之前：指定老年代（方法区的大小固定为10M，不能进行自动扩展） * VM Args: -XX:PermSize=10M -XX:MaxPermSize=10M * * - JDK8：完全废除了老年代，用元空间代替。 * VM Args: -XX:MetaspaceSize=10M -XX:MaxMetaspaceSize=10M * * @author wugang * date: 2020-06-04 18:44 **/public class JavaMethodAreaOOM &#123; static class OOMObject &#123;&#125; /** * 借助CGLib使得方法区出现内存溢出异常： * 方法区的主要职责是用于存放类型的相关信息：如类名、访问修饰符、常量池、字段描述、方法描述等。 * 对于这部分区域的测试，基本的思路是：运行时产生大量的类去填满方法区，直到溢出为止。 * 所以：可以借助CGLib直接操作字节码，运行时生成了大量的动态类。 * 注意： * 当前的很多主流框架，如Spring、Hibernate对类进行增强时，都会使用到 CGLib这类字节码技术， * 当增强的类越多，就需要越大的方法区以保证动态生成的新类型可以载入内存。 */ public static void main(String[] args) &#123; while (true) &#123; Enhancer enhancer = new Enhancer(); enhancer.setSuperclass(OOMObject.class); enhancer.setUseCache(false); enhancer.setCallback(new MethodInterceptor() &#123; @Override public Object intercept(Object o, Method method, Object[] objects, MethodProxy methodProxy) throws Throwable &#123; return methodProxy.invokeSuper(o, args); &#125; &#125;); enhancer.create(); &#125; &#125;&#125; 输出： 12345678910111213141516171819Exception in thread &quot;main&quot; net.sf.cglib.core.CodeGenerationException: java.lang.reflect.InvocationTargetException--&gt;null at net.sf.cglib.core.AbstractClassGenerator.generate(AbstractClassGenerator.java:348) at net.sf.cglib.proxy.Enhancer.generate(Enhancer.java:492) at net.sf.cglib.core.AbstractClassGenerator$ClassLoaderData.get(AbstractClassGenerator.java:117) at net.sf.cglib.core.AbstractClassGenerator.create(AbstractClassGenerator.java:294) at net.sf.cglib.proxy.Enhancer.createHelper(Enhancer.java:480) at net.sf.cglib.proxy.Enhancer.create(Enhancer.java:305) at com.bubble.jvm.error.JavaMethodAreaOOM.main(JavaMethodAreaOOM.java:39)Caused by: java.lang.reflect.InvocationTargetException at sun.reflect.GeneratedMethodAccessor1.invoke(Unknown Source) at sun.reflect.DelegatingMethodAccessorImpl.invoke(DelegatingMethodAccessorImpl.java:43) at java.lang.reflect.Method.invoke(Method.java:498) at net.sf.cglib.core.ReflectUtils.defineClass(ReflectUtils.java:459) at net.sf.cglib.core.AbstractClassGenerator.generate(AbstractClassGenerator.java:339) ... 6 moreCaused by: java.lang.OutOfMemoryError: Metaspace at java.lang.ClassLoader.defineClass1(Native Method) at java.lang.ClassLoader.defineClass(ClassLoader.java:763) ... 11 more 运行时常量池12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import java.util.HashSet;import java.util.Set;/** * 方法区（运行时常量池）的OOM异常，（方法区在JDK8后开始废除，之前也被称为永久代） * - 在JDK 6或更早之前的HotSpot虚拟机中，常量池都是分配在永久代中， * 我们可以通过-XX:PermSize和-XX:M axPermSize限制永久代的大小，即可间接限制其中常量池的容量。 * 如：VM Args:-XX:PermSize=6M -XX:MaxPermSize=6M * * @author wugang * date: 2020-06-04 17:36 **/public class RuntimeConstantPoolOOM &#123; /** * JDK6来运行代码，抛出异常： * Exception in thread \"main\" java.lang.OutOfMemoryError: PermGen space * at java.lang.String.intern(Native Method) * 说明运行时常量池是属于方法区(即JDK 6的HotSpot虚拟机中的永久代)的一部分。 * * 注意： * 无论是在JDK7中继续使用-XX:MaxPermSize参数或者在JDK8及以上版本使用-XX:MaxMeta-spaceSize参数 * 把方法区容量同样限制在6MB，也都不会重现JDK6中的溢出异常，循环将一直进行下去，永不停歇。 * * 因为自JDK7起，原本存放在永久代的字符串常量池被移至Java堆之中， * 所以在JDK7及以上版本，限制方法区的容量对该测试用例来说是毫无意义的。 * * 但使用-Xmx参数限制最大堆到6MB就能够看到下面两种运行结果之一，具体取决于哪里的对象分配时产生了溢出： * - OOM异常一： * Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space * at java.base/java.lang.Integer.toString(Integer.java:440) * at java.base/java.lang.String.valueOf(String.java:3058) * - OOM异常二： * Exception in thread \"main\" java.lang.OutOfMemoryError: Java heap space * at java.base/java.util.HashMap.resize(HashMap.java:699) * at java.base/java.util.HashMap.putVal(HashMap.java:658) * at java.base/java.util.HashMap.put(HashMap.java:607) * at java.base/java.util.HashSet.add(HashSet.java:220) * */ private static void runByJDK6() &#123; // 使用Set保持着常量池引用，避免Full GC回收常量池行为 Set&lt;String&gt; set = new HashSet&lt;&gt;(); // 在short范围内足以让6MB的PermSize产生OOM了 short i = 0; while (true) &#123; set.add(String.valueOf(i++).intern()); &#125; &#125; public static void main(String[] args) &#123; runByJDK6(); &#125;&#125; String::intern()方法String::intern()是一个Native方法，返回该对象在常量池中的引用。 1public native String intern(); 作用：如果字符串常量池中已经包含一个等于该String对象的字符串，则返回代表池中这个字符串的String对象的引用；否则，会将此String对象包含的字符串添加到常量池中，并且返回此String对象的引用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556/** * - 在JDK 6中运行，会得到三个false； * 在JDK 6中，intern()方法会把首次遇到的字符串实例复制到永久代（方法区）的字符串常量池中存储， * 返回的也是永久代里面这个字符串实例的引用，而由StringBuilder创建的字符串对象实例在Java堆上， * 所以必然不可能是同一个引用，结果将返回false。 * * - 而在JDK 7后中运行，会得到一个true、一个false和一个true； * 因为JDK7中，intern()方法实现就不需要再拷贝字符串的实例到永久代了，既然字符串常量池已经移到Java堆中， * 那只需要在常量池里记录一下首次出现的实例引用即可。 * 因此intern()返回的引用和由StringBuilder创建的那个字符串实例就是同一个。 * 而对str2比较返回false，这是因为java这个字符串在执行StringBuilder()之前就已经出现过了，(在加载sun.misc.Version这个类的时候进入常量池的) * 字符串常量池中已经有它的引用，不符合intern()方法要求“首次遇到”的原则，“JVM调优”这个字符串则是首次出现的，因此结果返回true。 * 而str3和str1一样，\"JDKJVM\"这个字符串则是首次出现。 * */private static void compare() &#123; String str1 = new StringBuilder().append(\"JVM\").append(\"调优\").toString(); System.out.println(str1.intern() == str1); // java这个字符串在执行StringBuilder()之前就已经出现过了，在加载sun.misc.Version这个类的时候进入常量池的。 /* * 参考：https://www.zhihu.com/question/51102308/answer/124441115 * sun.misc.Version类会在JDK类库的初始化过程中被加载并初始化， * 而在初始化时它需要对静态常量字段根据指定的常量值（ConstantValue）做默认初始化， * 此时被 sun.misc.Version.launcher 静态常量字段所引用的\"java\"字符串字面量就被intern到HotSpot VM的字符串常量池StringTable里了。 */ String str2 = new StringBuilder().append(\"ja\").append(\"va\").toString(); System.out.println(str2.intern() == str2); // 而JDKJVM这个字符串则是首次出现 String str3 = new StringBuilder().append(\"JDK\").append(\"JVM\").toString(); System.out.println(str3.intern() == str3);&#125;/** * java中的String是引用类型。创建的String对象，实际上存储的是一个地址。 * 所以下面a和b都是引用类型，其存储的是字符串的地址。它们本身存储在Java虚拟机栈的局部变量表中。 * - a：直接将字符串存储在常量池中，然后将a指向常量池种中的\"JVM\"。 * - b：先将字符串\"JVM\"存储在常量池中，然后在heap中创建一个对象，该对象指向常量池中的\"JVM\"，最后将b指向heap中创建的这个对象。 * * 也就是说，a和b存储的内容是一样的，都是\"JVM\"，但地址不一样：a中保存的是常量池中\"JVM\"的地址，b保存的是heap中那个对象的地址， * * 双等于号\"==\"比较的是地址，equals()比较的是内容。 */private static void compareStr() &#123; String a = \"JVM\"; // new一个对象 String b = new String(\"JVM\"); // == 比较地址是否相等 // 都在运行时常量池中 System.out.println(\"JVM\" == a); // true System.out.println(a.intern() == a); // true // a为字符字面量（存储在运行时常量池中），b为对象（存储在堆中），所以不等。 System.out.println(a == b); // false System.out.println(a.intern() == b); // false System.out.println(a.equals(b)); // true&#125; 其他（不受JVM GC管理区域）本机直接内存溢出直接内存（Direct Memory）直接内存并不是虚拟机运行时数据区的一部分，也不是《Java虚拟机规范》中定义的内存区域。 容量大小可通过-XX:MaxDirectMemorySize参数来指定，如果不去指定，则默认与Java堆最大值(由-Xmx指定)一致。 NIO(New Input/Output)类NIO引入了一种基于通道(Channel)与缓冲区 (Buffer)的I/O方式，它可以使用Native函数库直接分配堆外内存，然后通过一个存储在Java堆里面的DirectByteBuffer对象作为这块内存的引用进行操作。这样能在一些场景中显著提高性能，因为避免了在Java堆和Native堆中来回复制数据。 OOM异常当各个内存区域总和大于物理内存限制(包括物理的和操作系统级的限制)，从而导致动态扩展时出现 OutOfMemoryError异常。 1234567891011121314151617181920212223242526272829303132333435import sun.misc.Unsafe;import java.lang.reflect.Field;/** * 直接内存OOM异常：使用unsafe分配本机内存 * VM Args: -Xmx20M -XX:MaxDirectMemorySize=10M * * @author wugang * date: 2020-06-04 19:43 **/public class DirectMemoryOOM &#123; private static final int _1MB = 1024 * 1024; /** * 越过了DirectByteBuffer类直接通过反射获取Unsafe实例进行内存分配。 * （Unsafe类的getUnsafe()方法指定只有引导类加载器才会返回实例，体现了设计者希望只有虚拟机标准类库里面的类才能使用Unsafe的功能，在JDK 10时才将Unsafe的部分功能通过VarHandle开放给外部使用） * 因为虽然使用DirectByteBuffer分配内存也会抛出内存溢出异常，但它抛出异常时并没有真正向操作系统申请分配内存， * 而是通过计算得知内存无法分配就会在代码里手动抛出溢出异常，真正申请分配内存的方法是Unsafe::allocateMemory ()。 * * 抛出异常： * Exception in thread \"main\" java.lang.OutOfMemoryError * at sun.misc.Unsafe.allocateMemory(Native Method) */ public static void main(String[] args) throws IllegalAccessException &#123; Field unsafeField = Unsafe.class.getDeclaredFields()[0]; unsafeField.setAccessible(true); Unsafe unsafe = (Unsafe) unsafeField.get(null); while (true) &#123; unsafe.allocateMemory(_1MB); &#125; &#125;&#125; 由直接内存导致的内存溢出，一个明显的特征是在Heap Dump文件中不会看见有什么明显的异常情况。如果发现内存溢出之后产生的Dump文件很小，而程序中又直接或间接使用了DirectMemory(典型的间接使用就是NIO)，那就可以考虑重点检查一下直接内存方面的原因了。","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://bubblewu.github.io/categories/Java/JVM/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"JVM","slug":"JVM","permalink":"https://bubblewu.github.io/tags/JVM/"}]},{"title":"生产者-消费者案例","slug":"Java/生产者-消费者案例","date":"2020-06-05T06:52:19.000Z","updated":"2020-06-14T08:15:51.867Z","comments":true,"path":"ckd70wo77000jqlyd8qx0g49p/","link":"","permalink":"https://bubblewu.github.io/ckd70wo77000jqlyd8qx0g49p/","excerpt":"基于Java的生产者-消费者模式代码实现，可以此为Demo来用于具体的实际业务。","text":"基于Java的生产者-消费者模式代码实现，可以此为Demo来用于具体的实际业务。 生产者-消费者demo123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243import org.slf4j.Logger;import org.slf4j.LoggerFactory;import java.time.Duration;import java.time.Instant;import java.util.*;import java.util.concurrent.ArrayBlockingQueue;import java.util.concurrent.LinkedBlockingQueue;import java.util.concurrent.ThreadPoolExecutor;import java.util.concurrent.TimeUnit;&#x2F;** * 推荐服务：生产者-消费者模式 * * @author bubble * date: 2018-10-22 15:03 **&#x2F;@Deprecatedpublic class RecService &#123; private static final Logger LOGGER &#x3D; LoggerFactory.getLogger(RecService.class); &#x2F;&#x2F; 日志打印间隔 private static int DEFAULT_LOG_INTERVAL &#x3D; 1000 * 10; &#x2F;&#x2F; 队列默认处理容量，为避免队列扩容造成额外性能损耗，默认不扩容，达到当前大小，进入等待，消费者处理一部分数据之后，生产者继续生产 private static int DEFAULT_QUEUE_DISPOSE_SIZE &#x3D; 1000 * 10; &#x2F;&#x2F; 队列默认容量 private static int DEFAULT_QUEUE_SIZE &#x3D; DEFAULT_QUEUE_DISPOSE_SIZE + 200; &#x2F;&#x2F; 每个队列满时默认休眠时间 private static int DEFAULT_SLEEP_TIME &#x3D; 1000; &#x2F;&#x2F; 线程池默认消费者数量 private static int DEFAULT_CONSUMER_NUM &#x3D; 2; &#x2F;&#x2F; 用户的phoneId队列 private LinkedBlockingQueue&lt;Long&gt; phoneIdQueue &#x3D; new LinkedBlockingQueue&lt;&gt;(DEFAULT_QUEUE_SIZE); private Long STOP_FLAG &#x3D; -1L; private Map&lt;Long, List&lt;FlightInfoBean&gt;&gt; flightInfoMap; &#x2F;&#x2F; 用户航班信息 private Map&lt;Long, List&lt;FlightInfoBean&gt;&gt; getFlightInfoMap() &#123; return flightInfoMap; &#125; private void setFlightInfoMap(Map&lt;Long, List&lt;FlightInfoBean&gt;&gt; flightInfoMap) &#123; this.flightInfoMap &#x3D; flightInfoMap; &#125; private RecJobBean recJob; private TipRecService tipRecService; private CarRecService carRecService; private HotelRecService hotelRecService; public RecService(RecJobBean recJob) &#123; this.recJob &#x3D; recJob; switch (recJob) &#123; case TIP: tipRecService &#x3D; Optional.ofNullable(tipRecService).orElse(new TipRecService()); break; case CAR: carRecService &#x3D; Optional.ofNullable(carRecService).orElse(new CarRecService()); break; case HOTEL: hotelRecService &#x3D; Optional.ofNullable(hotelRecService).orElse(new HotelRecService()); break; default: LOGGER.error(&quot;please enter the correct rec type, error type: &#123;&#125; &quot;, recJob.getType()); System.exit(0); break; &#125; &#125; public void rec(Map&lt;Long, List&lt;FlightInfoBean&gt;&gt; userFlightMap, int top) &#123; LOGGER.info(&quot;start &#123;&#125; rec job.&quot;, recJob.getType()); if (userFlightMap &#x3D;&#x3D; null || userFlightMap.isEmpty()) &#123; LOGGER.error(&quot;user flight is empty, rec job for &#123;&#125; exit.&quot;, recJob.getType()); System.exit(0); &#125; setFlightInfoMap(userFlightMap); UserProducer userProducer &#x3D; new UserProducer(); userProducer.setName(&quot;producer&quot;); userProducer.start(); UserConsumer userConsumer &#x3D; new UserConsumer(recJob, top); ThreadPoolExecutor poolExecutor &#x3D; userConsumer.consumerAndRec(); threadMonitor(poolExecutor); &#125; &#x2F;** * 监控ThreadPoolExecutor线程池，无活动线程就关闭线程池连接； *&#x2F; private void threadMonitor(ThreadPoolExecutor executor) &#123; Runnable runnable &#x3D; () -&gt; &#123; try &#123; TimeUnit.SECONDS.sleep(2); while (executor.getActiveCount() &gt; 0) &#123; TimeUnit.SECONDS.sleep(1); &#125; executor.shutdown(); &#125; catch (InterruptedException e) &#123; LOGGER.error(&quot;thread monitor error.&quot;, e); &#125; &#125;; new Thread(runnable).start(); &#125; &#x2F;** * 生产者: 可用phoneId集合 *&#x2F; class UserProducer extends Thread &#123; int i &#x3D; 0; @Override public void run() &#123; addUser(); try &#123; &#x2F;&#x2F; 给每个线程都在队列（FIFO）末尾添加标识 phoneIdQueue.put(STOP_FLAG); &#125; catch (InterruptedException e) &#123; LOGGER.error(&quot;save phoneId error.&quot;, e); &#125; LOGGER.info(&quot;[&#123;&#125;] thread altogether produces &#123;&#125; data&quot;, this.getName(), i); LOGGER.info(&quot;[&#123;&#125;] thread produces done.&quot;, this.getName()); &#125; private void addUser() &#123; try &#123; int step &#x3D; 0; LOGGER.info(&quot;add &#123;&#125; user in producer queue.&quot;, getFlightInfoMap().size()); Iterator iter &#x3D; getFlightInfoMap().entrySet().iterator(); while (iter.hasNext()) &#123; Map.Entry entry &#x3D; (Map.Entry) iter.next(); long uid &#x3D; (long) entry.getKey(); phoneIdQueue.put(uid); step++; while (phoneIdQueue.size() &gt; DEFAULT_QUEUE_DISPOSE_SIZE) &#123; Thread.sleep(DEFAULT_SLEEP_TIME); &#125; if (step &#x3D;&#x3D; DEFAULT_LOG_INTERVAL) &#123; i +&#x3D; step; step &#x3D; 0; LOGGER.info(&quot;[&#123;&#125;] thread has produced &#123;&#125; pieces of data&quot;, this.getName(), i); &#125; &#125; i +&#x3D; step; &#125; catch (InterruptedException e) &#123; LOGGER.error(&quot;save phoneId error.&quot;, e); &#125; &#125; &#125; &#x2F;** * 消费者：取phoneId并进行推荐 *&#x2F; class UserConsumer &#123; private int top; private RecJobBean recJob; public UserConsumer(RecJobBean recJob, int top) &#123; this.recJob &#x3D; recJob; this.top &#x3D; top; &#125; public ThreadPoolExecutor consumerAndRec() &#123; ThreadPoolExecutor poolExecutor &#x3D; new ThreadPoolExecutor(DEFAULT_CONSUMER_NUM, DEFAULT_CONSUMER_NUM &lt;&lt; 1, 60 * 60 * 4, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(50), new ThreadPoolExecutor.CallerRunsPolicy()); LOGGER.info(&quot;Consumer start.&quot;); for (int i &#x3D; 0; i &lt; DEFAULT_CONSUMER_NUM; i++) &#123; Thread t &#x3D; new Thread() &#123; int step &#x3D; 0; int consumerNum &#x3D; 0; @Override public void run() &#123; while (!this.isInterrupted()) &#123; Long phoneId; try &#123; phoneId &#x3D; phoneIdQueue.take(); if (phoneId.equals(STOP_FLAG)) &#123; &#x2F;&#x2F; 该线程取到-1，说明产品队列中已无产品，可以结束线程，但是可能还有其他线程存活，需要通知其他线程已无数据 &#x2F;&#x2F; 因此，插入-1，同时跳出循环，线程归还线程池，等待监控线程发现其处于非活动状态，将其销毁，最终销毁线程池 phoneIdQueue.put(STOP_FLAG); LOGGER.info(&quot;[&#123;&#125;] thread consumes done.&quot;, this.getName()); break; &#125; recOneUser(recJob, phoneId, top); consumerNum++; step++; if (step &#x3D;&#x3D; DEFAULT_LOG_INTERVAL) &#123; step &#x3D; 0; LOGGER.info(&quot;[&#123;&#125;] thread has consumed &#123;&#125; pieces of data&quot;, this.getName(), consumerNum); &#125; &#125; catch (InterruptedException e) &#123; LOGGER.error(&quot;read data from phoneIdQueue error.&quot;, e); &#125; &#125; LOGGER.info(&quot;[&#123;&#125;] thread altogether consumes &#123;&#125; user data&quot;, this.getName(), consumerNum); LOGGER.info(&quot;RecConsumer end.&quot;); &#125; &#125;; t.setName(&quot;RecConsumer-&quot; + i); poolExecutor.execute(t); &#125; return poolExecutor; &#125; &#125; private void recOneUser(RecJobBean recJob, long uid, int top) &#123; Instant begin &#x3D; Instant.now(); List&lt;FlightInfoBean&gt; userFlightInfoList &#x3D; getFlightInfoMap().get(uid); if (userFlightInfoList !&#x3D; null &amp;&amp; !userFlightInfoList.isEmpty()) &#123; List&lt;TipsUserLinkBean&gt; recItems &#x3D; new ArrayList&lt;&gt;(); switch (recJob) &#123; case TIP: recItems &#x3D; tipRecService.rec(uid, userFlightInfoList, top); break; case CAR: recItems &#x3D; carRecService.rec(uid, userFlightInfoList); break; case HOTEL: recItems &#x3D; hotelRecService.rec(uid, userFlightInfoList, top); break; default: LOGGER.error(&quot;please enter the correct rec type, error type: &#123;&#125; &quot;, recJob.getType()); break; &#125; LOGGER.info(&quot;&#123;&#125; rec for user [&#123;&#125;] count is &#123;&#125;, costs &#123;&#125; ms&quot;, recJob.getType(), uid, recItems.size(), Duration.between(begin, Instant.now()).toMillis()); Instant saveStart &#x3D; Instant.now(); try &#123; DataService.saveTipsUserLink(recItems, recJob); &#125; catch (java.lang.NullPointerException np) &#123; LOGGER.error(&quot;user [&#123;&#125;] saveTipsUserLink error.&quot;, uid, np); &#125; LOGGER.info(&quot;&#123;&#125; rec for user [&#123;&#125;] count is &#123;&#125;, save costs &#123;&#125; ms&quot;, recJob.getType(), uid, recItems.size(), Duration.between(saveStart, Instant.now()).toMillis()); &#125; &#125;&#125;","categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"}]},{"title":"Bubble Sort","slug":"Python/冒泡排序","date":"2020-05-11T15:08:10.000Z","updated":"2020-06-14T08:23:06.061Z","comments":true,"path":"ckd70wo75000hqlydauhj1t6k/","link":"","permalink":"https://bubblewu.github.io/ckd70wo75000hqlydauhj1t6k/","excerpt":"经典面试题---进阶版冒泡排序","text":"经典面试题---进阶版冒泡排序 常规版1234567891011121314151617#!/usr/bin/env python3# -*- coding: utf-8 -*-def foo(data): \"\"\"常规版\"\"\" for i in range(len(data)): for j in range(len(data)-i-1): if data[j] &gt; data[j+1]: data[j], data[j + 1] = data[j + 1], data[j] return dataif __name__ == '__main__': data = [3, 0, 5, 4, 2, 6, 8, 1, 9, 7] print(data) print(foo(data)) 进阶版1234567891011121314151617181920212223242526272829303132#!/usr/bin/env python3# -*- coding: utf-8 -*-def bubble_sort(data): \"\"\" 进阶版 最坏情况 时间复杂度 O(n**2) 最好情况 时间复杂度 O(n) 稳定排序法 空间复杂度最佳 只需要一个额外空间 适用于数据量小或有部分数据已经排过序的情况 :param data: :return: \"\"\" # i 倒序循环列表排序 for i in range(len(data)-1, -1, -1): flag = False # flag判断是否执行了交换操作 for j in range(i): # i 为倒序循环，所以j的最大值即是i 0～i if data[j] &gt; data[j + 1]: data[j], data[j + 1] = data[j + 1], data[j] flag = True # 执行过交换操作，把flag置为True if not flag: # 执行完一次扫描后，判断是否执行过交换操作，如果没有交换过数据，就表示此时数组已完成排序，故直接跳出循环 break print('第&#123;0&#125;次排序: &#123;1&#125;'.format(len(data)-i, data)) return dataif __name__ == '__main__': data = [3, 0, 5, 4, 2, 6, 8, 1, 9, 7] print(data) print(bubble_sort(data))","categories":[{"name":"Python","slug":"Python","permalink":"https://bubblewu.github.io/categories/Python/"}],"tags":[{"name":"面试","slug":"面试","permalink":"https://bubblewu.github.io/tags/%E9%9D%A2%E8%AF%95/"}]}],"categories":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/categories/Java/"},{"name":"并发","slug":"Java/并发","permalink":"https://bubblewu.github.io/categories/Java/%E5%B9%B6%E5%8F%91/"},{"name":"Redis","slug":"Redis","permalink":"https://bubblewu.github.io/categories/Redis/"},{"name":"Tool","slug":"Java/Tool","permalink":"https://bubblewu.github.io/categories/Java/Tool/"},{"name":"JVM","slug":"Java/JVM","permalink":"https://bubblewu.github.io/categories/Java/JVM/"},{"name":"Neo4j","slug":"Neo4j","permalink":"https://bubblewu.github.io/categories/Neo4j/"},{"name":"Python","slug":"Python","permalink":"https://bubblewu.github.io/categories/Python/"}],"tags":[{"name":"Java","slug":"Java","permalink":"https://bubblewu.github.io/tags/Java/"},{"name":"并发","slug":"并发","permalink":"https://bubblewu.github.io/tags/%E5%B9%B6%E5%8F%91/"},{"name":"Redis","slug":"Redis","permalink":"https://bubblewu.github.io/tags/Redis/"},{"name":"Tool","slug":"Tool","permalink":"https://bubblewu.github.io/tags/Tool/"},{"name":"JVM","slug":"JVM","permalink":"https://bubblewu.github.io/tags/JVM/"},{"name":"Neo4j","slug":"Neo4j","permalink":"https://bubblewu.github.io/tags/Neo4j/"},{"name":"Python","slug":"Python","permalink":"https://bubblewu.github.io/tags/Python/"},{"name":"面试","slug":"面试","permalink":"https://bubblewu.github.io/tags/%E9%9D%A2%E8%AF%95/"}]}